<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 The linear model | Research Design and Statistics</title>
  <meta name="description" content="An introduction to research design and statistics" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 The linear model | Research Design and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An introduction to research design and statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 The linear model | Research Design and Statistics" />
  
  <meta name="twitter:description" content="An introduction to research design and statistics" />
  

<meta name="author" content="Bradley J. Cosentino" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bayesian-workflow.html"/>
<link rel="next" href="graphical-causal-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#work-in-progress"><i class="fa fa-check"></i>Work in progress</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#copyright"><i class="fa fa-check"></i>Copyright</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html"><i class="fa fa-check"></i><b>1</b> Why Statistics? The Problem of Uncertainty</a>
<ul>
<li class="chapter" data-level="1.1" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#the-nature-of-science"><i class="fa fa-check"></i><b>1.1</b> The nature of science</a></li>
<li class="chapter" data-level="1.2" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#goals-of-scientific-research"><i class="fa fa-check"></i><b>1.2</b> Goals of scientific research</a></li>
<li class="chapter" data-level="1.3" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#three-general-goals-of-scientific-research"><i class="fa fa-check"></i><b>1.3</b> Three general goals of scientific research</a></li>
<li class="chapter" data-level="1.4" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#research-design-and-statistical-analysis-depend-on-your-goal"><i class="fa fa-check"></i><b>1.4</b> Research design and statistical analysis depend on your goal</a></li>
<li class="chapter" data-level="1.5" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#you-cant-escape-uncertainty-in-science"><i class="fa fa-check"></i><b>1.5</b> You can’t escape uncertainty in science</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html"><i class="fa fa-check"></i><b>2</b> Scientific workflow: Connecting ideas to data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#research-questions"><i class="fa fa-check"></i><b>2.1</b> Research questions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#clarify-your-primary-goal-description-prediction-or-explanation"><i class="fa fa-check"></i><b>2.1.1</b> Clarify your primary goal: description, prediction, or explanation?</a></li>
<li class="chapter" data-level="2.1.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#identify-the-scope-of-inference-the-who-what-when-and-where-of-your-study."><i class="fa fa-check"></i><b>2.1.2</b> Identify the scope of inference: The who, what, when, and where of your study.</a></li>
<li class="chapter" data-level="2.1.3" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-it-interesting"><i class="fa fa-check"></i><b>2.1.3</b> Make it interesting</a></li>
<li class="chapter" data-level="2.1.4" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-it-answerable-with-data"><i class="fa fa-check"></i><b>2.1.4</b> Make it answerable with data</a></li>
<li class="chapter" data-level="2.1.5" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#ground-it-in-theory"><i class="fa fa-check"></i><b>2.1.5</b> Ground it in theory</a></li>
<li class="chapter" data-level="2.1.6" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-sure-its-feasible"><i class="fa fa-check"></i><b>2.1.6</b> Make sure it’s feasible</a></li>
<li class="chapter" data-level="2.1.7" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#avoid-analyzing-the-data-before-stating-your-question"><i class="fa fa-check"></i><b>2.1.7</b> Avoid analyzing the data before stating your question</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#connecting-ideas-to-data"><i class="fa fa-check"></i><b>2.2</b> Connecting ideas to data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#theory"><i class="fa fa-check"></i><b>2.2.1</b> Theory</a></li>
<li class="chapter" data-level="2.2.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#research-question"><i class="fa fa-check"></i><b>2.2.2</b> Research question</a></li>
<li class="chapter" data-level="2.2.3" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#generative-model"><i class="fa fa-check"></i><b>2.2.3</b> Generative model</a></li>
<li class="chapter" data-level="2.2.4" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#study-design"><i class="fa fa-check"></i><b>2.2.4</b> Study design</a></li>
<li class="chapter" data-level="2.2.5" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#estimand"><i class="fa fa-check"></i><b>2.2.5</b> Estimand</a></li>
<li class="chapter" data-level="2.2.6" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#target-population"><i class="fa fa-check"></i><b>2.2.6</b> Target population</a></li>
<li class="chapter" data-level="2.2.7" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#sample-data"><i class="fa fa-check"></i><b>2.2.7</b> Sample data</a></li>
<li class="chapter" data-level="2.2.8" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#statistical-model"><i class="fa fa-check"></i><b>2.2.8</b> Statistical model</a></li>
<li class="chapter" data-level="2.2.9" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#estimate"><i class="fa fa-check"></i><b>2.2.9</b> Estimate</a></li>
<li class="chapter" data-level="2.2.10" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#summary"><i class="fa fa-check"></i><b>2.2.10</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html"><i class="fa fa-check"></i><b>3</b> Introduction to Data and R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#an-introduction-to-data"><i class="fa fa-check"></i><b>3.1</b> An introduction to data</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#variables-and-observations"><i class="fa fa-check"></i><b>3.1.1</b> Variables and observations</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#types-of-variables"><i class="fa fa-check"></i><b>3.1.2</b> Types of variables</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#relationships-between-variables"><i class="fa fa-check"></i><b>3.1.3</b> Relationships between variables</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#variable-naming-conventions-and-metadata"><i class="fa fa-check"></i><b>3.1.4</b> Variable naming conventions and metadata</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#introduction-to-r"><i class="fa fa-check"></i><b>3.2</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>3.2.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#the-rstudio-interface"><i class="fa fa-check"></i><b>3.2.2</b> The RStudio Interface</a></li>
<li class="chapter" data-level="3.2.3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#basic-data-manipulation-in-r"><i class="fa fa-check"></i><b>3.2.3</b> Basic data manipulation in R</a></li>
<li class="chapter" data-level="3.2.4" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#scripting"><i class="fa fa-check"></i><b>3.2.4</b> Scripting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="describing-data.html"><a href="describing-data.html"><i class="fa fa-check"></i><b>4</b> Describing data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="describing-data.html"><a href="describing-data.html#defining-the-population"><i class="fa fa-check"></i><b>4.1</b> Defining the population</a></li>
<li class="chapter" data-level="4.2" data-path="describing-data.html"><a href="describing-data.html#loading-data-into-r"><i class="fa fa-check"></i><b>4.2</b> Loading data into R</a></li>
<li class="chapter" data-level="4.3" data-path="describing-data.html"><a href="describing-data.html#inspecting-the-dataset"><i class="fa fa-check"></i><b>4.3</b> Inspecting the dataset</a></li>
<li class="chapter" data-level="4.4" data-path="describing-data.html"><a href="describing-data.html#describing-single-variables"><i class="fa fa-check"></i><b>4.4</b> Describing single variables</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="describing-data.html"><a href="describing-data.html#qualitative-variables"><i class="fa fa-check"></i><b>4.4.1</b> Qualitative variables</a></li>
<li class="chapter" data-level="4.4.2" data-path="describing-data.html"><a href="describing-data.html#quantitative-variables"><i class="fa fa-check"></i><b>4.4.2</b> Quantitative variables</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="describing-data.html"><a href="describing-data.html#describing-relationships-between-variables"><i class="fa fa-check"></i><b>4.5</b> Describing relationships between variables</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="describing-data.html"><a href="describing-data.html#associations-between-quantitative-variables"><i class="fa fa-check"></i><b>4.5.1</b> Associations between quantitative variables</a></li>
<li class="chapter" data-level="4.5.2" data-path="describing-data.html"><a href="describing-data.html#associations-between-quantitative-and-qualitative-variables"><i class="fa fa-check"></i><b>4.5.2</b> Associations between quantitative and qualitative variables</a></li>
<li class="chapter" data-level="4.5.3" data-path="describing-data.html"><a href="describing-data.html#associations-between-qualitative-variables"><i class="fa fa-check"></i><b>4.5.3</b> Associations between qualitative variables</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="describing-data.html"><a href="describing-data.html#next-steps"><i class="fa fa-check"></i><b>4.6</b> Next steps</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html"><i class="fa fa-check"></i><b>5</b> Uncertainty from sampling</a>
<ul>
<li class="chapter" data-level="5.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#sampling-requires-estimation"><i class="fa fa-check"></i><b>5.1</b> Sampling requires estimation</a></li>
<li class="chapter" data-level="5.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#parameters-estimates-estimands"><i class="fa fa-check"></i><b>5.2</b> Parameters, estimates, estimands</a></li>
<li class="chapter" data-level="5.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#sources-of-uncertainty-from-sampling"><i class="fa fa-check"></i><b>5.3</b> Sources of uncertainty from sampling</a></li>
<li class="chapter" data-level="5.4" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#accuracy-and-precision"><i class="fa fa-check"></i><b>5.4</b> Accuracy and precision</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#accuracy"><i class="fa fa-check"></i><b>5.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.4.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#precision"><i class="fa fa-check"></i><b>5.4.2</b> Precision</a></li>
<li class="chapter" data-level="5.4.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#considering-accuracy-and-precision-together"><i class="fa fa-check"></i><b>5.4.3</b> Considering accuracy and precision together</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#maximizing-accuracy-and-precision-of-estimates"><i class="fa fa-check"></i><b>5.5</b> Maximizing accuracy and precision of estimates</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#random-sampling"><i class="fa fa-check"></i><b>5.5.1</b> Random sampling</a></li>
<li class="chapter" data-level="5.5.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#replication"><i class="fa fa-check"></i><b>5.5.2</b> Replication</a></li>
<li class="chapter" data-level="5.5.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#take-home-points"><i class="fa fa-check"></i><b>5.5.3</b> Take-home points</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html"><i class="fa fa-check"></i><b>6</b> Probability as the Language of Uncertainty</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#defining-probability"><i class="fa fa-check"></i><b>6.1</b> Defining probability</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#frequentist-definition"><i class="fa fa-check"></i><b>6.1.1</b> Frequentist definition</a></li>
<li class="chapter" data-level="6.1.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#bayesian-definition"><i class="fa fa-check"></i><b>6.1.2</b> Bayesian definition</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#probability-rules"><i class="fa fa-check"></i><b>6.2</b> Probability rules</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#individual-events"><i class="fa fa-check"></i><b>6.2.1</b> Individual events</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#joint-events"><i class="fa fa-check"></i><b>6.2.2</b> Joint events</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#general-addition-rule"><i class="fa fa-check"></i><b>6.2.3</b> General addition rule</a></li>
<li class="chapter" data-level="6.2.4" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#quantifying-marginal-probabilities"><i class="fa fa-check"></i><b>6.2.4</b> Quantifying marginal probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-probability-distributions"><i class="fa fa-check"></i><b>6.3</b> Sampling from probability distributions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-populations-is-probabalistic"><i class="fa fa-check"></i><b>6.3.1</b> Sampling from populations is probabalistic</a></li>
<li class="chapter" data-level="6.3.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#discrete-random-variables"><i class="fa fa-check"></i><b>6.3.2</b> Discrete random variables</a></li>
<li class="chapter" data-level="6.3.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.3.3</b> Continuous random variables</a></li>
<li class="chapter" data-level="6.3.4" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-probability-distributions-1"><i class="fa fa-check"></i><b>6.3.4</b> Sampling from probability distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html"><i class="fa fa-check"></i><b>7</b> Bayesian estimation and inference</a>
<ul>
<li class="chapter" data-level="7.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#scientific-workflow-for-the-problem"><i class="fa fa-check"></i><b>7.1</b> Scientific workflow for the problem</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#theory-and-the-research-question"><i class="fa fa-check"></i><b>7.1.1</b> Theory and the research question</a></li>
<li class="chapter" data-level="7.1.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#generative-model-and-estimand"><i class="fa fa-check"></i><b>7.1.2</b> Generative model and estimand</a></li>
<li class="chapter" data-level="7.1.3" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#statistical-model-and-estimate"><i class="fa fa-check"></i><b>7.1.3</b> Statistical model and estimate</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#bayes-theorem"><i class="fa fa-check"></i><b>7.2</b> Bayes Theorem</a></li>
<li class="chapter" data-level="7.3" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#applying-bayes-theorem-to-statistical-analysis"><i class="fa fa-check"></i><b>7.3</b> Applying Bayes Theorem to statistical analysis</a></li>
<li class="chapter" data-level="7.4" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#steps-of-estimation-with-bayesian-inference"><i class="fa fa-check"></i><b>7.4</b> Steps of estimation with Bayesian inference</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#specify-the-prior-distribution"><i class="fa fa-check"></i><b>7.4.1</b> Specify the prior distribution</a></li>
<li class="chapter" data-level="7.4.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#quantify-the-likelihood-of-the-data"><i class="fa fa-check"></i><b>7.4.2</b> Quantify the likelihood of the data</a></li>
<li class="chapter" data-level="7.4.3" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#quantify-the-total-probability-of-the-data-marginal-likelihood"><i class="fa fa-check"></i><b>7.4.3</b> Quantify the total probability of the data (marginal likelihood)</a></li>
<li class="chapter" data-level="7.4.4" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#quantify-the-posterior-distribution"><i class="fa fa-check"></i><b>7.4.4</b> Quantify the posterior distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#summarizing-the-posterior-distribution"><i class="fa fa-check"></i><b>7.5</b> Summarizing the posterior distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#sampling-from-the-posterior-distribution"><i class="fa fa-check"></i><b>7.5.1</b> Sampling from the posterior distribution</a></li>
<li class="chapter" data-level="7.5.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#central-tendency-and-variance"><i class="fa fa-check"></i><b>7.5.2</b> Central tendency and variance</a></li>
<li class="chapter" data-level="7.5.3" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#intervals"><i class="fa fa-check"></i><b>7.5.3</b> Intervals</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#specifying-priors"><i class="fa fa-check"></i><b>7.6</b> Specifying priors</a></li>
<li class="chapter" data-level="7.7" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#decision-making"><i class="fa fa-check"></i><b>7.7</b> Decision making</a></li>
<li class="chapter" data-level="7.8" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#specifying-and-fitting-statistical-models-with-bayes"><i class="fa fa-check"></i><b>7.8</b> Specifying and fitting statistical models with Bayes</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#statistical-model-specification"><i class="fa fa-check"></i><b>7.8.1</b> Statistical model specification</a></li>
<li class="chapter" data-level="7.8.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#fitting-models-with-brms"><i class="fa fa-check"></i><b>7.8.2</b> Fitting models with <em>brms</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html"><i class="fa fa-check"></i><b>8</b> Bayesian Workflow</a>
<ul>
<li class="chapter" data-level="8.1" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-1-choose-an-appropriate-model-for-the-likelihood"><i class="fa fa-check"></i><b>8.1</b> Step 1: Choose an appropriate model for the likelihood</a></li>
<li class="chapter" data-level="8.2" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-2-decide-on-prior-distributions-for-each-parameter-in-the-likelihood"><i class="fa fa-check"></i><b>8.2</b> Step 2: Decide on prior distributions for each parameter in the likelihood</a></li>
<li class="chapter" data-level="8.3" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-3-prior-predictive-check"><i class="fa fa-check"></i><b>8.3</b> Step 3: Prior predictive check</a></li>
<li class="chapter" data-level="8.4" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-4-fit-the-statistical-model-with-the-observed-data"><i class="fa fa-check"></i><b>8.4</b> Step 4: Fit the statistical model with the observed data</a></li>
<li class="chapter" data-level="8.5" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-5-evaluating-and-applying-a-fitted-model"><i class="fa fa-check"></i><b>8.5</b> Step 5: Evaluating and applying a fitted model</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#a-quick-glance-at-the-estimates"><i class="fa fa-check"></i><b>8.5.1</b> A quick glance at the estimates</a></li>
<li class="chapter" data-level="8.5.2" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#checking-for-convergence"><i class="fa fa-check"></i><b>8.5.2</b> Checking for convergence</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#checking-the-shape-of-the-posterior-distribution"><i class="fa fa-check"></i><b>8.6</b> Checking the shape of the posterior distribution</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#inference-and-posterior-predictive-check"><i class="fa fa-check"></i><b>8.6.1</b> Inference and posterior predictive check</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#summary-1"><i class="fa fa-check"></i><b>8.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="the-linear-model.html"><a href="the-linear-model.html"><i class="fa fa-check"></i><b>9</b> The linear model</a>
<ul>
<li class="chapter" data-level="9.1" data-path="the-linear-model.html"><a href="the-linear-model.html#statistical-models"><i class="fa fa-check"></i><b>9.1</b> Statistical models</a></li>
<li class="chapter" data-level="9.2" data-path="the-linear-model.html"><a href="the-linear-model.html#linear-model"><i class="fa fa-check"></i><b>9.2</b> Linear model</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="the-linear-model.html"><a href="the-linear-model.html#basic-structure-of-the-linear-model"><i class="fa fa-check"></i><b>9.2.1</b> Basic structure of the linear model</a></li>
<li class="chapter" data-level="9.2.2" data-path="the-linear-model.html"><a href="the-linear-model.html#fitting-the-linear-model-in-brms"><i class="fa fa-check"></i><b>9.2.2</b> Fitting the linear model in brms</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="the-linear-model.html"><a href="the-linear-model.html#linear-models-with-categorical-predictors"><i class="fa fa-check"></i><b>9.3</b> Linear models with categorical predictors</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="the-linear-model.html"><a href="the-linear-model.html#binary-explanatory-variables"><i class="fa fa-check"></i><b>9.3.1</b> Binary explanatory variables</a></li>
<li class="chapter" data-level="9.3.2" data-path="the-linear-model.html"><a href="the-linear-model.html#categorical-predictors-with-more-than-two-categories"><i class="fa fa-check"></i><b>9.3.2</b> Categorical predictors with more than two categories</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html"><i class="fa fa-check"></i><b>10</b> Graphical Causal Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>10.1</b> Directed acyclic graphs (DAGs)</a></li>
<li class="chapter" data-level="10.2" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#three-causal-structures-in-dags"><i class="fa fa-check"></i><b>10.2</b> Three causal structures in DAGs</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-fork-confounders"><i class="fa fa-check"></i><b>10.2.1</b> The fork: confounders</a></li>
<li class="chapter" data-level="10.2.2" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-pipe-mediators"><i class="fa fa-check"></i><b>10.2.2</b> The pipe: mediators</a></li>
<li class="chapter" data-level="10.2.3" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-inverted-fork-colliders"><i class="fa fa-check"></i><b>10.2.3</b> The inverted fork: colliders</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#closing-backdoor-paths"><i class="fa fa-check"></i><b>10.3</b> Closing backdoor paths</a></li>
<li class="chapter" data-level="10.4" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#like-all-models-dags-require-assumptions"><i class="fa fa-check"></i><b>10.4</b> Like all models, DAGs require assumptions</a></li>
<li class="chapter" data-level="10.5" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#types-of-study-designs"><i class="fa fa-check"></i><b>10.5</b> Types of Study Designs</a></li>
<li class="chapter" data-level="10.6" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#experimental-studies"><i class="fa fa-check"></i><b>10.6</b> Experimental studies</a></li>
<li class="chapter" data-level="10.7" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#observational-studies"><i class="fa fa-check"></i><b>10.7</b> Observational studies</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#pros-and-cons-of-prospective-vs.-retrospective-studies-planned"><i class="fa fa-check"></i><b>10.7.1</b> Pros and cons of prospective vs. retrospective studies (planned)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html"><i class="fa fa-check"></i><b>11</b> Causal inference with linear models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#linear-models-with-multiple-predictor-variables"><i class="fa fa-check"></i><b>11.1</b> Linear models with multiple predictor variables</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#generic-linear-model-with-two-predictors"><i class="fa fa-check"></i><b>11.1.1</b> Generic linear model with two predictors</a></li>
<li class="chapter" data-level="11.1.2" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#multiple-regression-model-for-the-ice-cream-and-drownings-example"><i class="fa fa-check"></i><b>11.1.2</b> Multiple regression model for the ice cream and drownings example</a></li>
<li class="chapter" data-level="11.1.3" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#prior-predictive-check"><i class="fa fa-check"></i><b>11.1.3</b> Prior predictive check</a></li>
<li class="chapter" data-level="11.1.4" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#fitting-the-multiple-regression-model"><i class="fa fa-check"></i><b>11.1.4</b> Fitting the multiple regression model</a></li>
<li class="chapter" data-level="11.1.5" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#prediction-plots-for-multiple-regression-models"><i class="fa fa-check"></i><b>11.1.5</b> Prediction plots for multiple regression models</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#dag-informed-predictors-categorical-variables-what-multiple-regression-is-doing-with-predictor-residual-plot"><i class="fa fa-check"></i><b>11.2</b> DAG-informed predictors, categorical variables, what multiple regression is doing with predictor residual plot</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="interaction-effects.html"><a href="interaction-effects.html"><i class="fa fa-check"></i><b>12</b> Interaction effects</a></li>
<li class="chapter" data-level="13" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>13</b> Generalized linear models</a></li>
<li class="chapter" data-level="14" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>14</b> Multilevel models</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html"><i class="fa fa-check"></i><b>A</b> Estimation with frequentist inference</a>
<ul>
<li class="chapter" data-level="A.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#frequentist-estimates-are-point-estimates"><i class="fa fa-check"></i><b>A.1</b> Frequentist estimates are point estimates</a></li>
<li class="chapter" data-level="A.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions"><i class="fa fa-check"></i><b>A.2</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions-are-centered-on-the-true-parameter-value"><i class="fa fa-check"></i><b>A.2.1</b> Sampling distributions are centered on the true parameter value</a></li>
<li class="chapter" data-level="A.2.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions-allow-us-to-estimate-precision"><i class="fa fa-check"></i><b>A.2.2</b> Sampling distributions allow us to estimate precision</a></li>
<li class="chapter" data-level="A.2.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sample-size-affects-the-shape-of-sampling-distributions"><i class="fa fa-check"></i><b>A.2.3</b> Sample size affects the shape of sampling distributions</a></li>
<li class="chapter" data-level="A.2.4" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#summary-points-on-sampling-distributions"><i class="fa fa-check"></i><b>A.2.4</b> Summary points on sampling distributions</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#quantifying-uncertainty-standard-error-and-confidence-intervals"><i class="fa fa-check"></i><b>A.3</b> Quantifying uncertainty: standard error and confidence intervals</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#standard-error"><i class="fa fa-check"></i><b>A.3.1</b> Standard error</a></li>
<li class="chapter" data-level="A.3.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>A.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="A.3.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#the-standard-normal-approximation-does-not-work-well-under-low-sample-size"><i class="fa fa-check"></i><b>A.3.3</b> The standard normal approximation does not work well under low sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html"><i class="fa fa-check"></i><b>B</b> Decision-making with frequentist estimates</a>
<ul>
<li class="chapter" data-level="B.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#framework-of-classical-hypothesis-testing"><i class="fa fa-check"></i><b>B.1</b> Framework of classical hypothesis testing</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#state-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>B.1.1</b> State null and alternative hypotheses</a></li>
<li class="chapter" data-level="B.1.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#assume-the-null-hypothesis-is-true"><i class="fa fa-check"></i><b>B.1.2</b> Assume the null hypothesis is true</a></li>
<li class="chapter" data-level="B.1.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#quantify-the-likelihood-of-the-data-under-the-null-hypothesis-p-values"><i class="fa fa-check"></i><b>B.1.3</b> Quantify the likelihood of the data under the null hypothesis: P-values</a></li>
<li class="chapter" data-level="B.1.4" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#making-a-decision-based-on-the-p-value-and-significance-value"><i class="fa fa-check"></i><b>B.1.4</b> Making a decision based on the P-value and significance value</a></li>
<li class="chapter" data-level="B.1.5" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#decision-errors-happen"><i class="fa fa-check"></i><b>B.1.5</b> Decision errors happen</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#making-decisions-with-confidence-intervals"><i class="fa fa-check"></i><b>B.2</b> Making decisions with confidence intervals</a></li>
<li class="chapter" data-level="B.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#issues-with-the-null-hypothesis-framework"><i class="fa fa-check"></i><b>B.3</b> Issues with the null hypothesis framework</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#significance-testing-reinforces-binary-thinking"><i class="fa fa-check"></i><b>B.3.1</b> Significance testing reinforces binary thinking</a></li>
<li class="chapter" data-level="B.3.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#statistical-testing-reinforces-gamification-in-science"><i class="fa fa-check"></i><b>B.3.2</b> Statistical testing reinforces gamification in science</a></li>
<li class="chapter" data-level="B.3.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#statistical-significance-is-not-the-same-thing-as-practical-significance"><i class="fa fa-check"></i><b>B.3.3</b> Statistical significance is not the same thing as practical significance</a></li>
<li class="chapter" data-level="B.3.4" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#type-i-errors-become-more-likely-with-multiple-tests"><i class="fa fa-check"></i><b>B.3.4</b> Type I errors become more likely with multiple tests</a></li>
<li class="chapter" data-level="B.3.5" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-is-almost-certainly-wrong"><i class="fa fa-check"></i><b>B.3.5</b> The null hypothesis is almost certainly wrong</a></li>
<li class="chapter" data-level="B.3.6" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-focuses-on-data-you-did-not-observe"><i class="fa fa-check"></i><b>B.3.6</b> The null hypothesis focuses on data you did not observe</a></li>
<li class="chapter" data-level="B.3.7" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#a-single-null-and-alternative-hypothesis-is-too-constraining"><i class="fa fa-check"></i><b>B.3.7</b> A single null and alternative hypothesis is too constraining</a></li>
<li class="chapter" data-level="B.3.8" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-p-value-is-not-the-probability-we-want"><i class="fa fa-check"></i><b>B.3.8</b> The P-value is not the probability we want</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Research Design and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-linear-model" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> The linear model<a href="the-linear-model.html#the-linear-model" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<ul>
<li>change this chapter to use the BAC example in HW9</li>
</ul>
<p>Over the last few chapters we have examined the process of estimating unknown quantities from samples with frequentist and Bayesian inference. Sample estimates vary in their quality, and we’ve emphasized the importance of quantifying metrics of uncertainty for our estimates, such as credible or confidence intervals. To this point the quantities we have estimated are very simple, such as a single proportion or mean characterizing a population. But what happens when life isn’t so simple? What if we’re not simply interested in the prevalence of an infection in a single city, but rather variation in the prevalence of the infection among cities? What if the variation in the prevalence among cities is affected by population density?</p>
<p>The same reasoning applies to population means for continuous variables. Suppose you are a real estate broker, and you’re interested in the average price at which a home sells. It would be inadequate to estimate a single mean price for all homes, because you know home price is affected by a variety of factors, such as square footage. Thus, what you really need to do is estimate the mean home price at different levels of square footage.</p>
<p>In this chapter we will start developing a tool for situations like this where we want to link a mean (or a proportion) to other measurements. The tool we will use is the <strong>generalized linear model</strong>. The GLM is the powerhouse of statistical analysis. It’s flexible enough to allow us to estimate the simplest of quantities, such as a single mean or proportion, but also to link a response variable to other measurements. We can use GLMs to examine the relationship between two variables in a simple experiment, and we can use to examine the relaitonship between two variables while adjusting for other variables, often a necessity in observational designs. We can use the GLM for situations where we expect a relationship to be constant, or in situations where the relationship between variables depends on a third variable. The bottom line is that GLMs are extremely flexible, and as such, they will be the focus of the remainder of this book.</p>
<p>In light of the criticisms of frequentist inference with null hypothesis significance testing, all the examples in the remainder of the book will be presented initially with Bayesian estimation procedures. However, because students of statistics should know how to interpret studies using frequentist inference, each example will include a short “How a Frequentist Would Analyze It” section.</p>
<div id="statistical-models" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Statistical models<a href="the-linear-model.html#statistical-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The rest of this book is about designing statistical models to estimate quantities of interest. A <strong>model</strong> is just a simplified representation of some phenomenon of interest. We’ve already seen models in the form of DAGs, which represent our scientific model of how variables are causally related to each other. As scientific models, DAGs are largely conceptual in nature. Science is about confronting our ideas with data, and so we need a model to help us make that link. That’s where <strong>statistical models</strong> enter the picture. Statistical models are quantitative representations of our scientific models. They can consist of an equation, or a set of equations, that describe single variables, and more often in causal inference, the relationship between variables.</p>
<p>Let’s develop the idea of a statistical model with an example. In this chapter we will look at the the growth of perennial ryegrass, which is native to Europe and Asia but has been cultivated and introduced around the world. Ryegrass can be considered an invasive species in that it can outcompete native plants. We’re going to look at the growth rate of ryegrass as measured in the lab, using data from (<a href="https://doi.org/10.1034/j.1399-3054.2002.1140312.x">Inderjit et al. 2002</a>).</p>
<p>Let’s go ahead and load the data. This is actually only a subset of N = 9 observations. You’ll see there are two variables in the data frame, <code>conc</code> and <code>rootl</code>, and for now we’ll focus our attention on <code>rootl</code>, which is the root length of ryegrass measured in cm.</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="the-linear-model.html#cb269-1" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/ryegrass_sub.csv&quot;</span>)</span>
<span id="cb269-2"><a href="the-linear-model.html#cb269-2" tabindex="-1"></a><span class="fu">print</span>(d)</span></code></pre></div>
<pre><code>##      rootl conc
## 1 8.355556 0.94
## 2 6.914286 0.94
## 3 7.750000 0.94
## 4 6.871429 1.88
## 5 6.450000 1.88
## 6 5.922222 1.88
## 7 1.925000 3.75
## 8 2.885714 3.75
## 9 4.233333 3.75</code></pre>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="the-linear-model.html#cb271-1" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> d, <span class="fu">aes</span>(<span class="at">x =</span> rootl)) <span class="sc">+</span></span>
<span id="cb271-2"><a href="the-linear-model.html#cb271-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.5</span>, <span class="at">fill =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb271-3"><a href="the-linear-model.html#cb271-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Root length (cm)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Frequency&quot;</span>) <span class="sc">+</span></span>
<span id="cb271-4"><a href="the-linear-model.html#cb271-4" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c01"></span>
<img src="ch09_linearModels_files/figure-html/c09c01-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.1: TODO: caption.
</p>
</div>
<p>The histogram doesn’t tell us much with only nine observations, but we do know root length is a continuous random variable. Root length in this dataset is being used to measure the growth of ryegrass in the lab. Growth rates and plant size typically exhibit bell-shaped, approximately normal distributions. Indeed, any attribute that is influenced by many processes with non-trivial effects (e.g., many genes and environmental factors) tends to exhibit an approximately normal distribution. So we will generate a simple statistical model that describes root length with a normal distribution.</p>
<p>We will follow the approach outlined in McElreath (2020) to define statistical models, which involves:</p>
<ol style="list-style-type: decimal">
<li>Identify the observed variables. These are the data we collect from samples.</li>
<li>Identify the unobserved parameters. These are the unknown quantities we wish to estimate with the data.</li>
<li>Define how the observed data are generated. This can be a simple as defining a single variable as a random variable from a particular probaiblity distribution, or we can define variables in terms of other variables.</li>
<li>For Bayesian analysis, define our prior distributions for each unknown parameter.</li>
</ol>
<p>Let’s apply this to our ryegrass example. To start, we are simply describing the observed root length data as a random variable drawn from a normal distribution. The normal distribution has two parameters that we need to estimate: the mean and the standard deviation. Thus, in our model, we need a line to describe root length as a random variable, and two lines to define the prior distributions for each of the unknown parameters. Here’s the model we will use:</p>
<p><span class="math display">\[
\begin{array}{l}
r_i \sim \mathrm{Normal}(\mu, \sigma) \\
\mu \sim \mathrm{Normal}(5, 2) \\
\sigma \sim \mathrm{Uniform}(0, 5)
\end{array}
\]</span></p>
<p>Let’s walk through each line of our statistical model. First we have <span class="math inline">\(r_i \sim \mathrm{Normal}(\mu, \sigma)\)</span>. Here we are defining the observed values of root length for each individual <em>i</em> (<span class="math inline">\(r_i\)</span>) as a random variable following a normal distribution with parameters mean = <span class="math inline">\(\mu\)</span> and standard deviation = <span class="math inline">\(\sigma\)</span>. Remember the tilde symbol (~) defines a relationship as <strong>stochastic</strong>, which means that the observed values <span class="math inline">\(r_i\)</span> are probabalistic rather than being determiend with certainty. The normal distribution with its parameters defines the probability of drawing particulare values of root length. We don’t know what those parameter values are, so we will have to estimate them. In the context of Bayesian estimation, this line represents the likelihood.</p>
<p>The second and third lines are prior distributions. In Bayesian estimation, every parameter in the statistical model requires a prior. Even though we might be more interested in the mean root length than its variation, we’re assuming root length has a normal distribution, and the normal distibution has two parameters (mean and standard deviation). When we assume a variable is drawn from a particular probability distribution, we have to estimate the parmaeters for that probability distribution whether we want them or not. That’s why it’s useful to differentiate between types of parameters, the estimands being the parameters that we are most interested in.</p>
<p>Now consider what each prior distribution says. The first prior is for the mean root length: <span class="math inline">\(\mu \sim \mathrm{Normal}(5, 2)\)</span>. This defines the probability of the mean taking on different values with a normal distribution, specifically a normal distribution with a mean of 5 and standard deviation of 2. Effetively what this means is that - prior to analyzing the data - I think the most plausible values for the mean root lenght are around 5 cm. The mean could be greater or less than 5 cm, but 5 cm is the most likely value (as the mean of the normal distribution). Of course we can say exatly how likely the other values are. Following hte empricail rule, I’m assuming that there’s a 95% chance that the mean root length is between 1 and 9 cm. Values outside those bounds collectively have only a 5% probability.</p>
<p>How did I know to use those particular values for the normal prior (mean = 5, standard deviation = 2). This is where domain knowledge is helpful. Based on prior knowledge from people who have worked with ryegrass in this kind of experimental setting (growing plants in petri dishes), we know the mean root lengths are going to be relatively small, likely somewhere in the range of 0-10 cm. The values at the extremes of that range are much less likely than values in the middle - indeed, it’s not even possible to have a root length of 0 cm. The normal distribution captures that prior knowledge nicely (albeit imperfectly, as every model is imperfect).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c02"></span>
<img src="ch09_linearModels_files/figure-html/c09c02-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.2: TODO: caption.
</p>
</div>
<p>Remember that Bayesian inference combines the prior and likelihood to quantify the posterior distributions for each a parameter. We’re going to use <code>brms</code> to do just that, but before doing so, it can be very useful to do that’s called a <strong>prior predictive simulation</strong>. The idea is that we can use the prior distributions to simulate data to get a sense for what the prior distributions imply about what the data should look like. For the ryegrass example, the idea is to get a sense for the different possible combinations of the mean and standard deviation of root length, and the resulting distribution of root length implied by the priors:</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="the-linear-model.html#cb272-1" tabindex="-1"></a><span class="co">#from https://bookdown.org/content/4857/geocentric-models.html#a-language-for-describing-models</span></span>
<span id="cb272-2"><a href="the-linear-model.html#cb272-2" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb272-3"><a href="the-linear-model.html#cb272-3" tabindex="-1"></a></span>
<span id="cb272-4"><a href="the-linear-model.html#cb272-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb272-5"><a href="the-linear-model.html#cb272-5" tabindex="-1"></a></span>
<span id="cb272-6"><a href="the-linear-model.html#cb272-6" tabindex="-1"></a><span class="co">#randomly draw means from the prior</span></span>
<span id="cb272-7"><a href="the-linear-model.html#cb272-7" tabindex="-1"></a>mu.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb272-8"><a href="the-linear-model.html#cb272-8" tabindex="-1"></a></span>
<span id="cb272-9"><a href="the-linear-model.html#cb272-9" tabindex="-1"></a><span class="co">#randomly draw SDs from the prior</span></span>
<span id="cb272-10"><a href="the-linear-model.html#cb272-10" tabindex="-1"></a>sigma.sim <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">5</span>)</span>
<span id="cb272-11"><a href="the-linear-model.html#cb272-11" tabindex="-1"></a></span>
<span id="cb272-12"><a href="the-linear-model.html#cb272-12" tabindex="-1"></a><span class="co">#randomly draw values of root length from the combined means and SDs</span></span>
<span id="cb272-13"><a href="the-linear-model.html#cb272-13" tabindex="-1"></a>r.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu.sim, <span class="at">sd =</span> sigma.sim)</span>
<span id="cb272-14"><a href="the-linear-model.html#cb272-14" tabindex="-1"></a></span>
<span id="cb272-15"><a href="the-linear-model.html#cb272-15" tabindex="-1"></a><span class="co">#plot the simulated root lenth distribution</span></span>
<span id="cb272-16"><a href="the-linear-model.html#cb272-16" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">r.sim =</span> r.sim)</span>
<span id="cb272-17"><a href="the-linear-model.html#cb272-17" tabindex="-1"></a></span>
<span id="cb272-18"><a href="the-linear-model.html#cb272-18" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> r.sim)) <span class="sc">+</span></span>
<span id="cb272-19"><a href="the-linear-model.html#cb272-19" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;darkblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb272-20"><a href="the-linear-model.html#cb272-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Implied distribution of root length from priors&quot;</span>,</span>
<span id="cb272-21"><a href="the-linear-model.html#cb272-21" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Root length (cm)&quot;</span>,</span>
<span id="cb272-22"><a href="the-linear-model.html#cb272-22" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb272-23"><a href="the-linear-model.html#cb272-23" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c03"></span>
<img src="ch09_linearModels_files/figure-html/c09c03-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.3: TODO: caption.
</p>
</div>
<p>We can see the distribution of root length implied by the priors has a mean right around 5 cm as expected, so that’s good. But what’s not good is that the variation around that mean is unrealistic. The priors are implying a non-trivial chance of seeing root lengths that are 0 or negative! Good thing we did this prior predictive simulation. This is exactly why you’d do such a thing; to see if the priors you assumed are realistic. Clearly the priors we’re using can be improved. Let’s tighten things up with a revised statsitical model:</p>
<p><span class="math display">\[
\begin{array}{l}
r_i \sim \mathrm{Normal}(\mu, \sigma) \\
\mu \sim \mathrm{Normal}(5, 1) \\
\sigma \sim \mathrm{Uniform}(0, 3)
\end{array}
\]</span></p>
<p>Do you see what changed? The normal prior for the mean now implies a 95% chance of the mean being 3-7 cm, and we’ve reduced the upper bound of the standard deviation from 5 cm to 3 cm. Let’s see if that implies a more realistic distribution of heights:</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="the-linear-model.html#cb273-1" tabindex="-1"></a><span class="co">#from https://bookdown.org/content/4857/geocentric-models.html#a-language-for-describing-models</span></span>
<span id="cb273-2"><a href="the-linear-model.html#cb273-2" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb273-3"><a href="the-linear-model.html#cb273-3" tabindex="-1"></a></span>
<span id="cb273-4"><a href="the-linear-model.html#cb273-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb273-5"><a href="the-linear-model.html#cb273-5" tabindex="-1"></a></span>
<span id="cb273-6"><a href="the-linear-model.html#cb273-6" tabindex="-1"></a><span class="co">#randomly draw means from the prior</span></span>
<span id="cb273-7"><a href="the-linear-model.html#cb273-7" tabindex="-1"></a>mu.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb273-8"><a href="the-linear-model.html#cb273-8" tabindex="-1"></a></span>
<span id="cb273-9"><a href="the-linear-model.html#cb273-9" tabindex="-1"></a><span class="co">#randomly draw SDs from the prior</span></span>
<span id="cb273-10"><a href="the-linear-model.html#cb273-10" tabindex="-1"></a>sigma.sim <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">3</span>)</span>
<span id="cb273-11"><a href="the-linear-model.html#cb273-11" tabindex="-1"></a></span>
<span id="cb273-12"><a href="the-linear-model.html#cb273-12" tabindex="-1"></a><span class="co">#randomly draw values of root length from the combined means and SDs</span></span>
<span id="cb273-13"><a href="the-linear-model.html#cb273-13" tabindex="-1"></a>r.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu.sim, <span class="at">sd =</span> sigma.sim)</span>
<span id="cb273-14"><a href="the-linear-model.html#cb273-14" tabindex="-1"></a></span>
<span id="cb273-15"><a href="the-linear-model.html#cb273-15" tabindex="-1"></a><span class="co">#plot the simulated root lenth distribution</span></span>
<span id="cb273-16"><a href="the-linear-model.html#cb273-16" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">r.sim =</span> r.sim)</span>
<span id="cb273-17"><a href="the-linear-model.html#cb273-17" tabindex="-1"></a></span>
<span id="cb273-18"><a href="the-linear-model.html#cb273-18" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> r.sim)) <span class="sc">+</span></span>
<span id="cb273-19"><a href="the-linear-model.html#cb273-19" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;darkblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb273-20"><a href="the-linear-model.html#cb273-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Implied distribution of root length from priors&quot;</span>,</span>
<span id="cb273-21"><a href="the-linear-model.html#cb273-21" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Root length (cm)&quot;</span>,</span>
<span id="cb273-22"><a href="the-linear-model.html#cb273-22" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb273-23"><a href="the-linear-model.html#cb273-23" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c04"></span>
<img src="ch09_linearModels_files/figure-html/c09c04-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.4: TODO: caption.
</p>
</div>
<p>There are still some negative values implied by the priors, but now they are quite rare. One of the reasons we continue to see some very small proportion of negative root lengths is that we’re assuming a normal distribution for root length, and the normal distribution can have negative values. As we’ll see later in the book, there are other probability distributions that may be more effective. In this case, it would be helpful to use a probability distribution that has a bell-shaped curve, but that does not allow negative values. Stay tuned. For now, this prior distribution will suffice. Let’s proceed with estimation in <code>brms</code>:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="the-linear-model.html#cb274-1" tabindex="-1"></a><span class="co">#specify model formula</span></span>
<span id="cb274-2"><a href="the-linear-model.html#cb274-2" tabindex="-1"></a>m1.formula <span class="ot">&lt;-</span> <span class="fu">bf</span>(rootl <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb274-3"><a href="the-linear-model.html#cb274-3" tabindex="-1"></a>                <span class="at">family =</span> gaussian) <span class="co">#defines root length as a normal random var</span></span>
<span id="cb274-4"><a href="the-linear-model.html#cb274-4" tabindex="-1"></a></span>
<span id="cb274-5"><a href="the-linear-model.html#cb274-5" tabindex="-1"></a><span class="co">#specify priors</span></span>
<span id="cb274-6"><a href="the-linear-model.html#cb274-6" tabindex="-1"></a>m1.prior <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">5</span>, <span class="dv">1</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb274-7"><a href="the-linear-model.html#cb274-7" tabindex="-1"></a>             <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">3</span>), <span class="at">class =</span> sigma, <span class="at">lb=</span><span class="dv">0</span>, <span class="at">ub=</span><span class="dv">3</span>))</span>
<span id="cb274-8"><a href="the-linear-model.html#cb274-8" tabindex="-1"></a>              </span>
<span id="cb274-9"><a href="the-linear-model.html#cb274-9" tabindex="-1"></a><span class="co">#compute the posterior</span></span>
<span id="cb274-10"><a href="the-linear-model.html#cb274-10" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">brm</span>(<span class="at">data =</span> d,</span>
<span id="cb274-11"><a href="the-linear-model.html#cb274-11" tabindex="-1"></a>         <span class="at">formula =</span> m1.formula,</span>
<span id="cb274-12"><a href="the-linear-model.html#cb274-12" tabindex="-1"></a>         <span class="at">prior =</span> m1.prior,</span>
<span id="cb274-13"><a href="the-linear-model.html#cb274-13" tabindex="-1"></a>         <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb274-14"><a href="the-linear-model.html#cb274-14" tabindex="-1"></a>         <span class="at">seed=</span><span class="dv">123</span>)</span>
<span id="cb274-15"><a href="the-linear-model.html#cb274-15" tabindex="-1"></a></span>
<span id="cb274-16"><a href="the-linear-model.html#cb274-16" tabindex="-1"></a><span class="fu">print</span>(m1)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity 
## Formula: rootl ~ 1 
##    Data: d (Number of observations: 9) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Regression Coefficients:
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     5.45      0.59     4.28     6.63 1.00     2069     1990
## 
## Further Distributional Parameters:
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     2.25      0.40     1.51     2.94 1.00     1568     1287
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Let’s walk through this. We’ve defined the likelihood with the <code>bf</code> function, where the formula <code>rootl ~ 1</code> tells <code>brms</code> that we want to fit a model with only an intercept, which in this case is a fancy way of saying we want the overall meam (this will make more sense later this chapter!). We’re assuming <code>rootl</code> is a normal random variable with <code>family = gaussian</code>. We then define our priors. In <code>brms</code>, each parameter getting a prior needs a distribution for the prior (<code>normal</code> for the mean, <code>uniform</code> for the stanard deviation in this case), and we specify the type of parameter with the <code>class</code> argument, here being an <code>Intercept</code> for the mean and <code>sigma</code> for the standard deviation. After fitting this model, we see the mean of the posterior distribution for root length is 5.45, and the 95% credible interval is 4.28-6.63. In other words, there’s a 95% probability that the mean root length is between 4.28 and 6.63. We can execute the <code>plot</code> function on our model object to see a graph of the posterior distributions and a plot that helps us diagnose whether the model is converged:</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="the-linear-model.html#cb276-1" tabindex="-1"></a><span class="fu">plot</span>(m1)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c06"></span>
<img src="ch09_linearModels_files/figure-html/c09c06-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.5: TODO: caption.
</p>
</div>
<p>The left panel shows the posterior distributions for the mean (<code>b_Intercept</code>) and standard deviation (<code>sigma</code>) parameters, and the right side of the panel shows <strong>trace plots</strong> for each panel. Trace plots allow you to view the value of each parameter for each iteration of the model in each chain. What we’re looking for here is relative consistency in the parameter values among the chains, that is <strong>convergence</strong> of the parameter values. These trace plots indicate solid convergence because the values for each chain overlap extensively and hover around a common value. Numerically, the <code>Rhat</code> values near 1 also indicate convergence.</p>
<p>Remember that we can also draw samples from the posterior distribution to compute any quantity of interest. For example, suppose we want to estimate the probability that the mean root length is greater than 5 cm. We just need to extract the samples from the posterior and find the proportion of values greater than 5 for the mean:</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="the-linear-model.html#cb277-1" tabindex="-1"></a><span class="co">#posterior samples</span></span>
<span id="cb277-2"><a href="the-linear-model.html#cb277-2" tabindex="-1"></a>m1.post <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">as_draws_df</span>(m1))</span>
<span id="cb277-3"><a href="the-linear-model.html#cb277-3" tabindex="-1"></a><span class="fu">head</span>(m1.post)</span></code></pre></div>
<pre><code>##   b_Intercept    sigma Intercept    lprior      lp__ .chain .iteration .draw
## 1    5.051680 2.925563  5.051680 -2.018886 -25.07558      1          1     1
## 2    4.882915 2.430660  4.882915 -2.024405 -22.87511      1          2     2
## 3    5.939409 1.763796  5.939409 -2.458796 -22.51164      1          3     3
## 4    5.695199 2.873104  5.695199 -2.259202 -24.50022      1          4     4
## 5    6.694626 2.061946  6.694626 -3.453430 -24.31155      1          5     5
## 6    6.645777 2.094947  6.645777 -3.371841 -24.11954      1          6     6</code></pre>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="the-linear-model.html#cb279-1" tabindex="-1"></a><span class="co">#probability that the proportion infected is greater than 10%</span></span>
<span id="cb279-2"><a href="the-linear-model.html#cb279-2" tabindex="-1"></a><span class="fu">mean</span>(m1.post<span class="sc">$</span>b_Intercept <span class="sc">&gt;</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>## [1] 0.77825</code></pre>
<p>We see there’s a 78% chance that the mean root length is &gt;5 cm.</p>
</div>
<div id="linear-model" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Linear model<a href="the-linear-model.html#linear-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="basic-structure-of-the-linear-model" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Basic structure of the linear model<a href="the-linear-model.html#basic-structure-of-the-linear-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As it turns out, the researchers who generated the data we just analyzed were not simply interested in describing the mean growth rate of ryegrass. Because ryegrass can be invasive, they were interested in understanding the effect of a new herbicide on ryegrass growth. Each petri dish with ryegrass was randomly assigned an herbicide concentration, and they measured root length as an index of plant growth. This is a simple experimental design in which all other resource levels were controlled (e.g., water, light, nutrients). Because there were no concerns about post-treatment bias (e.g., non-random dropout), we can represent the scientific model with a simple DAG:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c08"></span>
<img src="ch09_linearModels_files/figure-html/c09c08-1.png" alt="Initial DAG for the causal effect of greenspace on mental health." width="288" />
<p class="caption">
Figure 9.6: Initial DAG for the causal effect of greenspace on mental health.
</p>
</div>
<p>Recall that our DAG is a scientific model of factors affecting root length. Like any model, it’s a simplified representation of the system in that we are proposing the only non-trivial cause of root length variation is herbicide concentration. In reality we know there are plenty of other factors that affect plant growth - water, light, nutrients, etc. Those factors were controlled in this experiment, such that the different petri dishes were assigned identical levels of resources regardless of herbicide concentration. Because of measurement error, the resource levels won’t be perfectly identical. Some petri dishes will inevitably receive a few microliters more or less of water, for example. That variation may well affect root length, but because the impact is expected to be so miniscule, we leave causes like that out of the DAG. Again, models are simplified representations of reality.</p>
<p>Given our scientific model, how should we analyze the data? We need a statistical model that captures the nature of the relationship between root length and herbicide concentration. As we saw in Chapter 3, when we have two variables that are quantitative, we can use a scatterplot to visualize the association between those variables. Let’s start there:</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="the-linear-model.html#cb281-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb281-2"><a href="the-linear-model.html#cb281-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb281-3"><a href="the-linear-model.html#cb281-3" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb281-4"><a href="the-linear-model.html#cb281-4" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb281-5"><a href="the-linear-model.html#cb281-5" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb281-6"><a href="the-linear-model.html#cb281-6" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb281-7"><a href="the-linear-model.html#cb281-7" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb281-8"><a href="the-linear-model.html#cb281-8" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c09"></span>
<img src="ch09_linearModels_files/figure-html/c09c09-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.7: TODO: caption.
</p>
</div>
<p>We can see there were three levels of herbicide concentration assigned to three replicates for nine total observations. Visually it looks like there is a negative relationship between root length and herbicide concentration, root length decreases as herbicide concentration increases. We need a statistical model to estimate that association. Linear models are extremely useful for this task.</p>
<p>In our initial statistical model, we assumed that the root length values were drawn from a common normal distribution with a single mean and standard deviation. The scatterplot above suggests that’s not a good assumption. It looks like the average root length is high when little herbicide is applied, whereas average root length is high when a lot of herbicide is applied. We need a statistical model that allows the root length values to be drawn from distributions that have different means, where the mean root length depends on the herbicide concentration. Let’s revise the statistical model to do just that:</p>
<p><span class="math display">\[
\begin{array}{l}
r_i \sim \mathrm{Normal}(\mu_i, \sigma) \\
\mu_i = \alpha + \beta x_i \\
\alpha \sim \mathrm{Normal}(5, 2) \\
\beta \sim \mathrm{Normal}(0, 1) \\
\sigma \sim \mathrm{Uniform}(0, 3)
\end{array}
\]</span></p>
<p>Again let’s walk through the components:</p>
<ul>
<li><p><strong>Likelihood</strong> (<span class="math inline">\(r_i \sim \mathrm{Normal}(\mu_i, \sigma)\)</span>: Remember the likelihood is simply the probability of the data given the parameter values. How likely are the observed root length values given the mean and standard deviation for the ryegrass distribution? But there’s one big change here. Did you notice the mean parameter now has a subscript (<em>i)</em>? Rather than assuming we have a single normal distribution that describes all the root length values, we’re now saying that the observed root length for individual <em>i</em> is drawn from a unique normal distribution with its own mean.</p></li>
<li><p><strong>Linear model</strong> (<span class="math inline">\(\mu_i = \alpha + \beta x_i\)</span>): Our first linear model! This model defines how the unique mean for each individual <em>i</em> is determined. The model says the mean root length for each individual <em>i</em> is a linear function of two parameters: an intercept (<span class="math inline">\(\alpha\)</span>) and a slope (<span class="math inline">\(\beta\)</span>). You might remember from basic algebra that a line is defined by a simple equation <span class="math inline">\(y = mx + b\)</span>. That’s exactly what we have here, just with different labels for the parameters. What is each component of the linear model saying? The slope (<span class="math inline">\(\beta\)</span>) represents the expected change in the mean root length (<span class="math inline">\(\mu_i\)</span>) for each 1-unit change in <span class="math inline">\(x_i\)</span>. The value <span class="math inline">\(x_i\)</span> here represents the herbicide concentration that each individual <em>i</em> receives. Thus, the slope represents the expected change in the mean root length when the herbicide concentration increases by 1 mM. The intercept (<span class="math inline">\(\alpha\)</span>) represents the expected mean root length when the herbicide concentration is 0. That should make sense. When <span class="math inline">\(x_i=0\)</span>, the slope term in the linear model simply drops out, leaving just the intercept. Together, the intercept and slope determine the mean root length for the distributions from which each observed root length <em>i</em> is drawn.</p></li>
<li><p><strong>Priors:</strong> Remember that each parameter in a statistical model must have a prior distribution, reflecting our belief about the possible values of those parameters prior to analyzing the data. We may not be interested in all the parameters in the model. If our research question is whether the herbicide affects root length, the estimand is the slope (<span class="math inline">\(\beta\)</span>), but we still need to estimate the other parameters to estimate the slope. Let’s walk through the prior for each parameter:</p>
<ul>
<li><p><strong>Intercept</strong> (<span class="math inline">\(\alpha\)</span>): Here we are specifying a normal prior for the intercept with a mean of 5 and standard deviation of 2. That reflects our prior belief that there’s a 95% probability the mean root length is between 1 and 10 cm when there’s no herbicide applied. In this case we increased the standard deviation of the prior back from 1 to 2 to allow for a wider prior distribution given that we are no longer estimating the grand mean, but the mean when no herbicide is applied.</p></li>
<li><p><strong>Slope</strong> (<span class="math inline">\(\beta\)</span>): What is the expected change in mean root length with a 1 mM increase in herbicide concentration? Our normal prior with mean = 0 and standard deviation = 1 implies that the most likely value of the slope is 0, and there’s a 95% chance that the change in root length is between -2 and 2 cm as herbicide concentration increases by 1 mM. Biologically, the researchers very likely expect the root length will decrease as herbicide concentration increases. If much of literature supports such a negative effect, then it may be wise to use a prior that has more probability weighted towards negative effects. On the other hand, this is a new herbicide, and there’s a question about whether it works, so it’s possible that there’s no effect. Given that possibility, we choose to center the prior around 0. Even if we center the prior for the slope around 0, we would still want to use an appropriate standard deviation to limit the range of slopes to values we think are realistic. For example, it wouldn’t make sense to allow for a slope that allows a 100-cm change in root length per one unit increase in mM, when the range in root length values is 0-20 cm. So we restrict the variance in the prior distribution to a range of effect we think is plausible.</p></li>
<li><p><strong>Standard deviation</strong> (<span class="math inline">\(\sigma\)</span>). The standard deviation represents the expected variation in root length values around the expected mean. Any deviation in root length from the expected mean predicted by herbicide concentration represents variation that can’t be explained by herbicide concentration. For example, imagine the expected mean root length is 4 cm when the herbicide concentration is 1 mM. Not every plant with 1 mM herbicide applied will have exactly 4 cm root length. There will be deviations around the expected mean of 4 cm. Those deviations are called <strong>residual errors</strong> (or just “residuals”). Residual variation is always expected in systems that have multiple causes. Some of the variation around the expected mean based on herbicide concentration could be due to minor variation in water, light availability, or other resources. Some of the residual variation may simply be measurement error, and some may simply be random, not having obvious causes). The standard deviation parameter specifies the expected magnitude of the variation in observed root length round the expected mean based on herbicide concentration. Because there’s no <em>i</em> subscript on teh standard deviation, we’re assuming a common magnitude of residual error no matter what the mean root length may be. In this case, we’ve retained the same uniform prior distribution that we used in our more simple analysis that assumed a common normal distribution for all values of root length.</p></li>
</ul></li>
</ul>
</div>
<div id="fitting-the-linear-model-in-brms" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Fitting the linear model in brms<a href="the-linear-model.html#fitting-the-linear-model-in-brms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s go ahead and use a prior predictive simulation to see what the priors imply about the relationship between root length and herbicide concentration. Here all we do is simulate values of the intercept and slope from the priors, then plot them. I’ve limited the number of simulations to N = 100 to ensure that we can visualize the lines in the resulting graph.</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="the-linear-model.html#cb282-1" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb282-2"><a href="the-linear-model.html#cb282-2" tabindex="-1"></a></span>
<span id="cb282-3"><a href="the-linear-model.html#cb282-3" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb282-4"><a href="the-linear-model.html#cb282-4" tabindex="-1"></a></span>
<span id="cb282-5"><a href="the-linear-model.html#cb282-5" tabindex="-1"></a><span class="co">#intercept</span></span>
<span id="cb282-6"><a href="the-linear-model.html#cb282-6" tabindex="-1"></a>alpha.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb282-7"><a href="the-linear-model.html#cb282-7" tabindex="-1"></a></span>
<span id="cb282-8"><a href="the-linear-model.html#cb282-8" tabindex="-1"></a><span class="co">#slope</span></span>
<span id="cb282-9"><a href="the-linear-model.html#cb282-9" tabindex="-1"></a>beta.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb282-10"><a href="the-linear-model.html#cb282-10" tabindex="-1"></a></span>
<span id="cb282-11"><a href="the-linear-model.html#cb282-11" tabindex="-1"></a><span class="co">#values of x (herbicide concentration)</span></span>
<span id="cb282-12"><a href="the-linear-model.html#cb282-12" tabindex="-1"></a>x_vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb282-13"><a href="the-linear-model.html#cb282-13" tabindex="-1"></a></span>
<span id="cb282-14"><a href="the-linear-model.html#cb282-14" tabindex="-1"></a><span class="co"># Create a data frame with all lines</span></span>
<span id="cb282-15"><a href="the-linear-model.html#cb282-15" tabindex="-1"></a>lines_df <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">x =</span> x_vals, <span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span>n) <span class="sc">%&gt;%</span></span>
<span id="cb282-16"><a href="the-linear-model.html#cb282-16" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> alpha.sim[id] <span class="sc">+</span> beta.sim[id] <span class="sc">*</span> x)</span>
<span id="cb282-17"><a href="the-linear-model.html#cb282-17" tabindex="-1"></a></span>
<span id="cb282-18"><a href="the-linear-model.html#cb282-18" tabindex="-1"></a><span class="co"># Plot using ggplot</span></span>
<span id="cb282-19"><a href="the-linear-model.html#cb282-19" tabindex="-1"></a><span class="fu">ggplot</span>(lines_df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">group =</span> id)) <span class="sc">+</span></span>
<span id="cb282-20"><a href="the-linear-model.html#cb282-20" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span>  <span class="co"># Adjust transparency and color</span></span>
<span id="cb282-21"><a href="the-linear-model.html#cb282-21" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb282-22"><a href="the-linear-model.html#cb282-22" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb282-23"><a href="the-linear-model.html#cb282-23" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Root length (cm)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb282-24"><a href="the-linear-model.html#cb282-24" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c10"></span>
<img src="ch09_linearModels_files/figure-html/c09c10-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.8: TODO: caption.
</p>
</div>
<p>The graph of the prior predictive simulations shows the priors allow for both positive and negative relationships between root length and herbicide concentration. The priors also allow for a range in the expected rooth length when the herbicide concentration is 0 (the intercept). One thing I don’t like about these priors is that in some simulations they allow for relationships with negative expected values of root length, which of course is not possible. But the vast majority of the simulations appear realistic, and for our purposes this is sufficient to combine with the data to estimate the posterior.</p>
<p>To estimate the posterior in <code>brms</code>, we need to use the formula to specify the linear model. The formula we’ll use here is <code>rootl ~ 1 + conc</code>, where <code>1</code> represents the intercept, and <code>conc</code> represents the slope for the effect of herbicide concentration. We use the <code>+</code> operator to add the slope for <code>conc</code> to the model. Then we just need to make sure each parameter has a prior. Slope parameters are denoted <code>class = b</code> when defining priors in <code>brms</code>. Here’s the code to estimate the posterior:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="the-linear-model.html#cb283-1" tabindex="-1"></a><span class="co">#specify model formula</span></span>
<span id="cb283-2"><a href="the-linear-model.html#cb283-2" tabindex="-1"></a>m2.formula <span class="ot">&lt;-</span> <span class="fu">bf</span>(rootl <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> conc,</span>
<span id="cb283-3"><a href="the-linear-model.html#cb283-3" tabindex="-1"></a>                <span class="at">family =</span> gaussian) <span class="co">#defines root length as a normal random var</span></span>
<span id="cb283-4"><a href="the-linear-model.html#cb283-4" tabindex="-1"></a></span>
<span id="cb283-5"><a href="the-linear-model.html#cb283-5" tabindex="-1"></a><span class="co">#specify priors</span></span>
<span id="cb283-6"><a href="the-linear-model.html#cb283-6" tabindex="-1"></a>m2.prior <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">5</span>, <span class="dv">2</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb283-7"><a href="the-linear-model.html#cb283-7" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> b),</span>
<span id="cb283-8"><a href="the-linear-model.html#cb283-8" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">3</span>), <span class="at">class =</span> sigma, <span class="at">lb=</span><span class="dv">0</span>, <span class="at">ub=</span><span class="dv">3</span>))</span>
<span id="cb283-9"><a href="the-linear-model.html#cb283-9" tabindex="-1"></a>              </span>
<span id="cb283-10"><a href="the-linear-model.html#cb283-10" tabindex="-1"></a><span class="co">#compute the posterior</span></span>
<span id="cb283-11"><a href="the-linear-model.html#cb283-11" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">brm</span>(<span class="at">data =</span> d,</span>
<span id="cb283-12"><a href="the-linear-model.html#cb283-12" tabindex="-1"></a>         <span class="at">formula =</span> m2.formula,</span>
<span id="cb283-13"><a href="the-linear-model.html#cb283-13" tabindex="-1"></a>         <span class="at">prior =</span> m2.prior,</span>
<span id="cb283-14"><a href="the-linear-model.html#cb283-14" tabindex="-1"></a>         <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb283-15"><a href="the-linear-model.html#cb283-15" tabindex="-1"></a>         <span class="at">seed=</span><span class="dv">123</span>)</span>
<span id="cb283-16"><a href="the-linear-model.html#cb283-16" tabindex="-1"></a></span>
<span id="cb283-17"><a href="the-linear-model.html#cb283-17" tabindex="-1"></a><span class="fu">print</span>(m2)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity 
## Formula: rootl ~ 1 + conc 
##    Data: d (Number of observations: 9) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Regression Coefficients:
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     9.05      0.74     7.32    10.36 1.00     2046     1725
## conc         -1.54      0.30    -2.06    -0.86 1.00     2056     1547
## 
## Further Distributional Parameters:
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.00      0.36     0.55     1.93 1.00     1615     1636
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>How do we interpret the output? Remember that the summary for <code>brms</code> models shows the mean (<code>Estimate</code>), standard deviation (<code>Est.Error</code>) and 95% credible interval (<code>l-95% CI</code> and <code>u-95% CI</code>) for each parameter. We’re also given metrics to evaluate whether the parameters have converged to consistent values, an <code>Rhat</code> near 1 implying convergence. Based on the summary output, we can see the mean of the posterior for the intercept is 9.05, implying the most likely value of root length is 9.05 cm when no herbicide is applied. The line for <code>conc</code> supplies summary statistics for the slope for the effect of herbicide concentration on root length. We see the most likely value is -1.54, implying that for every one unit increase in herbicide concentration, root length declines by 1.54 cm on average. Notably the 95% credible interval is (-2.06, -0.86), suggesting the posterior distribution for the slope is broadly negative. We can confirm as much by plotting the posterior distributions:</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="the-linear-model.html#cb285-1" tabindex="-1"></a><span class="fu">plot</span>(m2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c12"></span>
<img src="ch09_linearModels_files/figure-html/c09c12-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.9: TODO: caption.
</p>
</div>
<p>Indeed, we see a posterior distribution that is entirely negative for the slope. This is strong evidence that the herbicide has a negative effect on root length, and that the suppression of plant growth increases with increasing herbicide concentration. We can also see from the traceplots that there is excellent convergence of the three parameters in our model (the third being the residual error).</p>
<p>Plots of the posterior distributions and tables summarizing those posterior distributions are helpful for summarizing the output for simple models like ours. But usually it’s even more helpful to visualize the output of our model graphically. Our primary interest is in the relationship between root length and herbicide concentration, so we should make a plot that shows what the posterior distribution implies about that relationship. Lets re-create our scatterplot for root length and herbicide concentration, but now we’ll add a line to the graph representing the association between root length and herbicide based on the posterior means. To do so, we’re going to first use the <code>fitted</code> function to predict the expected values of root length for different values of herbicide concentration. Let’s start with that:</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="the-linear-model.html#cb286-1" tabindex="-1"></a><span class="co">#values of herbicide concentration for which to predict root length</span></span>
<span id="cb286-2"><a href="the-linear-model.html#cb286-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(d<span class="sc">$</span>conc), <span class="fu">max</span>(d<span class="sc">$</span>conc), <span class="at">length.out=</span><span class="dv">100</span>)</span>
<span id="cb286-3"><a href="the-linear-model.html#cb286-3" tabindex="-1"></a></span>
<span id="cb286-4"><a href="the-linear-model.html#cb286-4" tabindex="-1"></a><span class="co">#predict values of root length for each value of herbicide</span></span>
<span id="cb286-5"><a href="the-linear-model.html#cb286-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">fitted</span>(m2, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">conc =</span> x))</span>
<span id="cb286-6"><a href="the-linear-model.html#cb286-6" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">conc =</span> x, y)</span>
<span id="cb286-7"><a href="the-linear-model.html#cb286-7" tabindex="-1"></a><span class="fu">head</span>(fit)</span></code></pre></div>
<pre><code>##        conc Estimate Est.Error     Q2.5    Q97.5
## 1 0.9400000 7.598360 0.5021902 6.480100 8.530201
## 2 0.9683838 7.554646 0.4959052 6.456589 8.478159
## 3 0.9967677 7.510932 0.4896868 6.433725 8.428845
## 4 1.0251515 7.467218 0.4835377 6.410807 8.375627
## 5 1.0535354 7.423504 0.4774606 6.383898 8.315237
## 6 1.0819192 7.379791 0.4714582 6.354950 8.265914</code></pre>
<p>What is the <code>fitted</code> function doing? It’s taking each value of <code>x</code> and plugging it into the linear model formula to compute the expected mean root length. For example, when herbicide concentration is <span class="math inline">\(x = 0.94\)</span>, the expected mean root length is <span class="math inline">\(y = 9.05 - 1.54*0.94 = 7.6\)</span> based on the posterior mean for the intercept (9.05) and slope (-1.54). But remember with Bayesian inference the estimate is not a single point, but an entire distribution. The <code>fitted</code> function computes the expected mean root length from the values of <span class="math inline">\(x\)</span> across every sample for the posterior distribution, and it provides summary statistics of the variation around the posterior mean, namely the standard deviation (<code>Est.Error</code>) and a 95% credible interval (<code>Q2.5</code> and <code>Q97.5</code>).</p>
<p>Now let’s make our scatterplot and add the posterior mean predictions. All we do here is take the code for our original scatterplot, and we add the function <code>geom_line</code> to add the prediction line:</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="the-linear-model.html#cb288-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb288-2"><a href="the-linear-model.html#cb288-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb288-3"><a href="the-linear-model.html#cb288-3" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> fit, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> Estimate)) <span class="sc">+</span></span>
<span id="cb288-4"><a href="the-linear-model.html#cb288-4" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb288-5"><a href="the-linear-model.html#cb288-5" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb288-6"><a href="the-linear-model.html#cb288-6" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb288-7"><a href="the-linear-model.html#cb288-7" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb288-8"><a href="the-linear-model.html#cb288-8" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb288-9"><a href="the-linear-model.html#cb288-9" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c14"></span>
<img src="ch09_linearModels_files/figure-html/c09c14-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.10: TODO: caption.
</p>
</div>
<p>It’s worth bearing in mind that this prediction line represents the posterior mean, so it doesn’t communicate the uncertainty about our estimate. To see what I mean, let’s add prediction lines for a selection of the posterior samples to get a sense for the variation To do so, we need to first extract the samples with <code>as_draws_df</code>:</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="the-linear-model.html#cb289-1" tabindex="-1"></a>m2.post <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(m2)</span>
<span id="cb289-2"><a href="the-linear-model.html#cb289-2" tabindex="-1"></a><span class="fu">head</span>(m2.post)</span></code></pre></div>
<pre><code>## # A draws_df: 6 iterations, 1 chains, and 6 variables
##   b_Intercept b_conc sigma Intercept lprior lp__
## 1         9.6   -1.8  0.56       5.6   -5.4  -17
## 2         9.4   -1.5  1.18       6.2   -4.9  -17
## 3         8.2   -1.3  1.30       5.4   -4.5  -18
## 4         7.8   -1.1  0.88       5.4   -4.3  -18
## 5         9.8   -1.9  0.81       5.7   -5.4  -16
## 6         9.7   -1.8  1.02       5.8   -5.3  -16
## # ... hidden reserved variables {&#39;.chain&#39;, &#39;.iteration&#39;, &#39;.draw&#39;}</code></pre>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="the-linear-model.html#cb291-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb291-2"><a href="the-linear-model.html#cb291-2" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">data =</span> m2.post, </span>
<span id="cb291-3"><a href="the-linear-model.html#cb291-3" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">intercept =</span> b_Intercept, <span class="at">slope =</span> b_conc),</span>
<span id="cb291-4"><a href="the-linear-model.html#cb291-4" tabindex="-1"></a>              <span class="at">linewidth=</span><span class="fl">0.1</span>, <span class="at">alpha=</span><span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb291-5"><a href="the-linear-model.html#cb291-5" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> fit, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Estimate), <span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb291-6"><a href="the-linear-model.html#cb291-6" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb291-7"><a href="the-linear-model.html#cb291-7" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb291-8"><a href="the-linear-model.html#cb291-8" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb291-9"><a href="the-linear-model.html#cb291-9" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb291-10"><a href="the-linear-model.html#cb291-10" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb291-11"><a href="the-linear-model.html#cb291-11" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb291-12"><a href="the-linear-model.html#cb291-12" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c16"></span>
<img src="ch09_linearModels_files/figure-html/c09c16-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.11: TODO: caption.
</p>
</div>
<p>This plot shows the prediction line for every single posterior sample from our model. I leveraged the <code>geom_abline</code> function to make this easy, as it automatically adds a line to the graph based on a supplied intercept and slope. I made the line width small and the lines transparent (<code>alpha = 0.3</code>) so that you could see the the points, the posterior mean prediction, and where most of the lines are concentrated. What we see is that the posterior mean prediction is in the center of the cluster, and the variation around it represents uncertainty. The more variation in the predictions from individual samples, the more uncertainty we have about the estimated relationship. Including predictions from each draw of the posterior can effective for displaying uncertainty, but an alternative would be to plot a credible interval at a particular level of probability around the posterior mean prediciton. Here’s the same plot but with a 95% credible interval for the prediction line:</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="the-linear-model.html#cb292-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb292-2"><a href="the-linear-model.html#cb292-2" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data =</span> fit,</span>
<span id="cb292-3"><a href="the-linear-model.html#cb292-3" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> Estimate, <span class="at">ymin =</span> Q2<span class="fl">.5</span>, <span class="at">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb292-4"><a href="the-linear-model.html#cb292-4" tabindex="-1"></a>              <span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb292-5"><a href="the-linear-model.html#cb292-5" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">linewidth =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb292-6"><a href="the-linear-model.html#cb292-6" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb292-7"><a href="the-linear-model.html#cb292-7" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb292-8"><a href="the-linear-model.html#cb292-8" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb292-9"><a href="the-linear-model.html#cb292-9" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb292-10"><a href="the-linear-model.html#cb292-10" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb292-11"><a href="the-linear-model.html#cb292-11" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb292-12"><a href="the-linear-model.html#cb292-12" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c17"></span>
<img src="ch09_linearModels_files/figure-html/c09c17-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.12: TODO: caption.
</p>
</div>
<p>Here we’re drawing on the predictions we made with the <code>fitted</code> function, which computed the 95% credible interval. The <code>geom_smooth</code> function adds the prediction line and a shaded area for the 95% credible interval.</p>
<p>It’s important to note that the variation in the prediction lines and the credible interval we just plotted both represent uncertainty about the <em>expected mean</em> value of the response variable at each value of the explanatory variable. In the context of our statistical model, these represent uncertainty about the values of <span class="math inline">\(\mu_i\)</span>. What if we wanted to represent uncertainty about the observed values of the response variable? We can clearly see that not all the points are exactly the same as the mean root length at a given herbicide concentration. There is residual variation in root length unexplained by herbicide concentration. How do we represent uncertainty about the individual values of root length?</p>
<p>To quantify uncertainty about the individual values of root length, we need to consider the standard deviation parameter, which represents the variation in root length values around the expected mean. In <code>brms</code>, the <code>fitted</code> function we used before only makes predictions about the mean of the response variable, and it quantifies uncertainty only about that mean. The<code>predict</code> function allows us to quantify uncertainty about the individual values of the response variable, collectively considering the mean and the standard deviation. It works much like the <code>fitted</code> function:</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="the-linear-model.html#cb293-1" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">predict</span>(m2, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">conc =</span> x))</span>
<span id="cb293-2"><a href="the-linear-model.html#cb293-2" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">conc =</span> x, y)</span>
<span id="cb293-3"><a href="the-linear-model.html#cb293-3" tabindex="-1"></a><span class="fu">head</span>(pred)</span></code></pre></div>
<pre><code>##        conc Estimate Est.Error     Q2.5    Q97.5
## 1 0.9400000 7.585479  1.133356 5.198950 9.701865
## 2 0.9683838 7.526634  1.166065 5.125505 9.812272
## 3 0.9967677 7.506209  1.185859 5.172469 9.809129
## 4 1.0251515 7.450557  1.161147 5.058929 9.727346
## 5 1.0535354 7.448916  1.154815 5.082123 9.682222
## 6 1.0819192 7.378764  1.155527 5.023748 9.561848</code></pre>
<p>Notice that although the estimated values are similar to the estimates from <code>fitted</code>, the credible intervals are much wider here because they consider the uncertainty in the mean and the individual observations around the mean. We call this interval the <span class="math display">\[prediction interval\]</span>. Let’s go ahead and plot it:</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="the-linear-model.html#cb295-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb295-2"><a href="the-linear-model.html#cb295-2" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> pred, </span>
<span id="cb295-3"><a href="the-linear-model.html#cb295-3" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> Estimate, <span class="at">ymin =</span> Q2<span class="fl">.5</span>, <span class="at">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb295-4"><a href="the-linear-model.html#cb295-4" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;grey83&quot;</span>) <span class="sc">+</span></span>
<span id="cb295-5"><a href="the-linear-model.html#cb295-5" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data =</span> fit,</span>
<span id="cb295-6"><a href="the-linear-model.html#cb295-6" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> Estimate, <span class="at">ymin =</span> Q2<span class="fl">.5</span>, <span class="at">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb295-7"><a href="the-linear-model.html#cb295-7" tabindex="-1"></a>              <span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb295-8"><a href="the-linear-model.html#cb295-8" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">linewidth =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb295-9"><a href="the-linear-model.html#cb295-9" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb295-10"><a href="the-linear-model.html#cb295-10" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb295-11"><a href="the-linear-model.html#cb295-11" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb295-12"><a href="the-linear-model.html#cb295-12" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb295-13"><a href="the-linear-model.html#cb295-13" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb295-14"><a href="the-linear-model.html#cb295-14" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb295-15"><a href="the-linear-model.html#cb295-15" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c19"></span>
<img src="ch09_linearModels_files/figure-html/c09c19-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.13: TODO: caption.
</p>
</div>
<p>Here we’ve used the <code>geom_ribbon</code> function to add the prediction interval to the last version of our figure. This figure now shows the observed data (red points), the posterior mean prediction line (solid black line), uncertainty in the predicted mean (95% credible interval in dark gray shading), and uncertainty in the individual observations (95% prediction interval in light gray shading). Whereas the credible interval shows uncertainty about the expected mean, the 95% prediction interval in light gray shows where we would expect 95% of the root length values to occur at any particular value of herbicide concentration.</p>
</div>
</div>
<div id="linear-models-with-categorical-predictors" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Linear models with categorical predictors<a href="the-linear-model.html#linear-models-with-categorical-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Linear models are flexible and can be modified to accomodate different types of data. So far we’ve looked at a simple model when we have a continuous response variable and a continuous predictor variable. In this section we look at what happens when the response is continous and the explanatory variable is categorical.</p>
<div id="binary-explanatory-variables" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Binary explanatory variables<a href="the-linear-model.html#binary-explanatory-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s revisit the dataset on color morphology of red-backed salamanders. These salamanders have two primary color morphs, striped and unstriped, that have been shown to vary in a number of other phenotypic traits. In this section let’s examine if color morphology affects the size of adult salamanders, measured as the snout-vent-length (SVL). First we load the data:</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="the-linear-model.html#cb296-1" tabindex="-1"></a>tail <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/plci_tails.csv&quot;</span>)</span></code></pre></div>
<p>We begin by plotting the tail autotomy data and comparing between morphs, using the</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="the-linear-model.html#cb297-1" tabindex="-1"></a><span class="fu">ggplot</span>(tail, <span class="fu">aes</span>(<span class="at">x =</span> morph, <span class="at">y =</span> length.cm)) <span class="sc">+</span></span>
<span id="cb297-2"><a href="the-linear-model.html#cb297-2" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> <span class="fl">0.1</span>, <span class="at">shape =</span> <span class="dv">1</span>, <span class="fu">aes</span>(<span class="at">color =</span> morph)) <span class="sc">+</span></span>
<span id="cb297-3"><a href="the-linear-model.html#cb297-3" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;striped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb297-4"><a href="the-linear-model.html#cb297-4" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sex&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Snout-vent-length (cm)&quot;</span>, <span class="at">color =</span> <span class="st">&quot;morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb297-5"><a href="the-linear-model.html#cb297-5" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb297-6"><a href="the-linear-model.html#cb297-6" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c21"></span>
<img src="ch09_linearModels_files/figure-html/c09c21-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.14: TODO: caption.
</p>
</div>
<p>We need to fit a model that allows us to estimate the mean SVL for each color morph and compare the mean between morphs. Here’s our statistical model:</p>
<p><span class="math display">\[
\begin{array}{l}
l_i \sim \mathrm{Normal}(\mu_i, \sigma) \\
\mu_i = \alpha_{j} \\
\alpha_{j} \sim \mathrm{Normal}(3.5, 0.5) \\
\sigma \sim \mathrm{Exponential}(3)
\end{array}
\]</span></p>
<p>We assume the lengths (<em>l</em>) for each individual <em>i</em> follow a normal distribution with mean <span class="math inline">\(\mu_i\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. The second line says the expected mean for each individual <em>i</em> is defined by the mean for its morph, <span class="math inline">\(\alpha_j\)</span>, where <em>j</em> represents an index for each color morph. Thus each individual <em>i</em> is either striped or unstriped, and we assume separate meeans for each morph. We assume a normal prior for the means of each sex with mean = 3.5 cm and standard deviation = 0.5 lb, reflecting the prior belief of a ~95% probability that the mean SVL will be between 2.5 and 4.5 for each morph. For the standard deviation parameter we assume an exponential prior. This is the first time we’ve seen an exponential distribution. The exponential distribution is handy for standard deviations because it is bounded at zero and has only positive values. The probabiity density is greatest at 0, and density declines with greater values, with the rate of decline specified by a single rate parameter (greater values indicate steeper rates of decline). The exponential function is considered a regularizing prior for standard deviations because it favors smaller values. Here we choose a an exponential prior with rate parameter 1 for the standard deviation of SVL.</p>
<p>A simple way to code categorical explanatory variables is by specifying a numerical index value for each category. This is simple a way of representing each category as an integer value. Let’s define the striped morph as 1 and unstriped as 2:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="the-linear-model.html#cb298-1" tabindex="-1"></a>tail<span class="sc">$</span>morph.i <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(tail<span class="sc">$</span>morph <span class="sc">==</span> <span class="st">&quot;striped&quot;</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb298-2"><a href="the-linear-model.html#cb298-2" tabindex="-1"></a>tail<span class="sc">$</span>morph.i <span class="ot">&lt;-</span> <span class="fu">factor</span>(tail<span class="sc">$</span>morph.i)</span></code></pre></div>
<p>One way to handle categorical predictor variables<em>index variable</em>. An index variable represents each category as an integer value. We also define the index variable, <code>morph.i</code> as a factor variable, which is required by <code>brms</code>.</p>
<p>We begin the analysis with a prior predictive check:</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="the-linear-model.html#cb299-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># for reproducibility</span></span>
<span id="cb299-2"><a href="the-linear-model.html#cb299-2" tabindex="-1"></a></span>
<span id="cb299-3"><a href="the-linear-model.html#cb299-3" tabindex="-1"></a><span class="co">#draw 1000 values of the mean striped length from the prior</span></span>
<span id="cb299-4"><a href="the-linear-model.html#cb299-4" tabindex="-1"></a>striped_mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="at">mean =</span> <span class="fl">3.5</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb299-5"><a href="the-linear-model.html#cb299-5" tabindex="-1"></a></span>
<span id="cb299-6"><a href="the-linear-model.html#cb299-6" tabindex="-1"></a><span class="co">#draw 1000 values of the mean festriped weight from the prior</span></span>
<span id="cb299-7"><a href="the-linear-model.html#cb299-7" tabindex="-1"></a>unstriped_mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="at">mean =</span> <span class="fl">3.5</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb299-8"><a href="the-linear-model.html#cb299-8" tabindex="-1"></a></span>
<span id="cb299-9"><a href="the-linear-model.html#cb299-9" tabindex="-1"></a><span class="co">#draw 1000 values of the standard deviation in weight from the prior</span></span>
<span id="cb299-10"><a href="the-linear-model.html#cb299-10" tabindex="-1"></a>sample_sigma <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">1000</span>, <span class="dv">3</span>)</span>
<span id="cb299-11"><a href="the-linear-model.html#cb299-11" tabindex="-1"></a></span>
<span id="cb299-12"><a href="the-linear-model.html#cb299-12" tabindex="-1"></a><span class="co">#draw values of individual weights for stripeds and festripeds</span></span>
<span id="cb299-13"><a href="the-linear-model.html#cb299-13" tabindex="-1"></a>prior_striped_l <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, striped_mu, sample_sigma)</span>
<span id="cb299-14"><a href="the-linear-model.html#cb299-14" tabindex="-1"></a>prior_unstriped_l <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, unstriped_mu, sample_sigma)</span>
<span id="cb299-15"><a href="the-linear-model.html#cb299-15" tabindex="-1"></a></span>
<span id="cb299-16"><a href="the-linear-model.html#cb299-16" tabindex="-1"></a><span class="co">#combine to a dataframe</span></span>
<span id="cb299-17"><a href="the-linear-model.html#cb299-17" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">prior_striped_l =</span> prior_striped_l,</span>
<span id="cb299-18"><a href="the-linear-model.html#cb299-18" tabindex="-1"></a>                 <span class="at">prior_unstriped_l =</span> prior_unstriped_l)</span>
<span id="cb299-19"><a href="the-linear-model.html#cb299-19" tabindex="-1"></a></span>
<span id="cb299-20"><a href="the-linear-model.html#cb299-20" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb299-21"><a href="the-linear-model.html#cb299-21" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> df<span class="sc">$</span>prior_striped_l, <span class="at">fill =</span> <span class="st">&quot;striped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb299-22"><a href="the-linear-model.html#cb299-22" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> df<span class="sc">$</span>prior_unstriped_l, <span class="at">fill =</span> <span class="st">&quot;unstriped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb299-23"><a href="the-linear-model.html#cb299-23" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;striped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb299-24"><a href="the-linear-model.html#cb299-24" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;SVL (cm)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;Morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb299-25"><a href="the-linear-model.html#cb299-25" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="ch09_linearModels_files/figure-html/c09c23-1.png" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>We see the priors imply no difference in the distribution of individual SVLs, but certainly they allow for it. The only issue here is that the priors imply a few negative values for SVL, which of course doesn’t make sense. However those observations are extremely rare, and we proceed to fit the model:</p>
<p>Let’s go ahead look at how we fit the model with <code>brms</code>. We already have the data organized in the dataframe <code>tail</code>, so we can can get right to defining our model and priors.</p>
<p>All we want here is the estimation of a mean for each group, so we don’t want to estimate a typical intercept. To suppress the intercept estimation in <code>brms</code>, we use the <code>0 + ...</code> syntax. Adding <code>0 + morph.i</code> syntax tells <code>brms</code> to compute a separate intercept for each index value of the <code>morph.i</code> factor variable. As such, when we define the priors for the means, we do so by specifying <code>class = b</code> (rather than <code>Intercept</code>).</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="the-linear-model.html#cb300-1" tabindex="-1"></a><span class="co">#specify model formula</span></span>
<span id="cb300-2"><a href="the-linear-model.html#cb300-2" tabindex="-1"></a>m2.formula <span class="ot">&lt;-</span> <span class="fu">bf</span>(length.cm <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> morph.i,</span>
<span id="cb300-3"><a href="the-linear-model.html#cb300-3" tabindex="-1"></a>                <span class="at">family =</span> gaussian)  </span>
<span id="cb300-4"><a href="the-linear-model.html#cb300-4" tabindex="-1"></a></span>
<span id="cb300-5"><a href="the-linear-model.html#cb300-5" tabindex="-1"></a><span class="co">#specify priors</span></span>
<span id="cb300-6"><a href="the-linear-model.html#cb300-6" tabindex="-1"></a>m2.prior <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="fl">3.5</span>, <span class="fl">0.5</span>), <span class="at">class =</span> b),</span>
<span id="cb300-7"><a href="the-linear-model.html#cb300-7" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">3</span>), <span class="at">class=</span>sigma))</span>
<span id="cb300-8"><a href="the-linear-model.html#cb300-8" tabindex="-1"></a>              </span>
<span id="cb300-9"><a href="the-linear-model.html#cb300-9" tabindex="-1"></a><span class="co">#compute the posterior</span></span>
<span id="cb300-10"><a href="the-linear-model.html#cb300-10" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">brm</span>(<span class="at">data =</span> tail,</span>
<span id="cb300-11"><a href="the-linear-model.html#cb300-11" tabindex="-1"></a>         <span class="at">formula =</span> m2.formula,</span>
<span id="cb300-12"><a href="the-linear-model.html#cb300-12" tabindex="-1"></a>         <span class="at">prior =</span> m2.prior,</span>
<span id="cb300-13"><a href="the-linear-model.html#cb300-13" tabindex="-1"></a>         <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb300-14"><a href="the-linear-model.html#cb300-14" tabindex="-1"></a>         <span class="at">seed=</span><span class="dv">123</span>)</span>
<span id="cb300-15"><a href="the-linear-model.html#cb300-15" tabindex="-1"></a></span>
<span id="cb300-16"><a href="the-linear-model.html#cb300-16" tabindex="-1"></a><span class="fu">plot</span>(m2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c24"></span>
<img src="ch09_linearModels_files/figure-html/c09c24-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.15: TODO: caption.
</p>
</div>
<p>We see the plot function returns posterior distributions for three parameters, including the mean for each morph and the standard deviation. The means for each morph are labeled with the appropriate index level, specifically <code>morph.i1</code> for striped and <code>morph.i2</code> for unstriped. The traceplots look pretty good, so we turn our attention to the model summary:</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="the-linear-model.html#cb301-1" tabindex="-1"></a><span class="fu">print</span>(m2)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity 
## Formula: length.cm ~ 0 + morph.i 
##    Data: tail (Number of observations: 40) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Regression Coefficients:
##          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## morph.i1     3.75      0.08     3.58     3.91 1.00     3509     2932
## morph.i2     3.46      0.08     3.29     3.62 1.00     3670     2422
## 
## Further Distributional Parameters:
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.37      0.04     0.30     0.47 1.00     3474     2613
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>It looks like the mean SVL of the posterior for striped morph is 3.75 g, with a 95% credible interval from 3.58 to 3.91 g. In contrast, the mean of the posterior for unstriped morph is 3.46 cm, with a 95% credible interval of 3.29 to 3.62.</p>
<p>Is there a difference in the mean SVL between color morphs? The posterior distributions overlap somethwat, we we can see by the 95% credible intervals. But we don’t need to visually look for overlap of posterior distributions. We can use the samples of the mean SVL for each morph to derive values that allow us to make the dcomparison between morph explicit. Let’s first extract the samples and plot the posterior distributions for hte mean of each morph.</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="the-linear-model.html#cb303-1" tabindex="-1"></a><span class="co">#extract the posterior samples</span></span>
<span id="cb303-2"><a href="the-linear-model.html#cb303-2" tabindex="-1"></a>m2.post <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(m2)</span>
<span id="cb303-3"><a href="the-linear-model.html#cb303-3" tabindex="-1"></a><span class="fu">head</span>(m2.post)</span></code></pre></div>
<pre><code>## # A draws_df: 6 iterations, 1 chains, and 5 variables
##   b_morph.i1 b_morph.i2 sigma lprior lp__
## 1        3.9        3.5  0.37  -0.83  -19
## 2        3.8        3.5  0.37  -0.69  -18
## 3        3.8        3.6  0.40  -0.69  -18
## 4        3.8        3.3  0.35  -0.56  -18
## 5        3.7        3.6  0.35  -0.50  -17
## 6        3.7        3.5  0.42  -0.69  -18
## # ... hidden reserved variables {&#39;.chain&#39;, &#39;.iteration&#39;, &#39;.draw&#39;}</code></pre>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="the-linear-model.html#cb305-1" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb305-2"><a href="the-linear-model.html#cb305-2" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb305-3"><a href="the-linear-model.html#cb305-3" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> m2.post<span class="sc">$</span>b_morph.i1, <span class="at">fill =</span> <span class="st">&quot;striped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb305-4"><a href="the-linear-model.html#cb305-4" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> m2.post<span class="sc">$</span>b_morph.i2, <span class="at">fill =</span> <span class="st">&quot;unstriped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb305-5"><a href="the-linear-model.html#cb305-5" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;striped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb305-6"><a href="the-linear-model.html#cb305-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Mean SVL (cm)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;Morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb305-7"><a href="the-linear-model.html#cb305-7" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="ch09_linearModels_files/figure-html/c09c26-1.png" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>We can see in the plot what we thought was apparent in the credibel intervals: the bulk of the posterior distribution for mean SVL for striped is greater than unstriped, but there is some overlap. If we are really interested in the difference between the mean SVL of each morph, we should quantify that difference directly from the samples and examine the posterior distribution of the difference in means. This is as simple is adding a new column to <code>m2.post</code> as the difference in means between the morphs, then we can summarize that posterior distribution. This is called a <strong>contrast</strong>.</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="the-linear-model.html#cb306-1" tabindex="-1"></a><span class="co">#calculate the contrast as mean striped - mean unstriped</span></span>
<span id="cb306-2"><a href="the-linear-model.html#cb306-2" tabindex="-1"></a>m2.post<span class="sc">$</span>morph.delta <span class="ot">&lt;-</span> m2.post<span class="sc">$</span>b_morph.i1 <span class="sc">-</span> m2.post<span class="sc">$</span>b_morph.i2</span>
<span id="cb306-3"><a href="the-linear-model.html#cb306-3" tabindex="-1"></a></span>
<span id="cb306-4"><a href="the-linear-model.html#cb306-4" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb306-5"><a href="the-linear-model.html#cb306-5" tabindex="-1"></a><span class="fu">ggplot</span>(m2.post, <span class="fu">aes</span>(<span class="at">x =</span> morph.delta)) <span class="sc">+</span></span>
<span id="cb306-6"><a href="the-linear-model.html#cb306-6" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;slategray&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb306-7"><a href="the-linear-model.html#cb306-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Difference in mean SVL (cm; Stirped - Unstriped)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb306-8"><a href="the-linear-model.html#cb306-8" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c27"></span>
<img src="ch09_linearModels_files/figure-html/c09c27-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.16: TODO: caption.
</p>
</div>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="the-linear-model.html#cb307-1" tabindex="-1"></a><span class="co">#mean and credible interval</span></span>
<span id="cb307-2"><a href="the-linear-model.html#cb307-2" tabindex="-1"></a><span class="fu">mean</span>(m2.post<span class="sc">$</span>morph.delta)</span></code></pre></div>
<pre><code>## [1] 0.2888998</code></pre>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="the-linear-model.html#cb309-1" tabindex="-1"></a><span class="fu">quantile</span>(m2.post<span class="sc">$</span>morph.delta, <span class="at">probs=</span><span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##       2.5%      97.5% 
## 0.06143877 0.51822613</code></pre>
<p>We mean of the derived posterior difference in means between morphs is 0.29, with a 95% credible interval of 0.06 to 0.52 cm. Thus, There’s a 95% probability that the mean SVL for striped morph is at least 0.06 cm greater than the unstriped morph. We could also compute the probability of the mean for each morph being greater than the other:</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="the-linear-model.html#cb311-1" tabindex="-1"></a><span class="co">#probability of mean striped &gt; mean unstriped</span></span>
<span id="cb311-2"><a href="the-linear-model.html#cb311-2" tabindex="-1"></a><span class="fu">mean</span>(m2.post<span class="sc">$</span>morph.delta<span class="sc">&gt;</span><span class="dv">0</span>)</span></code></pre></div>
<pre><code>## [1] 0.99125</code></pre>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="the-linear-model.html#cb313-1" tabindex="-1"></a><span class="co">#probability of mean untriped &gt; mean striped</span></span>
<span id="cb313-2"><a href="the-linear-model.html#cb313-2" tabindex="-1"></a><span class="fu">mean</span>(m2.post<span class="sc">$</span>morph.delta<span class="sc">&lt;</span><span class="dv">0</span>)</span></code></pre></div>
<pre><code>## [1] 0.00875</code></pre>
<p>We find a 99% chance the mean SVL for striped is greater than unstriped.</p>
<p>In addition to examining the posterior distribution for the mean SVL, we can also examine the posterior distribution for the individual SVL values.</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="the-linear-model.html#cb315-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb315-2"><a href="the-linear-model.html#cb315-2" tabindex="-1"></a></span>
<span id="cb315-3"><a href="the-linear-model.html#cb315-3" tabindex="-1"></a><span class="co"># Simulate one weight per posterior sample</span></span>
<span id="cb315-4"><a href="the-linear-model.html#cb315-4" tabindex="-1"></a>post_s_w <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">nrow</span>(m2.post), <span class="at">mean =</span> m2.post<span class="sc">$</span>b_morph.i1, <span class="at">sd =</span> m2.post<span class="sc">$</span>sigma)</span>
<span id="cb315-5"><a href="the-linear-model.html#cb315-5" tabindex="-1"></a>post_u_w <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">nrow</span>(m2.post), <span class="at">mean =</span> m2.post<span class="sc">$</span>b_morph.i2, <span class="at">sd =</span> m2.post<span class="sc">$</span>sigma)</span>
<span id="cb315-6"><a href="the-linear-model.html#cb315-6" tabindex="-1"></a></span>
<span id="cb315-7"><a href="the-linear-model.html#cb315-7" tabindex="-1"></a><span class="co"># Create data frame for plotting</span></span>
<span id="cb315-8"><a href="the-linear-model.html#cb315-8" tabindex="-1"></a>df_post <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">post_s_w =</span> post_s_w,</span>
<span id="cb315-9"><a href="the-linear-model.html#cb315-9" tabindex="-1"></a>                      <span class="at">post_u_w =</span> post_u_w)</span>
<span id="cb315-10"><a href="the-linear-model.html#cb315-10" tabindex="-1"></a></span>
<span id="cb315-11"><a href="the-linear-model.html#cb315-11" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb315-12"><a href="the-linear-model.html#cb315-12" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> df_post<span class="sc">$</span>post_s_w, <span class="at">fill =</span> <span class="st">&quot;striped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb315-13"><a href="the-linear-model.html#cb315-13" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> df_post<span class="sc">$</span>post_u_w, <span class="at">fill =</span> <span class="st">&quot;unstriped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb315-14"><a href="the-linear-model.html#cb315-14" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;striped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb315-15"><a href="the-linear-model.html#cb315-15" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Individual weight (lb)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;Morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb315-16"><a href="the-linear-model.html#cb315-16" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="ch09_linearModels_files/figure-html/c09c29-1.png" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>Here the <code>rnorm</code> function is generating a random SVL for each color morph drawn from a distribution specified by the sampled mean and standard deviation from the posterior distributions for striped and unstriped morphs. Plotting the density of those 10,000 SVLs for each morph allows us to visualize the posterior distributions of individual SVL by morph. We can clearly see that the center of the distributions is greater for the striped than unstriped morph (as we saw previously), but that individual weights overlap quite a bit between color morphs.</p>
<p>We can also quantify a contrast for the individual SVLs. This gives us the posterior distribution of differences in <em>individual</em> SVLs between color morphs:</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="the-linear-model.html#cb316-1" tabindex="-1"></a><span class="co">#posterior distribution for difference in individual weights (contrast)</span></span>
<span id="cb316-2"><a href="the-linear-model.html#cb316-2" tabindex="-1"></a>df_post<span class="sc">$</span>l_contrast <span class="ot">&lt;-</span> df_post<span class="sc">$</span>post_s_w <span class="sc">-</span> df_post<span class="sc">$</span>post_u_w</span>
<span id="cb316-3"><a href="the-linear-model.html#cb316-3" tabindex="-1"></a></span>
<span id="cb316-4"><a href="the-linear-model.html#cb316-4" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb316-5"><a href="the-linear-model.html#cb316-5" tabindex="-1"></a><span class="fu">ggplot</span>(df_post, <span class="fu">aes</span>(<span class="at">x =</span> l_contrast)) <span class="sc">+</span></span>
<span id="cb316-6"><a href="the-linear-model.html#cb316-6" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;slategray&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb316-7"><a href="the-linear-model.html#cb316-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Difference in individual SVL (cm; Striped - Unstriped)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb316-8"><a href="the-linear-model.html#cb316-8" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09c30"></span>
<img src="ch09_linearModels_files/figure-html/c09c30-1.png" alt="TODO: caption." width="672" />
<p class="caption">
Figure 9.17: TODO: caption.
</p>
</div>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="the-linear-model.html#cb317-1" tabindex="-1"></a><span class="co">#proportion above zero</span></span>
<span id="cb317-2"><a href="the-linear-model.html#cb317-2" tabindex="-1"></a><span class="fu">sum</span>(df_post<span class="sc">$</span>l_contrast <span class="sc">&gt;</span> <span class="dv">0</span>)<span class="sc">/</span><span class="fu">nrow</span>(df_post)</span></code></pre></div>
<pre><code>## [1] 0.70675</code></pre>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="the-linear-model.html#cb319-1" tabindex="-1"></a><span class="co">#proportion below zero</span></span>
<span id="cb319-2"><a href="the-linear-model.html#cb319-2" tabindex="-1"></a><span class="fu">sum</span>(df_post<span class="sc">$</span>l_contrast <span class="sc">&lt;</span> <span class="dv">0</span>)<span class="sc">/</span><span class="fu">nrow</span>(df_post)</span></code></pre></div>
<pre><code>## [1] 0.29325</code></pre>
<p>This contrast indicate that if we randomly select one striped morph and one unstriped morph from their respective SVL distributions, we can expect the striped morph to have a longer SVL than the unstriped morph 71% of the time, whereas we expect the unstriped morph to have a greater SVL 29% of the time.</p>
</div>
<div id="categorical-predictors-with-more-than-two-categories" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Categorical predictors with more than two categories<a href="the-linear-model.html#categorical-predictors-with-more-than-two-categories" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Planned</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bayesian-workflow.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="graphical-causal-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["research-design-and-statistics.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true,
    "toc_depth": 2
  },
  "toolbar": {
    "position": "fixed"
  },
  "info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
