<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Appendix B Decision-making with frequentist estimates | Research Design and Statistics</title>
  <meta name="description" content="An introduction to research design and statistics" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Appendix B Decision-making with frequentist estimates | Research Design and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An introduction to research design and statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Appendix B Decision-making with frequentist estimates | Research Design and Statistics" />
  
  <meta name="twitter:description" content="An introduction to research design and statistics" />
  

<meta name="author" content="Bradley J. Cosentino" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimation-with-frequentist-inference.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#work-in-progress"><i class="fa fa-check"></i>Work in progress</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#copyright"><i class="fa fa-check"></i>Copyright</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html"><i class="fa fa-check"></i><b>1</b> Why Statistics? The Problem of Uncertainty</a>
<ul>
<li class="chapter" data-level="1.1" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#the-nature-of-science"><i class="fa fa-check"></i><b>1.1</b> The nature of science</a></li>
<li class="chapter" data-level="1.2" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#goals-of-scientific-research"><i class="fa fa-check"></i><b>1.2</b> Goals of scientific research</a></li>
<li class="chapter" data-level="1.3" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#three-general-goals-of-scientific-research"><i class="fa fa-check"></i><b>1.3</b> Three general goals of scientific research</a></li>
<li class="chapter" data-level="1.4" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#research-design-and-statistical-analysis-depend-on-your-goal"><i class="fa fa-check"></i><b>1.4</b> Research design and statistical analysis depend on your goal</a></li>
<li class="chapter" data-level="1.5" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#you-cant-escape-uncertainty-in-science"><i class="fa fa-check"></i><b>1.5</b> You can’t escape uncertainty in science</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html"><i class="fa fa-check"></i><b>2</b> Scientific workflow: Connecting ideas to data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#research-questions"><i class="fa fa-check"></i><b>2.1</b> Research questions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#clarify-your-primary-goal-description-prediction-or-explanation"><i class="fa fa-check"></i><b>2.1.1</b> Clarify your primary goal: description, prediction, or explanation?</a></li>
<li class="chapter" data-level="2.1.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#identify-the-scope-of-inference-the-who-what-when-and-where-of-your-study."><i class="fa fa-check"></i><b>2.1.2</b> Identify the scope of inference: The who, what, when, and where of your study.</a></li>
<li class="chapter" data-level="2.1.3" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-it-interesting"><i class="fa fa-check"></i><b>2.1.3</b> Make it interesting</a></li>
<li class="chapter" data-level="2.1.4" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-it-answerable-with-data"><i class="fa fa-check"></i><b>2.1.4</b> Make it answerable with data</a></li>
<li class="chapter" data-level="2.1.5" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#ground-it-in-theory"><i class="fa fa-check"></i><b>2.1.5</b> Ground it in theory</a></li>
<li class="chapter" data-level="2.1.6" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-sure-its-feasible"><i class="fa fa-check"></i><b>2.1.6</b> Make sure it’s feasible</a></li>
<li class="chapter" data-level="2.1.7" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#avoid-analyzing-the-data-before-stating-your-question"><i class="fa fa-check"></i><b>2.1.7</b> Avoid analyzing the data before stating your question</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#connecting-ideas-to-data"><i class="fa fa-check"></i><b>2.2</b> Connecting ideas to data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#theory"><i class="fa fa-check"></i><b>2.2.1</b> Theory</a></li>
<li class="chapter" data-level="2.2.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#research-question"><i class="fa fa-check"></i><b>2.2.2</b> Research question</a></li>
<li class="chapter" data-level="2.2.3" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#generative-model"><i class="fa fa-check"></i><b>2.2.3</b> Generative model</a></li>
<li class="chapter" data-level="2.2.4" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#study-design"><i class="fa fa-check"></i><b>2.2.4</b> Study design</a></li>
<li class="chapter" data-level="2.2.5" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#estimand"><i class="fa fa-check"></i><b>2.2.5</b> Estimand</a></li>
<li class="chapter" data-level="2.2.6" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#target-population"><i class="fa fa-check"></i><b>2.2.6</b> Target population</a></li>
<li class="chapter" data-level="2.2.7" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#sample-data"><i class="fa fa-check"></i><b>2.2.7</b> Sample data</a></li>
<li class="chapter" data-level="2.2.8" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#statistical-model"><i class="fa fa-check"></i><b>2.2.8</b> Statistical model</a></li>
<li class="chapter" data-level="2.2.9" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#estimate"><i class="fa fa-check"></i><b>2.2.9</b> Estimate</a></li>
<li class="chapter" data-level="2.2.10" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#summary"><i class="fa fa-check"></i><b>2.2.10</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html"><i class="fa fa-check"></i><b>3</b> Introduction to Data and R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#an-introduction-to-data"><i class="fa fa-check"></i><b>3.1</b> An introduction to data</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#variables-and-observations"><i class="fa fa-check"></i><b>3.1.1</b> Variables and observations</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#types-of-variables"><i class="fa fa-check"></i><b>3.1.2</b> Types of variables</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#relationships-between-variables"><i class="fa fa-check"></i><b>3.1.3</b> Relationships between variables</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#variable-naming-conventions-and-metadata"><i class="fa fa-check"></i><b>3.1.4</b> Variable naming conventions and metadata</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#introduction-to-r"><i class="fa fa-check"></i><b>3.2</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>3.2.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#the-rstudio-interface"><i class="fa fa-check"></i><b>3.2.2</b> The RStudio Interface</a></li>
<li class="chapter" data-level="3.2.3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#basic-data-manipulation-in-r"><i class="fa fa-check"></i><b>3.2.3</b> Basic data manipulation in R</a></li>
<li class="chapter" data-level="3.2.4" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#scripting"><i class="fa fa-check"></i><b>3.2.4</b> Scripting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="describing-data.html"><a href="describing-data.html"><i class="fa fa-check"></i><b>4</b> Describing data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="describing-data.html"><a href="describing-data.html#defining-the-population"><i class="fa fa-check"></i><b>4.1</b> Defining the population</a></li>
<li class="chapter" data-level="4.2" data-path="describing-data.html"><a href="describing-data.html#loading-data-into-r"><i class="fa fa-check"></i><b>4.2</b> Loading data into R</a></li>
<li class="chapter" data-level="4.3" data-path="describing-data.html"><a href="describing-data.html#inspecting-the-dataset"><i class="fa fa-check"></i><b>4.3</b> Inspecting the dataset</a></li>
<li class="chapter" data-level="4.4" data-path="describing-data.html"><a href="describing-data.html#describing-single-variables"><i class="fa fa-check"></i><b>4.4</b> Describing single variables</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="describing-data.html"><a href="describing-data.html#qualitative-variables"><i class="fa fa-check"></i><b>4.4.1</b> Qualitative variables</a></li>
<li class="chapter" data-level="4.4.2" data-path="describing-data.html"><a href="describing-data.html#quantitative-variables"><i class="fa fa-check"></i><b>4.4.2</b> Quantitative variables</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="describing-data.html"><a href="describing-data.html#describing-relationships-between-variables"><i class="fa fa-check"></i><b>4.5</b> Describing relationships between variables</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="describing-data.html"><a href="describing-data.html#associations-between-quantitative-variables"><i class="fa fa-check"></i><b>4.5.1</b> Associations between quantitative variables</a></li>
<li class="chapter" data-level="4.5.2" data-path="describing-data.html"><a href="describing-data.html#associations-between-quantitative-and-qualitative-variables"><i class="fa fa-check"></i><b>4.5.2</b> Associations between quantitative and qualitative variables</a></li>
<li class="chapter" data-level="4.5.3" data-path="describing-data.html"><a href="describing-data.html#associations-between-qualitative-variables"><i class="fa fa-check"></i><b>4.5.3</b> Associations between qualitative variables</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="describing-data.html"><a href="describing-data.html#next-steps"><i class="fa fa-check"></i><b>4.6</b> Next steps</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html"><i class="fa fa-check"></i><b>5</b> Uncertainty from sampling</a>
<ul>
<li class="chapter" data-level="5.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#sampling-requires-estimation"><i class="fa fa-check"></i><b>5.1</b> Sampling requires estimation</a></li>
<li class="chapter" data-level="5.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#parameters-estimates-estimands"><i class="fa fa-check"></i><b>5.2</b> Parameters, estimates, estimands</a></li>
<li class="chapter" data-level="5.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#sources-of-uncertainty-from-sampling"><i class="fa fa-check"></i><b>5.3</b> Sources of uncertainty from sampling</a></li>
<li class="chapter" data-level="5.4" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#accuracy-and-precision"><i class="fa fa-check"></i><b>5.4</b> Accuracy and precision</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#accuracy"><i class="fa fa-check"></i><b>5.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.4.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#precision"><i class="fa fa-check"></i><b>5.4.2</b> Precision</a></li>
<li class="chapter" data-level="5.4.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#considering-accuracy-and-precision-together"><i class="fa fa-check"></i><b>5.4.3</b> Considering accuracy and precision together</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#maximizing-accuracy-and-precision-of-estimates"><i class="fa fa-check"></i><b>5.5</b> Maximizing accuracy and precision of estimates</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#random-sampling"><i class="fa fa-check"></i><b>5.5.1</b> Random sampling</a></li>
<li class="chapter" data-level="5.5.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#replication"><i class="fa fa-check"></i><b>5.5.2</b> Replication</a></li>
<li class="chapter" data-level="5.5.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#take-home-points"><i class="fa fa-check"></i><b>5.5.3</b> Take-home points</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html"><i class="fa fa-check"></i><b>6</b> Probability as the Language of Uncertainty</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#defining-probability"><i class="fa fa-check"></i><b>6.1</b> Defining probability</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#frequentist-definition"><i class="fa fa-check"></i><b>6.1.1</b> Frequentist definition</a></li>
<li class="chapter" data-level="6.1.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#bayesian-definition"><i class="fa fa-check"></i><b>6.1.2</b> Bayesian definition</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#probability-rules"><i class="fa fa-check"></i><b>6.2</b> Probability rules</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#individual-events"><i class="fa fa-check"></i><b>6.2.1</b> Individual events</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#joint-events"><i class="fa fa-check"></i><b>6.2.2</b> Joint events</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#general-addition-rule"><i class="fa fa-check"></i><b>6.2.3</b> General addition rule</a></li>
<li class="chapter" data-level="6.2.4" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#quantifying-marginal-probabilities"><i class="fa fa-check"></i><b>6.2.4</b> Quantifying marginal probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-probability-distributions"><i class="fa fa-check"></i><b>6.3</b> Sampling from probability distributions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-populations-is-probabalistic"><i class="fa fa-check"></i><b>6.3.1</b> Sampling from populations is probabalistic</a></li>
<li class="chapter" data-level="6.3.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#discrete-random-variables"><i class="fa fa-check"></i><b>6.3.2</b> Discrete random variables</a></li>
<li class="chapter" data-level="6.3.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.3.3</b> Continuous random variables</a></li>
<li class="chapter" data-level="6.3.4" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-probability-distributions-1"><i class="fa fa-check"></i><b>6.3.4</b> Sampling from probability distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html"><i class="fa fa-check"></i><b>7</b> Bayesian estimation and inference</a>
<ul>
<li class="chapter" data-level="7.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#scientific-workflow-for-the-problem"><i class="fa fa-check"></i><b>7.1</b> Scientific workflow for the problem</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#theory-and-the-research-question"><i class="fa fa-check"></i><b>7.1.1</b> Theory and the research question</a></li>
<li class="chapter" data-level="7.1.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#generative-model-and-estimand"><i class="fa fa-check"></i><b>7.1.2</b> Generative model and estimand</a></li>
<li class="chapter" data-level="7.1.3" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#statistical-model-and-estimate"><i class="fa fa-check"></i><b>7.1.3</b> Statistical model and estimate</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#bayes-theorem"><i class="fa fa-check"></i><b>7.2</b> Bayes Theorem</a></li>
<li class="chapter" data-level="7.3" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#applying-bayes-theorem-to-statistical-analysis"><i class="fa fa-check"></i><b>7.3</b> Applying Bayes Theorem to statistical analysis</a></li>
<li class="chapter" data-level="7.4" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#steps-of-estimation-with-bayesian-inference"><i class="fa fa-check"></i><b>7.4</b> Steps of estimation with Bayesian inference</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#specify-the-prior-distribution"><i class="fa fa-check"></i><b>7.4.1</b> Specify the prior distribution</a></li>
<li class="chapter" data-level="7.4.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#quantify-the-likelihood-of-the-data"><i class="fa fa-check"></i><b>7.4.2</b> Quantify the likelihood of the data</a></li>
<li class="chapter" data-level="7.4.3" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#quantify-the-total-probability-of-the-data-marginal-likelihood"><i class="fa fa-check"></i><b>7.4.3</b> Quantify the total probability of the data (marginal likelihood)</a></li>
<li class="chapter" data-level="7.4.4" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#quantify-the-posterior-distribution"><i class="fa fa-check"></i><b>7.4.4</b> Quantify the posterior distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#summarizing-the-posterior-distribution"><i class="fa fa-check"></i><b>7.5</b> Summarizing the posterior distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#sampling-from-the-posterior-distribution"><i class="fa fa-check"></i><b>7.5.1</b> Sampling from the posterior distribution</a></li>
<li class="chapter" data-level="7.5.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#central-tendency-and-variance"><i class="fa fa-check"></i><b>7.5.2</b> Central tendency and variance</a></li>
<li class="chapter" data-level="7.5.3" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#intervals"><i class="fa fa-check"></i><b>7.5.3</b> Intervals</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#specifying-priors"><i class="fa fa-check"></i><b>7.6</b> Specifying priors</a></li>
<li class="chapter" data-level="7.7" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#decision-making"><i class="fa fa-check"></i><b>7.7</b> Decision making</a></li>
<li class="chapter" data-level="7.8" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#specifying-and-fitting-statistical-models-with-bayes"><i class="fa fa-check"></i><b>7.8</b> Specifying and fitting statistical models with Bayes</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#statistical-model-specification"><i class="fa fa-check"></i><b>7.8.1</b> Statistical model specification</a></li>
<li class="chapter" data-level="7.8.2" data-path="bayesian-estimation-and-inference.html"><a href="bayesian-estimation-and-inference.html#fitting-models-with-brms"><i class="fa fa-check"></i><b>7.8.2</b> Fitting models with <em>brms</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html"><i class="fa fa-check"></i><b>8</b> Bayesian Workflow</a>
<ul>
<li class="chapter" data-level="8.1" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-1-choose-an-appropriate-model-for-the-likelihood"><i class="fa fa-check"></i><b>8.1</b> Step 1: Choose an appropriate model for the likelihood</a></li>
<li class="chapter" data-level="8.2" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-2-decide-on-prior-distributions-for-each-parameter-in-the-likelihood"><i class="fa fa-check"></i><b>8.2</b> Step 2: Decide on prior distributions for each parameter in the likelihood</a></li>
<li class="chapter" data-level="8.3" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-3-prior-predictive-check"><i class="fa fa-check"></i><b>8.3</b> Step 3: Prior predictive check</a></li>
<li class="chapter" data-level="8.4" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-4-fit-the-statistical-model-with-the-observed-data"><i class="fa fa-check"></i><b>8.4</b> Step 4: Fit the statistical model with the observed data</a></li>
<li class="chapter" data-level="8.5" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#step-5-evaluating-and-applying-a-fitted-model"><i class="fa fa-check"></i><b>8.5</b> Step 5: Evaluating and applying a fitted model</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#a-quick-glance-at-the-estimates"><i class="fa fa-check"></i><b>8.5.1</b> A quick glance at the estimates</a></li>
<li class="chapter" data-level="8.5.2" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#checking-for-convergence"><i class="fa fa-check"></i><b>8.5.2</b> Checking for convergence</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#checking-the-shape-of-the-posterior-distribution"><i class="fa fa-check"></i><b>8.6</b> Checking the shape of the posterior distribution</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#inference-and-posterior-predictive-check"><i class="fa fa-check"></i><b>8.6.1</b> Inference and posterior predictive check</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#summary-1"><i class="fa fa-check"></i><b>8.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="the-linear-model.html"><a href="the-linear-model.html"><i class="fa fa-check"></i><b>9</b> The linear model</a>
<ul>
<li class="chapter" data-level="9.1" data-path="the-linear-model.html"><a href="the-linear-model.html#statistical-models"><i class="fa fa-check"></i><b>9.1</b> Statistical models</a></li>
<li class="chapter" data-level="9.2" data-path="the-linear-model.html"><a href="the-linear-model.html#linear-model"><i class="fa fa-check"></i><b>9.2</b> Linear model</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="the-linear-model.html"><a href="the-linear-model.html#basic-structure-of-the-linear-model"><i class="fa fa-check"></i><b>9.2.1</b> Basic structure of the linear model</a></li>
<li class="chapter" data-level="9.2.2" data-path="the-linear-model.html"><a href="the-linear-model.html#fitting-the-linear-model-in-brms"><i class="fa fa-check"></i><b>9.2.2</b> Fitting the linear model in brms</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="the-linear-model.html"><a href="the-linear-model.html#linear-models-with-categorical-predictors"><i class="fa fa-check"></i><b>9.3</b> Linear models with categorical predictors</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="the-linear-model.html"><a href="the-linear-model.html#binary-explanatory-variables"><i class="fa fa-check"></i><b>9.3.1</b> Binary explanatory variables</a></li>
<li class="chapter" data-level="9.3.2" data-path="the-linear-model.html"><a href="the-linear-model.html#categorical-predictors-with-more-than-two-categories"><i class="fa fa-check"></i><b>9.3.2</b> Categorical predictors with more than two categories</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html"><i class="fa fa-check"></i><b>10</b> Graphical Causal Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>10.1</b> Directed acyclic graphs (DAGs)</a></li>
<li class="chapter" data-level="10.2" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#three-causal-structures-in-dags"><i class="fa fa-check"></i><b>10.2</b> Three causal structures in DAGs</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-fork-confounders"><i class="fa fa-check"></i><b>10.2.1</b> The fork: confounders</a></li>
<li class="chapter" data-level="10.2.2" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-pipe-mediators"><i class="fa fa-check"></i><b>10.2.2</b> The pipe: mediators</a></li>
<li class="chapter" data-level="10.2.3" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-inverted-fork-colliders"><i class="fa fa-check"></i><b>10.2.3</b> The inverted fork: colliders</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#closing-backdoor-paths"><i class="fa fa-check"></i><b>10.3</b> Closing backdoor paths</a></li>
<li class="chapter" data-level="10.4" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#like-all-models-dags-require-assumptions"><i class="fa fa-check"></i><b>10.4</b> Like all models, DAGs require assumptions</a></li>
<li class="chapter" data-level="10.5" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#types-of-study-designs"><i class="fa fa-check"></i><b>10.5</b> Types of Study Designs</a></li>
<li class="chapter" data-level="10.6" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#experimental-studies"><i class="fa fa-check"></i><b>10.6</b> Experimental studies</a></li>
<li class="chapter" data-level="10.7" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#observational-studies"><i class="fa fa-check"></i><b>10.7</b> Observational studies</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#pros-and-cons-of-prospective-vs.-retrospective-studies-planned"><i class="fa fa-check"></i><b>10.7.1</b> Pros and cons of prospective vs. retrospective studies (planned)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html"><i class="fa fa-check"></i><b>11</b> Causal inference with linear models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#linear-models-with-multiple-predictor-variables"><i class="fa fa-check"></i><b>11.1</b> Linear models with multiple predictor variables</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#generic-linear-model-with-two-predictors"><i class="fa fa-check"></i><b>11.1.1</b> Generic linear model with two predictors</a></li>
<li class="chapter" data-level="11.1.2" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#multiple-regression-model-for-the-ice-cream-and-drownings-example"><i class="fa fa-check"></i><b>11.1.2</b> Multiple regression model for the ice cream and drownings example</a></li>
<li class="chapter" data-level="11.1.3" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#prior-predictive-check"><i class="fa fa-check"></i><b>11.1.3</b> Prior predictive check</a></li>
<li class="chapter" data-level="11.1.4" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#fitting-the-multiple-regression-model"><i class="fa fa-check"></i><b>11.1.4</b> Fitting the multiple regression model</a></li>
<li class="chapter" data-level="11.1.5" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#prediction-plots-for-multiple-regression-models"><i class="fa fa-check"></i><b>11.1.5</b> Prediction plots for multiple regression models</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#dag-informed-predictors-categorical-variables-what-multiple-regression-is-doing-with-predictor-residual-plot"><i class="fa fa-check"></i><b>11.2</b> DAG-informed predictors, categorical variables, what multiple regression is doing with predictor residual plot</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="interaction-effects.html"><a href="interaction-effects.html"><i class="fa fa-check"></i><b>12</b> Interaction effects</a></li>
<li class="chapter" data-level="13" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>13</b> Generalized linear models</a></li>
<li class="chapter" data-level="14" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>14</b> Multilevel models</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html"><i class="fa fa-check"></i><b>A</b> Estimation with frequentist inference</a>
<ul>
<li class="chapter" data-level="A.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#frequentist-estimates-are-point-estimates"><i class="fa fa-check"></i><b>A.1</b> Frequentist estimates are point estimates</a></li>
<li class="chapter" data-level="A.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions"><i class="fa fa-check"></i><b>A.2</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions-are-centered-on-the-true-parameter-value"><i class="fa fa-check"></i><b>A.2.1</b> Sampling distributions are centered on the true parameter value</a></li>
<li class="chapter" data-level="A.2.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions-allow-us-to-estimate-precision"><i class="fa fa-check"></i><b>A.2.2</b> Sampling distributions allow us to estimate precision</a></li>
<li class="chapter" data-level="A.2.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sample-size-affects-the-shape-of-sampling-distributions"><i class="fa fa-check"></i><b>A.2.3</b> Sample size affects the shape of sampling distributions</a></li>
<li class="chapter" data-level="A.2.4" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#summary-points-on-sampling-distributions"><i class="fa fa-check"></i><b>A.2.4</b> Summary points on sampling distributions</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#quantifying-uncertainty-standard-error-and-confidence-intervals"><i class="fa fa-check"></i><b>A.3</b> Quantifying uncertainty: standard error and confidence intervals</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#standard-error"><i class="fa fa-check"></i><b>A.3.1</b> Standard error</a></li>
<li class="chapter" data-level="A.3.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>A.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="A.3.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#the-standard-normal-approximation-does-not-work-well-under-low-sample-size"><i class="fa fa-check"></i><b>A.3.3</b> The standard normal approximation does not work well under low sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html"><i class="fa fa-check"></i><b>B</b> Decision-making with frequentist estimates</a>
<ul>
<li class="chapter" data-level="B.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#framework-of-classical-hypothesis-testing"><i class="fa fa-check"></i><b>B.1</b> Framework of classical hypothesis testing</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#state-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>B.1.1</b> State null and alternative hypotheses</a></li>
<li class="chapter" data-level="B.1.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#assume-the-null-hypothesis-is-true"><i class="fa fa-check"></i><b>B.1.2</b> Assume the null hypothesis is true</a></li>
<li class="chapter" data-level="B.1.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#quantify-the-likelihood-of-the-data-under-the-null-hypothesis-p-values"><i class="fa fa-check"></i><b>B.1.3</b> Quantify the likelihood of the data under the null hypothesis: P-values</a></li>
<li class="chapter" data-level="B.1.4" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#making-a-decision-based-on-the-p-value-and-significance-value"><i class="fa fa-check"></i><b>B.1.4</b> Making a decision based on the P-value and significance value</a></li>
<li class="chapter" data-level="B.1.5" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#decision-errors-happen"><i class="fa fa-check"></i><b>B.1.5</b> Decision errors happen</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#making-decisions-with-confidence-intervals"><i class="fa fa-check"></i><b>B.2</b> Making decisions with confidence intervals</a></li>
<li class="chapter" data-level="B.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#issues-with-the-null-hypothesis-framework"><i class="fa fa-check"></i><b>B.3</b> Issues with the null hypothesis framework</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#significance-testing-reinforces-binary-thinking"><i class="fa fa-check"></i><b>B.3.1</b> Significance testing reinforces binary thinking</a></li>
<li class="chapter" data-level="B.3.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#statistical-testing-reinforces-gamification-in-science"><i class="fa fa-check"></i><b>B.3.2</b> Statistical testing reinforces gamification in science</a></li>
<li class="chapter" data-level="B.3.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#statistical-significance-is-not-the-same-thing-as-practical-significance"><i class="fa fa-check"></i><b>B.3.3</b> Statistical significance is not the same thing as practical significance</a></li>
<li class="chapter" data-level="B.3.4" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#type-i-errors-become-more-likely-with-multiple-tests"><i class="fa fa-check"></i><b>B.3.4</b> Type I errors become more likely with multiple tests</a></li>
<li class="chapter" data-level="B.3.5" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-is-almost-certainly-wrong"><i class="fa fa-check"></i><b>B.3.5</b> The null hypothesis is almost certainly wrong</a></li>
<li class="chapter" data-level="B.3.6" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-focuses-on-data-you-did-not-observe"><i class="fa fa-check"></i><b>B.3.6</b> The null hypothesis focuses on data you did not observe</a></li>
<li class="chapter" data-level="B.3.7" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#a-single-null-and-alternative-hypothesis-is-too-constraining"><i class="fa fa-check"></i><b>B.3.7</b> A single null and alternative hypothesis is too constraining</a></li>
<li class="chapter" data-level="B.3.8" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-p-value-is-not-the-probability-we-want"><i class="fa fa-check"></i><b>B.3.8</b> The P-value is not the probability we want</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Research Design and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="decision-making-with-frequentist-estimates" class="section level1 hasAnchor" number="16">
<h1><span class="header-section-number">Appendix B</span> Decision-making with frequentist estimates<a href="decision-making-with-frequentist-estimates.html#decision-making-with-frequentist-estimates" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Note: add correct way to get binomial probabilitiy based on likelihood of the observation under the null for p-value</p>
<p>We have randomly sampled 100 people from a population of 10,000 and found that 8 of the 100 tested positive for a viral infection. Our frequentist estimate of the proportion infected is 0.08. We have quantified uncertainty about that estimate represented by the standard error (SE = 0.027) and confidence intervals. Based on the confidence interval, we can be 95% confident that the true proportion infected is between 0.026 and 0.134.</p>
<p>So there we have it. We have an estimate and have quantified uncertainty about the estimate with frequentist methods. What do we do with this information? Recall that our goal is to determine whether the prevalence of the infection is greater than 10%, a threshold that would trigger public health interventions. What should we conclude?</p>
<p>The decision in front of us is the crux of scientific inference. We gather structured observations to test ideas, which we can represent by numerical quantities. In this case, the quantity is a simple proportion. In other cases, we might have a causal hypothesis about how one variable affects another variable. We can represent those ideas with numerical quantities as well, and we’ll start doing that in a few chapters. But before we get there, we need to address this question of how we make a <em>decision</em> about a scientific idea based on our sample data. In this chapter, we’ll take a look at the tools to make decisions about hypotheses when estimates are made with frequentist methods.</p>
<div id="framework-of-classical-hypothesis-testing" class="section level2 hasAnchor" number="16.1">
<h2><span class="header-section-number">B.1</span> Framework of classical hypothesis testing<a href="decision-making-with-frequentist-estimates.html#framework-of-classical-hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="state-null-and-alternative-hypotheses" class="section level3 hasAnchor" number="16.1.1">
<h3><span class="header-section-number">B.1.1</span> State null and alternative hypotheses<a href="decision-making-with-frequentist-estimates.html#state-null-and-alternative-hypotheses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Classical hypothesis testing boils down to this. How likely are the observed sample data under the hypothesis that nothing interesting is going on? The idea that nothing interesting is going on is called the <strong>null hypothesis</strong>, abbreviated <span class="math inline">\(H_{0}\)</span>, which represents a hypothesis of “no effect”. Indeed, the word <em>null</em> means <em>nothing</em>.</p>
<p>Consider some examples of null hypotheses in practice. If you’re comparing the effect of a drug on blood pressure relative to a control (e.g., placebo), the null hypothesis is that there is no effect of the drug. If you’re examining the effect of greenspace around a person’s home on their mental health status, the null hypothesis is that there’s no effect of green space. If you’re examining the effect of pollution on the number of fish, the null hypothesis is that there’s no effect.</p>
<p>This is straightforward for situations where one has a causal hypothesis, but what about our case of describing the prevalence of a disease. In cases of description, the typical approach is to define the null hypothesis as a particular numerical value. For example, we could the null hypothesis that the prevalence is exactly 10%, which is the cutoff for triggering public health interventions.</p>
<p>What if we conclude the prevalence is <em>not</em> 10%? In such a case, we reject the null hypothesis and conclude the data support the <strong>alternative hypothesis</strong>, <span class="math inline">\(H_A\)</span>. The alternative hypothesis is simply the opposite of the null hypothesis. There is an effect of the drug on blood pressure, there is an effect of greenspace on mental health, there is an effect of pollution on fish population size, and the prevalence of the viral illness is not 10%.</p>
<p>Because we are using data to inform our decision about hypotheses, we need to define null and alternative hypotheses as specific quantitative values of the parameter(s) of interest. For example, to test if the prevalence of the viral illness exceeds 10%, we could test the following statistical hypotheses:</p>
<p><span class="math display">\[
H_0: p_{infected}=0.10 \\
H_A: p_{infected}&gt;0.10
\]</span></p>
<p>Here the null hypothesis is that 10% of the population is infected, and the alternative hypothesis is that greater than 10% are infected, reflecting values that would trigger interventions. The alternative hypothesis in this case is directional, specifying values only greater than 10%. This is called a <strong>one-sided</strong> hypothesis. Once our statistical hypotheses are specified numerically, we confront the hypotheses with data we’ve collected to see which hypothesis is more consistent with the data.</p>
<p>Defining statistical hypotheses numerically is straightforward for simple questions of description, but it can also be done when making causal hypotheses. For example, if we are examining the effect of pollution on fish populations, we could frame our statistical hypotheses numerically in this way:</p>
<p><span class="math display">\[
H_0: \mu_{polluted}-\mu_{unpolluted}=0 \\
H_A: \mu_{polluted}-\mu_{unpolluted}\neq0
\]</span></p>
<p>Here we’ve identified the mean number of fish in polluted and unpolluted waters as the parameters of interest. The null hypothesis says the difference in the mean number of fish between polluted and unpolluted areas is 0, meaning there is no difference between the means, which is what we might expect if pollution has no effect on fish populations. In this case the hypothesis is <strong>two-sided</strong> because it does not specify directionality of a potential effect, allowing for the possibility that fish are more populated in polluted than unpolluted areas, or vice-versa. For reasons we will see later, it is generally more conservative (and often more appropriate for causal hypotheses) to use two-sided tests.</p>
<p>Ultimately the precise way in which null and alternative hypotheses are framed depends on the research question and the parameters that best represent the scientific hypothesis being tested. Sometimes those parameters are simple means and proportions, and other times they will be values from more complex quantitative models, such as linear models that we’ll turn our attention to in a few chapters.</p>
</div>
<div id="assume-the-null-hypothesis-is-true" class="section level3 hasAnchor" number="16.1.2">
<h3><span class="header-section-number">B.1.2</span> Assume the null hypothesis is true<a href="decision-making-with-frequentist-estimates.html#assume-the-null-hypothesis-is-true" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So far we have seen that hypothesis testing involves flipping a scientific hypothesis on its head by forming a null hypothesis that assumes <em>no effect</em>, or that nothing interesting is going on. As if that wasn’t peculiar enough, we now presume that the null hypothesis is true. Why do that?</p>
<p>To understand the focus on a null hypothesis, it’s critical to remember that the foundation of frequentist inference is the idea that probability is defined in terms of long-run frequency. The concept of the sampling distribution illustrates this idea nicely. Consider that we’re testing the hypothesis that pollution affects fish population size by comparing the mean number of fish between polluted and unpolluted areas. The frequentist approach assumes there is some true value for the difference in the mean population size between these areas. We can estimate the difference in the means between areas in each sample, but the challenge we face is that we are likely to find <em>some</em> difference in the means between areas even if only by chance. Indeed, the sampling distribution shows us that the estimates of any quanity from random samples will form a probability distribution around the true value of the parameter. Estimates close to the true parameter are most likely, but deviations from the truth happen because of sampling error.</p>
<p>Now, in practice we don’t know the true difference in the means, which is why we’re doing the study in the first place! Without knowing the true difference in the means, we can’t describe the actual sampling distribution. But what we can do is assume the parameter takes on a particular value. If we do that, we can describe the sampling distribution based on that assumed parameter value and the estimated standard error, and then we can ask how likely it is that we’d see the particular estimate in our sample data under that assumption.</p>
<p>Fundamentally, frequentist hypothesis testing is basically about asking how likely the observed data are from a sample under some assumed parameter value. But what value should we assume for the parameter? Should we assume a value that reflects our scientific hypothesis? Perhaps the scientific hypothesis is that pollution will reduce fish populations because of toxicity effects on survival and reproduction. Makes sense. But what parameter value would best reflect that hypothesis? Should we assume the mean population size is 200 in polluted waters and 500 in unpolluted waters, such that the difference of the means is 300? Or what about a smaller effect, such as 467 in unpolluted waters and 425 in polluted waters, for a difference of 42?</p>
<p>Hopefully you see the problem. There’s an infinite number of possible values that the parameter could take on to be consistent with our scientific hypothesis. Frequentists solve this problem by isolating the <em>one</em> parameter value that would <em>not</em> be consistent with teh scientific model, namely that there’s no difference in fish populations between polluted and unpolluted waters. In other words, the null hypothesis! The only numerical value for the difference in the means consistent with the null hypothesis is 0. It’s much more tractable to form the sampling distribution around the null hypothesis, and then quantify how likely the data are in light of that null hypothesis. The idea is that if the data aren’t all that likely under the null hypothesis, then maybe the null hypothesis is wrong!</p>
<p>So ultimately the frequentist approach focuses on the null hypothesis because we can isolate a single parameter value for the null hypothesis to form a sampling distribution and quantify the likelihood of our data from that sampling distribution. The sampling distribution for the null hypothesis is called the <strong>null distribution</strong>. If the sample data are relatively likely under the null distribution, then we can conclude the data are consistent with the null hypothesis. If the sample data are very unlikely under the null distribution, then we will reject the null hypothesis and conclude the data support the alternative hypothesis, which is just the inverse of the null.</p>
<p>Assuming the null hypothesis is true is not an intuitive approach given that our scientific hypothesis is that there <em>is</em> an effect of pollution, but under the frequentist approach, it’s the most practical option. If your head is spinning and you’re thinking there are some problems with this approach, stay tuned! We’ll address some of those challenges, but first let’s finish working through the process.</p>
</div>
<div id="quantify-the-likelihood-of-the-data-under-the-null-hypothesis-p-values" class="section level3 hasAnchor" number="16.1.3">
<h3><span class="header-section-number">B.1.3</span> Quantify the likelihood of the data under the null hypothesis: P-values<a href="decision-making-with-frequentist-estimates.html#quantify-the-likelihood-of-the-data-under-the-null-hypothesis-p-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Once we have defined the null hypothesis and have the data in hand, we can go ahead and quantify how likely the data are assuming the null hypothesis is true. Remember: the general idea here is that when we randomly sample from populations, we always expect some deviation between a sample estimate and the true parameter value because of sampling error. We can minimize that sampling error by maximizing sample sizes, but it never completely goes away. With a defined null hypothesis, we can quantify the probability of observing the data from our particular sample occurring simply by chance with a <strong>P-value</strong>.</p>
<p>Let’s quantify a P-value for our question about the prevalence of the viral infection. To keep things simple for now, we’re going to test the null hypothesis that the proportion infected is exactly 10%, with a two-sided alternative hypothesis that the proportion infected is not 10%:</p>
<p><span class="math display">\[
H_0: p_{infected}=0.10 \\
H_A: p_{infected}\neq0.10
\]</span></p>
<p>We observed 8 out of 100 infected, for an estimated prevalence of 8%. The question now before us is how likely that observation is under the null hypothesis that the prevalence is 10%, which we will quantify as a P-value. Actually, this isn’t <em>quite</em> a P-value. Sorry, but it gets just a tad more complicated (and confusing). Rather than simply quantifying the probability of the observed data (the estimated prevalence of 8%) under the null distribution, we actually quantify the probability of the observed data <em>or data that are more extreme than the observed data relative to the null hypothesis</em>. What values are more extreme than 8% relative to the null hypothesized value of 10% when we take a sample of N = 100? Well, 7%, 6%, 5%, 4%, and so on. And because we are assuming a two-sided alternative hypothesis, values of 12%, 13%, 14%, etc. are equally or more extreme than 8% in relationship to the null hypothesized value.</p>
<p>Why do this? Why not just quantify the probability of the data point we observed under the null hypothesis that <span class="math inline">\(p_{infected} = 0.1\)</span> and call it good? We know how to do that with the <code>dbinom</code> function:</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="decision-making-with-frequentist-estimates.html#cb414-1" tabindex="-1"></a><span class="co">#exact probability of 8 out of 100 positives when p = 0.1</span></span>
<span id="cb414-2"><a href="decision-making-with-frequentist-estimates.html#cb414-2" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">8</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> <span class="fl">0.1</span>)</span></code></pre></div>
<pre><code>## [1] 0.114823</code></pre>
<p>Indeed, the probability of 8 positives out of 100 tests when the prevalence is 10$ is exactly 0.115. But we don’t stop there for a couple reasons. First, the goal of null hypothesis testing is to understand how unusual the data are relative to the null hypothesized value, and we can’t really tell how unusual the observation is without considering how likely more extreme observations would have been. Think of those observations as a sort of reference point. Second, consider a scenario where we had sampled more than 100 people. For example, assume we conducted N = 1000 tests. With 1000 tests there is much more resolution on the parameter space, where we can estimate prevalence down to the thousandths in comparison to the hundredths with a sample size of 100. That means the probability of any given outcome is lower with N = 1000 tests than N = 100 tests, simply because there are more possible outcomes. Indeed, the exact probability of 80 positives out of 1000 tests with p = 0.1 is only 0.004. That observation alone is unusual in large part because there are so many possible outcomes. This problem gets even worse for continuous distributions, where we can’t quantify the probability of any single outcome at all because there are an infinite number of possible outcomes!</p>
<p>The solution to this issue is the quantify the probability of a range of possible values. Because the goal of null hypothesis testing is to try to identify if the data are unusual under the null hypothesis, we focus specifically on the probability of all outcomes <em>at least</em> as extreme as the data we observed. Thus, the P-value is defined as the probability of sample estimates at least as extreme as the one we observed relative to the null hypothesis, all conditional on the null hypothesis being true. And when we use a two-sided alternative hypothesis, we consider observations that are at least as extreme as the one we observed both above and below the null hypothesized value.</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="decision-making-with-frequentist-estimates.html#cb416-1" tabindex="-1"></a><span class="co">#all possible values of positive tests out of N = 100</span></span>
<span id="cb416-2"><a href="decision-making-with-frequentist-estimates.html#cb416-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb416-3"><a href="decision-making-with-frequentist-estimates.html#cb416-3" tabindex="-1"></a></span>
<span id="cb416-4"><a href="decision-making-with-frequentist-estimates.html#cb416-4" tabindex="-1"></a><span class="co">#probability of each outcome assuming prevalence is 11%</span></span>
<span id="cb416-5"><a href="decision-making-with-frequentist-estimates.html#cb416-5" tabindex="-1"></a>p.hat <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> x, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> <span class="fl">0.10</span>)</span>
<span id="cb416-6"><a href="decision-making-with-frequentist-estimates.html#cb416-6" tabindex="-1"></a></span>
<span id="cb416-7"><a href="decision-making-with-frequentist-estimates.html#cb416-7" tabindex="-1"></a><span class="co">#combine into a data frame</span></span>
<span id="cb416-8"><a href="decision-making-with-frequentist-estimates.html#cb416-8" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(x, p.hat)</span>
<span id="cb416-9"><a href="decision-making-with-frequentist-estimates.html#cb416-9" tabindex="-1"></a>d<span class="sc">$</span>pval <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(d<span class="sc">$</span>x <span class="sc">&lt;=</span> <span class="dv">8</span> <span class="sc">|</span> d<span class="sc">$</span>x <span class="sc">&gt;=</span><span class="dv">12</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span>)</span>
<span id="cb416-10"><a href="decision-making-with-frequentist-estimates.html#cb416-10" tabindex="-1"></a></span>
<span id="cb416-11"><a href="decision-making-with-frequentist-estimates.html#cb416-11" tabindex="-1"></a><span class="co">#plot the sampling distribution</span></span>
<span id="cb416-12"><a href="decision-making-with-frequentist-estimates.html#cb416-12" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> p.hat, <span class="at">fill =</span> pval)) <span class="sc">+</span></span>
<span id="cb416-13"><a href="decision-making-with-frequentist-estimates.html#cb416-13" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">width =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">show.legend=</span><span class="cn">FALSE</span>) <span class="sc">+</span> </span>
<span id="cb416-14"><a href="decision-making-with-frequentist-estimates.html#cb416-14" tabindex="-1"></a> <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;TRUE&quot;</span> <span class="ot">=</span> <span class="st">&quot;darkorange&quot;</span>, <span class="st">&quot;FALSE&quot;</span> <span class="ot">=</span> <span class="st">&quot;steelblue&quot;</span>)) <span class="sc">+</span></span>
<span id="cb416-15"><a href="decision-making-with-frequentist-estimates.html#cb416-15" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Number of positives out of N = 100&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Probability&quot;</span>) <span class="sc">+</span></span>
<span id="cb416-16"><a href="decision-making-with-frequentist-estimates.html#cb416-16" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">30</span>) <span class="sc">+</span></span>
<span id="cb416-17"><a href="decision-making-with-frequentist-estimates.html#cb416-17" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:a02c02"></span>
<img src="appendix02_decision_freq_files/figure-html/a02c02-1.png" alt="Null distribution of the prevalence of infection based on a sample of N = 100 assuming the true prevalence is 10%. The values highlighted in orange make up the P-value for a two-sided hypothesis test when there are X = 8 positives." width="70%" />
<p class="caption">
Figure B.1: Null distribution of the prevalence of infection based on a sample of N = 100 assuming the true prevalence is 10%. The values highlighted in orange make up the P-value for a two-sided hypothesis test when there are X = 8 positives.
</p>
</div>
<p>Figure <a href="decision-making-with-frequentist-estimates.html#fig:a02c02">B.1</a> illustrates the null distribution assuming the true prevalence is 10%, and it highlights the values used to quantify the P-value. This includes the actual observation of 8 positive tests, plus all lower values, as well as observations of 12 and above. We can quantify the P-value in this way:</p>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="decision-making-with-frequentist-estimates.html#cb417-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">8</span>, <span class="dv">12</span><span class="sc">:</span><span class="dv">100</span>), <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob=</span><span class="fl">0.1</span>))</span></code></pre></div>
<pre><code>## [1] 0.6178408</code></pre>
<p>Here we see the p-value is 0.62. In other words, there was a 62% chance of seeing 8 or fewer positive tests, or 12 or more positive tests, if the true prevalence was exactly 10%.</p>
<p>Now in our particular circumstance, it is probably more appropriate to use a one-sided test because we are explicitly interested in the the possibility that the prevalence of the infection is <em>above</em> 10%. In such a case, we specify our statistical hypotheses in this way:</p>
<p><span class="math display">\[
H_0: p_{infected}=0.10 \\
H_A: p_{infected}&gt;0.10
\]</span></p>
<p>A one-sided tests requires a different approach to quantify the P-value than a two-sided test. Whereas we include observations in both tails of the null distribution to quantify the P-value for a two-sided test, we include only values into the tail specified by the alternative hypothesis in a one-sided test. For our case of 8 out of 100 tests, that means we need to include the probability of getting 8, 9, 10, 11, 12, and so on out of 100 positives, which is illustrated in Figure <a href="decision-making-with-frequentist-estimates.html#fig:a02c04">B.2</a>.</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="decision-making-with-frequentist-estimates.html#cb419-1" tabindex="-1"></a><span class="co">#all possible values of positive tests out of N = 100</span></span>
<span id="cb419-2"><a href="decision-making-with-frequentist-estimates.html#cb419-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb419-3"><a href="decision-making-with-frequentist-estimates.html#cb419-3" tabindex="-1"></a></span>
<span id="cb419-4"><a href="decision-making-with-frequentist-estimates.html#cb419-4" tabindex="-1"></a><span class="co">#probability of each outcome assuming prevalence is 11%</span></span>
<span id="cb419-5"><a href="decision-making-with-frequentist-estimates.html#cb419-5" tabindex="-1"></a>p.hat <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> x, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> <span class="fl">0.10</span>)</span>
<span id="cb419-6"><a href="decision-making-with-frequentist-estimates.html#cb419-6" tabindex="-1"></a></span>
<span id="cb419-7"><a href="decision-making-with-frequentist-estimates.html#cb419-7" tabindex="-1"></a><span class="co">#combine into a data frame</span></span>
<span id="cb419-8"><a href="decision-making-with-frequentist-estimates.html#cb419-8" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(x, p.hat)</span>
<span id="cb419-9"><a href="decision-making-with-frequentist-estimates.html#cb419-9" tabindex="-1"></a>d<span class="sc">$</span>pval <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(d<span class="sc">$</span>x <span class="sc">&gt;=</span> <span class="dv">8</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span>)</span>
<span id="cb419-10"><a href="decision-making-with-frequentist-estimates.html#cb419-10" tabindex="-1"></a></span>
<span id="cb419-11"><a href="decision-making-with-frequentist-estimates.html#cb419-11" tabindex="-1"></a><span class="co">#plot the sampling distribution</span></span>
<span id="cb419-12"><a href="decision-making-with-frequentist-estimates.html#cb419-12" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> p.hat, <span class="at">fill =</span> pval)) <span class="sc">+</span></span>
<span id="cb419-13"><a href="decision-making-with-frequentist-estimates.html#cb419-13" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">width =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">show.legend=</span><span class="cn">FALSE</span>) <span class="sc">+</span> </span>
<span id="cb419-14"><a href="decision-making-with-frequentist-estimates.html#cb419-14" tabindex="-1"></a> <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;TRUE&quot;</span> <span class="ot">=</span> <span class="st">&quot;darkorange&quot;</span>, <span class="st">&quot;FALSE&quot;</span> <span class="ot">=</span> <span class="st">&quot;steelblue&quot;</span>)) <span class="sc">+</span></span>
<span id="cb419-15"><a href="decision-making-with-frequentist-estimates.html#cb419-15" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Number of positives out of N = 100&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Probability&quot;</span>) <span class="sc">+</span></span>
<span id="cb419-16"><a href="decision-making-with-frequentist-estimates.html#cb419-16" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">30</span>) <span class="sc">+</span></span>
<span id="cb419-17"><a href="decision-making-with-frequentist-estimates.html#cb419-17" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:a02c04"></span>
<img src="appendix02_decision_freq_files/figure-html/a02c04-1.png" alt="Null distribution of the prevalence of infection based on a sample of N = 100 assuming the true prevalence is 10%. The values highlighted in orange make up the P-value for a one-sided hypothesis test when there are X = 8 positives." width="70%" />
<p class="caption">
Figure B.2: Null distribution of the prevalence of infection based on a sample of N = 100 assuming the true prevalence is 10%. The values highlighted in orange make up the P-value for a one-sided hypothesis test when there are X = 8 positives.
</p>
</div>
<p>The P-value for the one-sided test is:</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="decision-making-with-frequentist-estimates.html#cb420-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">8</span><span class="sc">:</span><span class="dv">100</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob=</span><span class="fl">0.1</span>))</span></code></pre></div>
<pre><code>## [1] 0.7939491</code></pre>
<p>We see that the P-value for a two-sided hypothesis test is 0.79. In other words, there was a 79% chance of seeing observations of 8 or more positive tests when the true prevalence is 10%.</p>
</div>
<div id="making-a-decision-based-on-the-p-value-and-significance-value" class="section level3 hasAnchor" number="16.1.4">
<h3><span class="header-section-number">B.1.4</span> Making a decision based on the P-value and significance value<a href="decision-making-with-frequentist-estimates.html#making-a-decision-based-on-the-p-value-and-significance-value" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hypothesis testing involves making a decision between two competing statistical hypotheses: the null and alternative. Indeed, these hypotheses are defined in a way to be mutually exclusive. If the prevalence of the disease is 10% (null hypothesis), then it must be some value other than 10% (alternative hypothesis). The goal is to determine if the data are more consistent with one hypothesis than another.</p>
<p>To accomplish this goal, the P-value is used to examine the likelihood of the data under the null hypothesis. The idea is that if the P-value is high, it means that the data are very consistent with the null hypothesis, and so perhaps the null hypothesis is true. Indeed, we saw the P-value was 0.79 when considering the null hypothesis that the prevalence of the infection is 10% against the alternative that the prevalence is greater than 10%. In other words, there was a 79% of seeing our data, or more extreme observations, if the prevalence is really 10%. Because that set of observations is quite likely under the null hypothesis, we conclude that the data support the null hypothesis and are inconsistent with the alternative hypothesis that the prevalence is greater than 10%.</p>
<p>But when should we conclude the opposite, that the data <em>don’t</em> support the null hypothesis. Remember the <strong>significance value</strong> from the last chapter? The significance value, <span class="math inline">\(\alpha\)</span>, represents a specific probability of observations being in the tails of the null distribution. In null hypothesis testing, the significance value represents the threshold for rejecting the null hypothesis. The most typical value of <span class="math inline">\(\alpha\)</span> is 0.05, such that if the P-value is below 0.05, one should conclude that the data do not support the null hypothesis. The idea is that if there’s a less than 5% chance of seeing the observed data (or more extreme observations) under the null hypothesis, then maybe the null hypothesis isn’t true. Those observations are so rare that we typically reject the null hypothesis and conclude that the data supports the alternative hypothesis.</p>
<p>For example, suppose that instead of finding X = 8 positives out of N = 100 tests, we find X = 17 positives instead. Let’s compute the P-value under the null that the prevalence is 10% and the alternative that the prevalence is greater than 10%:</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="decision-making-with-frequentist-estimates.html#cb422-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">17</span><span class="sc">:</span><span class="dv">100</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob=</span><span class="fl">0.1</span>))</span></code></pre></div>
<pre><code>## [1] 0.02059881</code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:a02c07"></span>
<img src="appendix02_decision_freq_files/figure-html/a02c07-1.png" alt="Null distribution of the prevalence of infection based on a sample of N = 100 individuals assuming the true prevalence is 10%. The values highlighted in orange make up the P-value for a one-sided hypothesis test when there are X = 17 positives." width="70%" />
<p class="caption">
Figure B.3: Null distribution of the prevalence of infection based on a sample of N = 100 individuals assuming the true prevalence is 10%. The values highlighted in orange make up the P-value for a one-sided hypothesis test when there are X = 17 positives.
</p>
</div>
<p>We see the P-value in this case with X = 17 positives is only 2%. Figure <a href="decision-making-with-frequentist-estimates.html#fig:a02c07">B.3</a> illustrates the null distribution and highlights the values used to compute the P-value in this case. The interpretation here is that there was only a 2% chance of getting 17 or greater positives if the true prevalence was 10%. Because the P-value is below the significance value of 0.05, we would reject the null hypothesis and conclude the data support the alternative hypothesis that the prevalence is greater than 10%.</p>
</div>
<div id="decision-errors-happen" class="section level3 hasAnchor" number="16.1.5">
<h3><span class="header-section-number">B.1.5</span> Decision errors happen<a href="decision-making-with-frequentist-estimates.html#decision-errors-happen" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you think about it, the sampling distribution tells us that we <em>should</em> see the observations outer 5% of the null distribution exactly 5% of the time <em>when the null hypothesis is true</em>. Indeed, extreme observations happen just by chance! We’re simply concluding that our one sample estimate in those tails is not a chance event, but we could be wrong. How often will we be wrong in this case? Well, exactly 5% of the time, or whatever level we set for the significance value.</p>
<p>This kind of error, where we reject a null hypothesis that is actually true, is (boringly) called a <strong>Type I error</strong>. The idea is simply that if we can imagine the null hypothesis is actually true and we repeat our sampling process thousands of times, we would see extreme observations in the outer 5% of the null distribution exactly 5% of the time.</p>
<p>We can also make the opposite error, namely <em>failing</em> to reject a null hypothesis that is false. This is called a <strong>Type II error</strong>, and unlike a Type I error, the probability of a Type II error is not straightforward. In general, the probability of a Type II error is most common under the following circumstances:</p>
<ul>
<li>The quantities being estimated are estimated with low precision (i.e., high standard error). Remembering that the standard error is a ratio of the standard deviation (variability among observations) to teh sample size, we know that precision is lowest when there is high variability int he observations and low sample size. In other words, low sample size and high variability in the observations both contribute to a greater likelihood of a Type II error.</li>
<li>The <strong>effect size</strong> is small. Imagine you are comparing the difference in mean population size of those fish between polluted and unpolluted areas. The magnitude of the difference in the mean population between polluted and unpolluted areas is the effect size. When effect sizes are small, in this case only a small difference in the population sizes between areas, then the probability of a Type II error is greater.</li>
<li>Low significance value. There’s nothign special about a significane value of 0.05. Indeed, one could set it higher or lower, but there’s a trade-off. Lowering the significance value will decrese the probability of a Type I error, but at the same time it will increase the probability of a Type II error!</li>
</ul>
<p>The probability of a Type II error is referred to as <span class="math inline">\(\beta\)</span>, and the inverse if the probability of a Type II error (<span class="math inline">\(1-\beta\)</span>) is called the <em>power</em> of a statistical test. The general goal when designing a study for a classical hypothesis test is to maximize power, or in other words, minimize the probability of making a Type II error. Researchers can only control some aspects of study design that affect power, namely the sample size (increase power by increasing sample size) and significance value (increase power by increasing the significance vqlue, but of course at greater risk of committing a Type I error).</p>
</div>
</div>
<div id="making-decisions-with-confidence-intervals" class="section level2 hasAnchor" number="16.2">
<h2><span class="header-section-number">B.2</span> Making decisions with confidence intervals<a href="decision-making-with-frequentist-estimates.html#making-decisions-with-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Statistical hypotheses can be evaluated without P-values, namely by using confidence intervals. Recall in the last chapter we estimated the 95% confidence interval for the true proportion infected was 2.7 - 13.3% based on our 8 observed positives. Note that our null hypothesized value of 10% is in the 95% confidence interval, so in other words it is considered a plausible value of the proportion infected based on our sample data. In this case, we would conclude with the confidence interval alone that the data are consistent with the null hypothesis that 10% of individuals are infected.</p>
<p>In some ways the 95% confidence interval gives you more information than a null hypothesis test of a single value. How so? Well, the range of values in the 95% confidence intervals defines the values of the paramter for which you would <em>not</em> reject the null hypothesis at a significance value of 5% (specifically when assuming a two-sided alternative hypothesis). In other words, suppose we defined the null hypothesis as <span class="math inline">\(p_{infected} = 0.124%\)</span> and the alternative as <span class="math inline">\(p_{infected} \neq 0.124\)</span>. Because 12.4% is in the 95% confidence interval, we would not reject the null hypothesis in that case. Any time the null hypothesis is between 2.4% and 13.3%, we wouldn’t reject it at the 5% significance levels.</p>
<p>We can interpret confidence intervals in the same way at any degree of confidence. The corollary is that the interval is defining the range of parameter values for which we wouldn’t reject the null hypothesis at the significance value being used.</p>
</div>
<div id="issues-with-the-null-hypothesis-framework" class="section level2 hasAnchor" number="16.3">
<h2><span class="header-section-number">B.3</span> Issues with the null hypothesis framework<a href="decision-making-with-frequentist-estimates.html#issues-with-the-null-hypothesis-framework" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Does your brain hurt after reading to this point? Don’t feel bad if it does. Decision theory with frequentist inference is not the most intuitive set of ideas! In this section we take a brief look at some of the flaws and criticisms of classic hypothesis testings.</p>
<div id="significance-testing-reinforces-binary-thinking" class="section level3 hasAnchor" number="16.3.1">
<h3><span class="header-section-number">B.3.1</span> Significance testing reinforces binary thinking<a href="decision-making-with-frequentist-estimates.html#significance-testing-reinforces-binary-thinking" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In my decade plus of teaching null hypothesis testing and emphasizing that scientists and statisticians are not in the business of certainty, I have continued to see students take a box-checking type of approach to making decisions about null hypotheses. “If the P-value is less than 0.05, reject the null hypothesis and accept the alternative hypothesis. If the P-value is greater than or equal to 0.05, accept the null hypothesis.” This is classic binary thinking - that the data we collect will produce a P-value that we can use to make a definitive either/or decision about our statistical hypotheses.</p>
<p>I don’t blame students of statistics for thinking this way. The competition between two diametrically opposed hypotheses and the predominance of a standard threshold for the significance value (0.05) reinforces the misconception that the results of statistical analyses can be boiled down to “significant” (i.e., P &lt; 0.05, reject the null) or “not significant” (P &gt; 0.05, accept the null). I thought this way myself when I was learning statistics. It took years of practice (and teaching) to really understand these concepts and the nuances of interpretation.</p>
<p>Although it must be true that null hypotheses (or any hypothesis) are either right or wrong, statistical evidence can never get us to the point where we can conclude with certainty that a null hypothesis is right or wrong. We have to think about hypotheses probabilistically in light of the evidence in front of us. Null hypothesis testing gives students of statistics the illusion that we can conduct statistical tests and find “the answer” based on a P-value.</p>
</div>
<div id="statistical-testing-reinforces-gamification-in-science" class="section level3 hasAnchor" number="16.3.2">
<h3><span class="header-section-number">B.3.2</span> Statistical testing reinforces gamification in science<a href="decision-making-with-frequentist-estimates.html#statistical-testing-reinforces-gamification-in-science" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Why is the significance value typically 0.05? Why not 0.047? Or 0.09? We could clearly trace the history of the significance value set at 0.05 to early frequentist statisticians, but it’s just not my goal. There’s ultimately no good reason to set the value to 0.05. It’s arbitrary.</p>
<p>One of the problems with using an arbitrary threshold - and this is related to the idea that significance testing reinforces binary thinking - is that scientists know what they have to do to find a significant result. The last thing scientists want to see when fitting a statistical model on their computer is the output “P = 0.72”. Not significant, not publishable. Sadly that has been the state of science publishing, and it has reinforced bad behavior.</p>
<p>What kind of behaviors? Basically the culture of publishing has incentivized research practices to achieve significant results rather than to achieve trustworthy results. Any scientist who does their own statistical analysis knows that there are often many ways one could analyze the data to shed light on a hypothesis. Some scientists - again, encouraged by the incentives of publishing, which affects promotions, grant seeking, and more - have engaged in what is called <strong>p-hacking</strong>, essentially the practice of analyzing the data multiple ways in hopes that one of those ways produces something like “P = 0.003” on their computer screen. This is thought to explain why the <strong>reproducibility</strong> crisis in some fields, where the findings from many studies that have been published cannot be replicated.</p>
</div>
<div id="statistical-significance-is-not-the-same-thing-as-practical-significance" class="section level3 hasAnchor" number="16.3.3">
<h3><span class="header-section-number">B.3.3</span> Statistical significance is not the same thing as practical significance<a href="decision-making-with-frequentist-estimates.html#statistical-significance-is-not-the-same-thing-as-practical-significance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I once reviewed a paper where the researchers were interested in whether the genetic distance between individuals in a wildlife population (basically the inverse of genetic relatedness) was related to the physical distance between them. The data looked like Figure <a href="#fig:a02chunk08"><strong>??</strong></a>, which shows N = 3000 data points and a line that summarizes the relationship between genetic distance and physical distance. If you fit a model to test the null hypothesis that the slope of that line is exactly 0, you would compute a P-value of P = 0.02, leading one to reject the null hypothesis and conclude that the genetic distance is positively related to physical distance. And that’s exactly what the authors did.</p>
<p>Hopefully you can see the problem. Although the finding is “statistically significant”, the strength of the relationship between genetic and physical distance is rather unimpressive. This is an important lesson. Statistical significance is not equivalent to practical significance in one’s field.</p>
<p>Why do we see cases like this? The problem is that P-values are affected by sample size in frequentist statistical tests. Increasing the sample size reduces the standard error, which increases the precision with which even a small effect size can be detected.</p>
<p>It’s important to note that not finding statistical significance does not rule out practical importance. Because P-values are affected by sample size, one might find what appears to be a strong effect even with a P-value above 0.05. Consider our example of fish populations and pollution. Suppose you find a mean difference in fish populations of 100 between polluted and unpolluted water such as a mean difference of N = 40 individuals between polluted and unpolluted waters. Also assume the standard deviation of population size among locations is 50. If these estimates were made with a sample size of N = 50 polluted and unpolluted locations each, the P-value would be 0.0002. However, if the same estimates were made with a sample size of N = 10 polluted and unpolluted locations each, the P-value would be 0.08. Same effect size, but a borderline P-value when the sample size is low. Rather than outright accepting the null hypotheses, a better practice would be to consider the effect size in light of the low sample size.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:a02c08"></span>
<img src="appendix02_decision_freq_files/figure-html/a02c08-1.png" alt="Simulated relationship of genetic distance to physical distance between individuals in a wildlife population. There are 3000 data points and the P-value for the null hypothesis that the slope of the line relating genetic distance to physical distance is P = 0.02, which would lead to rejecting the null hypothesis." width="70%" />
<p class="caption">
Figure B.4: Simulated relationship of genetic distance to physical distance between individuals in a wildlife population. There are 3000 data points and the P-value for the null hypothesis that the slope of the line relating genetic distance to physical distance is P = 0.02, which would lead to rejecting the null hypothesis.
</p>
</div>
</div>
<div id="type-i-errors-become-more-likely-with-multiple-tests" class="section level3 hasAnchor" number="16.3.4">
<h3><span class="header-section-number">B.3.4</span> Type I errors become more likely with multiple tests<a href="decision-making-with-frequentist-estimates.html#type-i-errors-become-more-likely-with-multiple-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider again the case of estimating the prevalence of a respiratory illness. Suppose that for each person brought in for a random test, you collect 10 measurements about each individual to investigate potential differences between infected and non-infected individuals. This might include individual’s sex, weight, BMI, exposure history, and so on. After the test results come back, you conduct a hypothesis test comparing the infected and non-infected groups for each of those 10 measurements. You use the standard significance value of 0.05 for each test, and so the probability of making a Type I error (rejecting a true null hypothesis) is 0.05 for each test. What’s the probability of making at least one Type I error?</p>
<p>The most efficient solution to this question is to quantify the probability of making no Type I errors, and then applying the not rule to find the probability of at least one Type I error. When we conduct 10 tests each with a 0.05 probability of a Type I error, the probability of making no Type I errors is <span class="math inline">\((1-0.05)^{10}\)</span>, and so the probability of making at least one Type I error is <span class="math inline">\(1 - (1-0.05)^{10}=0.40\)</span>. Wow - a 40% chance of making at least one Type I errors when we conduct 10 tests. This is the problem of making <strong>multiple comparisons</strong>. For each additional hypothesis test, the probability of making at least one Type I error increases.</p>
<p>The probability of making at least one Type I error across a <em>family</em> of tests is sometimes called the <strong>family-wise Type I error rate</strong>, and it can be quantified as <span class="math inline">\(1-(1 - \alpha)^N\)</span>, where <span class="math inline">\(\alpha\)</span> is the significance level for each test and N is the number of tests. When multiple tests are conducted in a single study, the probability of a spurious result increases with each additional test. One way to combat this is by applying a correction to maintain the family-wise error rate at 0.05. One popular correction is the <strong>Bonferonni correction</strong>, which is applied by using a corrected significance for each test that is based on the number of tests: <span class="math inline">\(0.05/N\)</span>. Thus, if we were to conduct 10 tests, we could use a corrected alpha of <span class="math inline">\(0.05/10=0.005\)</span> for each test to maintain the family-wise Type I error rate at 0.05.</p>
</div>
<div id="the-null-hypothesis-is-almost-certainly-wrong" class="section level3 hasAnchor" number="16.3.5">
<h3><span class="header-section-number">B.3.5</span> The null hypothesis is almost certainly wrong<a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-is-almost-certainly-wrong" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the null hypothesis that the prevalence of a disease is 10%. The claim is that the prevalence is <em>exactly</em> <span class="math inline">\(10.\bar{0}\%\)</span>. That hypothesis is almost certainly wrong. If the prevalence was 9.9%, or 10.3%, we should technically reject teh null hypothesis. If you’re evaluating the effect of some new drug on an outcome, the likelihood that the drug has <em>exactly</em> no impact is very low. At best all we can do with frequentist hypothesis tests is say that there’s either enough information to reject the null hypothesis, or there is not. But why test a null hypothesis that is almost certainly not true to begin with?</p>
</div>
<div id="the-null-hypothesis-focuses-on-data-you-did-not-observe" class="section level3 hasAnchor" number="16.3.6">
<h3><span class="header-section-number">B.3.6</span> The null hypothesis focuses on data you did not observe<a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-focuses-on-data-you-did-not-observe" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall the P-value does not just measure the likelihood of the data you actually observed, assuming the null hypothesis is true. It measures the likelihood of the data you observed, <em>or data equally or more extreme</em>, assuming the null hypothesis is true. Why should we be asking about the probability of data we didn’t actually observed?</p>
<p>Moreover, because the P-value is quantified based on tail regions of the sampling distribution more extreme than the observed data, scientists can game the system by changing the type of tail region to include. This could be done by conducting a one-tailed hypothesis tests, which will cut the P-value exactly in half, increasing the likelihoood of rejecting the null hypothesis, or by using a different kind of probability distribution for null distribution that has lower probability in the tail.</p>
</div>
<div id="a-single-null-and-alternative-hypothesis-is-too-constraining" class="section level3 hasAnchor" number="16.3.7">
<h3><span class="header-section-number">B.3.7</span> A single null and alternative hypothesis is too constraining<a href="decision-making-with-frequentist-estimates.html#a-single-null-and-alternative-hypothesis-is-too-constraining" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that our epidemiological goal was to examine whether the prevalence of the disease was greater than 10%. We want to know this because public health measures will be implemented at that level. But how do test whether the prevalence of disease is greater than 10% in a null hypothesis framework? The null hypothesis requires a specific value for the parameter of interest. That’s why we set the null hypothesis to exactly 10% rather than looking at a set of possible values. We <em>were</em> able to specify a set of possible values for the alternative hypothesis, but remember that in the end, null hypothesis significance testing is a test of the null hypothesis, not the alternative hypothesis.</p>
</div>
<div id="the-p-value-is-not-the-probability-we-want" class="section level3 hasAnchor" number="16.3.8">
<h3><span class="header-section-number">B.3.8</span> The P-value is not the probability we want<a href="decision-making-with-frequentist-estimates.html#the-p-value-is-not-the-probability-we-want" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I’ll save the best for last. When we conduct a scientific study, what we really want to know is the probability that a scientific hypothesis is true. We represent those scientific hypotheses by quantitative parameters that we can estimate from data, but with null hypothesis significance testing, we never actually quantify the probability of a hypothesis. P-values are frequently interpreted as the probability that the null hypothesis is true, but that interpretation is wrong. A P-value is the probability of observing the data or more extreme observations <em>all conditional on the null hypothesis being true</em>. P-values are conditional probabilities: P(data | hypothesis). What we really want is the reverse conditional probability: P(hypothesis | data), but P-values don’t give us that.</p>

</div>
</div>
</div>










            </section>

          </div>
        </div>
      </div>
<a href="estimation-with-frequentist-inference.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["research-design-and-statistics.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true,
    "toc_depth": 2
  },
  "toolbar": {
    "position": "fixed"
  },
  "info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
