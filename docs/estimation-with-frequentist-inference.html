<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 15 Estimation with frequentist inference | Research Design and Statistics</title>
  <meta name="description" content="An introduction to research design and statistics" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 15 Estimation with frequentist inference | Research Design and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An introduction to research design and statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 15 Estimation with frequentist inference | Research Design and Statistics" />
  
  <meta name="twitter:description" content="An introduction to research design and statistics" />
  

<meta name="author" content="Bradley J. Cosentino" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multilevel-models.html"/>
<link rel="next" href="decision-making-with-frequentist-estimates.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#work-in-progress"><i class="fa fa-check"></i>Work in progress</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#copyright"><i class="fa fa-check"></i>Copyright</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html"><i class="fa fa-check"></i><b>1</b> Why Statistics? The Problem of Uncertainty</a>
<ul>
<li class="chapter" data-level="1.1" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#the-nature-of-science"><i class="fa fa-check"></i><b>1.1</b> The nature of science</a></li>
<li class="chapter" data-level="1.2" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#goals-of-scientific-research"><i class="fa fa-check"></i><b>1.2</b> Goals of scientific research</a></li>
<li class="chapter" data-level="1.3" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#three-general-goals-of-scientific-research"><i class="fa fa-check"></i><b>1.3</b> Three general goals of scientific research</a></li>
<li class="chapter" data-level="1.4" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#research-design-and-statistical-analysis-depend-on-your-goal"><i class="fa fa-check"></i><b>1.4</b> Research design and statistical analysis depend on your goal</a></li>
<li class="chapter" data-level="1.5" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#you-cant-escape-uncertainty-in-science"><i class="fa fa-check"></i><b>1.5</b> You can’t escape uncertainty in science</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html"><i class="fa fa-check"></i><b>2</b> Scientific workflow: Connecting ideas to data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#research-questions"><i class="fa fa-check"></i><b>2.1</b> Research questions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#clarify-your-primary-goal-description-prediction-or-explanation"><i class="fa fa-check"></i><b>2.1.1</b> Clarify your primary goal: description, prediction, or explanation?</a></li>
<li class="chapter" data-level="2.1.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#identify-the-scope-of-inference-the-who-what-when-and-where-of-your-study."><i class="fa fa-check"></i><b>2.1.2</b> Identify the scope of inference: The who, what, when, and where of your study.</a></li>
<li class="chapter" data-level="2.1.3" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-it-interesting"><i class="fa fa-check"></i><b>2.1.3</b> Make it interesting</a></li>
<li class="chapter" data-level="2.1.4" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-it-answerable-with-data"><i class="fa fa-check"></i><b>2.1.4</b> Make it answerable with data</a></li>
<li class="chapter" data-level="2.1.5" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#ground-it-in-theory"><i class="fa fa-check"></i><b>2.1.5</b> Ground it in theory</a></li>
<li class="chapter" data-level="2.1.6" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-sure-its-feasible"><i class="fa fa-check"></i><b>2.1.6</b> Make sure it’s feasible</a></li>
<li class="chapter" data-level="2.1.7" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#avoid-analyzing-the-data-before-stating-your-question"><i class="fa fa-check"></i><b>2.1.7</b> Avoid analyzing the data before stating your question</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#connecting-ideas-to-data"><i class="fa fa-check"></i><b>2.2</b> Connecting ideas to data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#theory"><i class="fa fa-check"></i><b>2.2.1</b> Theory</a></li>
<li class="chapter" data-level="2.2.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#research-question"><i class="fa fa-check"></i><b>2.2.2</b> Research question</a></li>
<li class="chapter" data-level="2.2.3" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#generative-model"><i class="fa fa-check"></i><b>2.2.3</b> Generative model</a></li>
<li class="chapter" data-level="2.2.4" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#study-design"><i class="fa fa-check"></i><b>2.2.4</b> Study design</a></li>
<li class="chapter" data-level="2.2.5" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#estimand"><i class="fa fa-check"></i><b>2.2.5</b> Estimand</a></li>
<li class="chapter" data-level="2.2.6" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#target-population"><i class="fa fa-check"></i><b>2.2.6</b> Target population</a></li>
<li class="chapter" data-level="2.2.7" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#sample-data"><i class="fa fa-check"></i><b>2.2.7</b> Sample data</a></li>
<li class="chapter" data-level="2.2.8" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#statistical-model"><i class="fa fa-check"></i><b>2.2.8</b> Statistical model</a></li>
<li class="chapter" data-level="2.2.9" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#estimate"><i class="fa fa-check"></i><b>2.2.9</b> Estimate</a></li>
<li class="chapter" data-level="2.2.10" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#summary"><i class="fa fa-check"></i><b>2.2.10</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html"><i class="fa fa-check"></i><b>3</b> Introduction to Data and R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#an-introduction-to-data"><i class="fa fa-check"></i><b>3.1</b> An introduction to data</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#variables-and-observations"><i class="fa fa-check"></i><b>3.1.1</b> Variables and observations</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#types-of-variables"><i class="fa fa-check"></i><b>3.1.2</b> Types of variables</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#relationships-between-variables"><i class="fa fa-check"></i><b>3.1.3</b> Relationships between variables</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#variable-naming-conventions-and-metadata"><i class="fa fa-check"></i><b>3.1.4</b> Variable naming conventions and metadata</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#introduction-to-r"><i class="fa fa-check"></i><b>3.2</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>3.2.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#the-rstudio-interface"><i class="fa fa-check"></i><b>3.2.2</b> The RStudio Interface</a></li>
<li class="chapter" data-level="3.2.3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#basic-data-manipulation-in-r"><i class="fa fa-check"></i><b>3.2.3</b> Basic data manipulation in R</a></li>
<li class="chapter" data-level="3.2.4" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#scripting"><i class="fa fa-check"></i><b>3.2.4</b> Scripting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="describing-data.html"><a href="describing-data.html"><i class="fa fa-check"></i><b>4</b> Describing data</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="describing-data.html"><a href="describing-data.html#defining-the-population"><i class="fa fa-check"></i><b>4.0.1</b> Defining the population</a></li>
<li class="chapter" data-level="4.0.2" data-path="describing-data.html"><a href="describing-data.html#loading-data-into-r"><i class="fa fa-check"></i><b>4.0.2</b> Loading data into R</a></li>
<li class="chapter" data-level="4.0.3" data-path="describing-data.html"><a href="describing-data.html#inspecting-the-dataset"><i class="fa fa-check"></i><b>4.0.3</b> Inspecting the dataset</a></li>
<li class="chapter" data-level="4.0.4" data-path="describing-data.html"><a href="describing-data.html#describing-single-qualitative-variables"><i class="fa fa-check"></i><b>4.0.4</b> Describing single qualitative variables</a></li>
<li class="chapter" data-level="4.0.5" data-path="describing-data.html"><a href="describing-data.html#describing-single-quantitative-variables"><i class="fa fa-check"></i><b>4.0.5</b> Describing single quantitative variables</a></li>
<li class="chapter" data-level="4.0.6" data-path="describing-data.html"><a href="describing-data.html#describing-relationships-between-variables"><i class="fa fa-check"></i><b>4.0.6</b> Describing relationships between variables</a></li>
<li class="chapter" data-level="4.0.7" data-path="describing-data.html"><a href="describing-data.html#associations-between-quantitative-variables"><i class="fa fa-check"></i><b>4.0.7</b> Associations between quantitative variables</a></li>
<li class="chapter" data-level="4.0.8" data-path="describing-data.html"><a href="describing-data.html#associations-between-quantitative-and-qualitative-variables"><i class="fa fa-check"></i><b>4.0.8</b> Associations between quantitative and qualitative variables</a></li>
<li class="chapter" data-level="4.0.9" data-path="describing-data.html"><a href="describing-data.html#associations-between-qualitative-variables"><i class="fa fa-check"></i><b>4.0.9</b> Associations between qualitative variables</a></li>
<li class="chapter" data-level="4.0.10" data-path="describing-data.html"><a href="describing-data.html#this-is-just-the-beginning"><i class="fa fa-check"></i><b>4.0.10</b> This is just the beginning</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html"><i class="fa fa-check"></i><b>5</b> Uncertainty from sampling</a>
<ul>
<li class="chapter" data-level="5.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#sampling-requires-estimation"><i class="fa fa-check"></i><b>5.1</b> Sampling requires estimation</a></li>
<li class="chapter" data-level="5.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#parameters-estimates-estimands"><i class="fa fa-check"></i><b>5.2</b> Parameters, estimates, estimands</a></li>
<li class="chapter" data-level="5.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#sources-of-uncertainty-from-sampling"><i class="fa fa-check"></i><b>5.3</b> Sources of uncertainty from sampling</a></li>
<li class="chapter" data-level="5.4" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#accuracy-and-precision"><i class="fa fa-check"></i><b>5.4</b> Accuracy and precision</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#accuracy"><i class="fa fa-check"></i><b>5.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.4.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#precision"><i class="fa fa-check"></i><b>5.4.2</b> Precision</a></li>
<li class="chapter" data-level="5.4.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#considering-accuracy-and-precision-together"><i class="fa fa-check"></i><b>5.4.3</b> Considering accuracy and precision together</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#maximizing-accuracy-and-precision-of-estimates"><i class="fa fa-check"></i><b>5.5</b> Maximizing accuracy and precision of estimates</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#random-sampling"><i class="fa fa-check"></i><b>5.5.1</b> Random sampling</a></li>
<li class="chapter" data-level="5.5.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#replication"><i class="fa fa-check"></i><b>5.5.2</b> Replication</a></li>
<li class="chapter" data-level="5.5.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#take-home-points"><i class="fa fa-check"></i><b>5.5.3</b> Take-home points</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html"><i class="fa fa-check"></i><b>6</b> Probability as the Language of Uncertainty</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#defining-probability"><i class="fa fa-check"></i><b>6.1</b> Defining probability</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#frequentist-definition"><i class="fa fa-check"></i><b>6.1.1</b> Frequentist definition</a></li>
<li class="chapter" data-level="6.1.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#bayesian-definition"><i class="fa fa-check"></i><b>6.1.2</b> Bayesian definition</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#probability-rules"><i class="fa fa-check"></i><b>6.2</b> Probability rules</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#individual-events"><i class="fa fa-check"></i><b>6.2.1</b> Individual events</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#joint-events"><i class="fa fa-check"></i><b>6.2.2</b> Joint events</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#general-addition-rule"><i class="fa fa-check"></i><b>6.2.3</b> General addition rule</a></li>
<li class="chapter" data-level="6.2.4" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#quantifying-marginal-probabilities"><i class="fa fa-check"></i><b>6.2.4</b> Quantifying marginal probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-probability-distributions"><i class="fa fa-check"></i><b>6.3</b> Sampling from probability distributions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-populations-is-probabalistic"><i class="fa fa-check"></i><b>6.3.1</b> Sampling from populations is probabalistic</a></li>
<li class="chapter" data-level="6.3.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#discrete-random-variables"><i class="fa fa-check"></i><b>6.3.2</b> Discrete random variables</a></li>
<li class="chapter" data-level="6.3.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.3.3</b> Continuous random variables</a></li>
<li class="chapter" data-level="6.3.4" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-probability-distributions-1"><i class="fa fa-check"></i><b>6.3.4</b> Sampling from probability distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>7</b> Estimation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimation.html"><a href="estimation.html#scientific-workflow-for-the-problem"><i class="fa fa-check"></i><b>7.1</b> Scientific workflow for the problem</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimation.html"><a href="estimation.html#theory-and-the-research-question"><i class="fa fa-check"></i><b>7.1.1</b> Theory and the research question</a></li>
<li class="chapter" data-level="7.1.2" data-path="estimation.html"><a href="estimation.html#generative-model-and-estimand"><i class="fa fa-check"></i><b>7.1.2</b> Generative model and estimand</a></li>
<li class="chapter" data-level="7.1.3" data-path="estimation.html"><a href="estimation.html#statistical-model-and-estimate"><i class="fa fa-check"></i><b>7.1.3</b> Statistical model and estimate</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimation.html"><a href="estimation.html#bayes-theorem"><i class="fa fa-check"></i><b>7.2</b> Bayes Theorem</a></li>
<li class="chapter" data-level="7.3" data-path="estimation.html"><a href="estimation.html#applying-bayes-theorem-to-statistical-analysis"><i class="fa fa-check"></i><b>7.3</b> Applying Bayes Theorem to statistical analysis</a></li>
<li class="chapter" data-level="7.4" data-path="estimation.html"><a href="estimation.html#steps-of-estimation-with-bayesian-inference"><i class="fa fa-check"></i><b>7.4</b> Steps of estimation with Bayesian inference</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="estimation.html"><a href="estimation.html#specify-the-prior-distribution"><i class="fa fa-check"></i><b>7.4.1</b> Specify the prior distribution</a></li>
<li class="chapter" data-level="7.4.2" data-path="estimation.html"><a href="estimation.html#quantify-the-likelihood-of-the-data"><i class="fa fa-check"></i><b>7.4.2</b> Quantify the likelihood of the data</a></li>
<li class="chapter" data-level="7.4.3" data-path="estimation.html"><a href="estimation.html#quantify-the-total-probability-of-the-data-marginal-likelihood"><i class="fa fa-check"></i><b>7.4.3</b> Quantify the total probability of the data (marginal likelihood)</a></li>
<li class="chapter" data-level="7.4.4" data-path="estimation.html"><a href="estimation.html#quantify-the-posterior-distribution"><i class="fa fa-check"></i><b>7.4.4</b> Quantify the posterior distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="estimation.html"><a href="estimation.html#summarizing-the-posterior-distribution"><i class="fa fa-check"></i><b>7.5</b> Summarizing the posterior distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="estimation.html"><a href="estimation.html#sampling-from-the-posterior-distribution"><i class="fa fa-check"></i><b>7.5.1</b> Sampling from the posterior distribution</a></li>
<li class="chapter" data-level="7.5.2" data-path="estimation.html"><a href="estimation.html#central-tendency-and-variance"><i class="fa fa-check"></i><b>7.5.2</b> Central tendency and variance</a></li>
<li class="chapter" data-level="7.5.3" data-path="estimation.html"><a href="estimation.html#intervals"><i class="fa fa-check"></i><b>7.5.3</b> Intervals</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="estimation.html"><a href="estimation.html#specifying-priors"><i class="fa fa-check"></i><b>7.6</b> Specifying priors</a></li>
<li class="chapter" data-level="7.7" data-path="estimation.html"><a href="estimation.html#decision-making"><i class="fa fa-check"></i><b>7.7</b> Decision making</a></li>
<li class="chapter" data-level="7.8" data-path="estimation.html"><a href="estimation.html#specifying-and-fitting-statistical-models-with-bayes"><i class="fa fa-check"></i><b>7.8</b> Specifying and fitting statistical models with Bayes</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="estimation.html"><a href="estimation.html#statistical-model-specification"><i class="fa fa-check"></i><b>7.8.1</b> Statistical model specification</a></li>
<li class="chapter" data-level="7.8.2" data-path="estimation.html"><a href="estimation.html#fitting-models-with-brms"><i class="fa fa-check"></i><b>7.8.2</b> Fitting models with <em>brms</em></a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="estimation.html"><a href="estimation.html#estimation-for-a-continuous-random-variable"><i class="fa fa-check"></i><b>7.9</b> Estimation for a continuous random variable</a></li>
<li class="chapter" data-level="7.10" data-path="estimation.html"><a href="estimation.html#next-steps"><i class="fa fa-check"></i><b>7.10</b> Next steps</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html"><i class="fa fa-check"></i><b>8</b> Bayesian Workflow</a>
<ul>
<li class="chapter" data-level="8.1" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#prior-distribution-choices"><i class="fa fa-check"></i><b>8.1</b> Prior distribution choices</a></li>
<li class="chapter" data-level="8.2" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#prior-predictive-checks"><i class="fa fa-check"></i><b>8.2</b> Prior predictive checks</a></li>
<li class="chapter" data-level="8.3" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>8.3</b> Posterior predictive checks</a></li>
<li class="chapter" data-level="8.4" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#next-steps-1"><i class="fa fa-check"></i><b>8.4</b> Next steps</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="the-linear-model.html"><a href="the-linear-model.html"><i class="fa fa-check"></i><b>9</b> The linear model</a>
<ul>
<li class="chapter" data-level="9.1" data-path="the-linear-model.html"><a href="the-linear-model.html#statistical-models"><i class="fa fa-check"></i><b>9.1</b> Statistical models</a></li>
<li class="chapter" data-level="9.2" data-path="the-linear-model.html"><a href="the-linear-model.html#linear-model"><i class="fa fa-check"></i><b>9.2</b> Linear model</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="the-linear-model.html"><a href="the-linear-model.html#basic-structure-of-the-linear-model"><i class="fa fa-check"></i><b>9.2.1</b> Basic structure of the linear model</a></li>
<li class="chapter" data-level="9.2.2" data-path="the-linear-model.html"><a href="the-linear-model.html#fitting-the-linear-model-in-brms"><i class="fa fa-check"></i><b>9.2.2</b> Fitting the linear model in brms</a></li>
<li class="chapter" data-level="9.2.3" data-path="the-linear-model.html"><a href="the-linear-model.html#how-a-frequentist-might-do-it"><i class="fa fa-check"></i><b>9.2.3</b> How a frequentist might do it</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="the-linear-model.html"><a href="the-linear-model.html#linear-models-with-categorical-predictors"><i class="fa fa-check"></i><b>9.3</b> Linear models with categorical predictors</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="the-linear-model.html"><a href="the-linear-model.html#binary-explanatory-variables"><i class="fa fa-check"></i><b>9.3.1</b> Binary explanatory variables</a></li>
<li class="chapter" data-level="9.3.2" data-path="the-linear-model.html"><a href="the-linear-model.html#categorical-predictors-with-more-than-two-categories"><i class="fa fa-check"></i><b>9.3.2</b> Categorical predictors with more than two categories</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html"><i class="fa fa-check"></i><b>10</b> Graphical Causal Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>10.1</b> Directed acyclic graphs (DAGs)</a></li>
<li class="chapter" data-level="10.2" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#three-causal-structures-in-dags"><i class="fa fa-check"></i><b>10.2</b> Three causal structures in DAGs</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-fork-confounders"><i class="fa fa-check"></i><b>10.2.1</b> The fork: confounders</a></li>
<li class="chapter" data-level="10.2.2" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-pipe-mediators"><i class="fa fa-check"></i><b>10.2.2</b> The pipe: mediators</a></li>
<li class="chapter" data-level="10.2.3" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-inverted-fork-colliders"><i class="fa fa-check"></i><b>10.2.3</b> The inverted fork: colliders</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#closing-backdoor-paths"><i class="fa fa-check"></i><b>10.3</b> Closing backdoor paths</a></li>
<li class="chapter" data-level="10.4" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#like-all-models-dags-require-assumptions"><i class="fa fa-check"></i><b>10.4</b> Like all models, DAGs require assumptions</a></li>
<li class="chapter" data-level="10.5" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#types-of-study-designs"><i class="fa fa-check"></i><b>10.5</b> Types of Study Designs</a></li>
<li class="chapter" data-level="10.6" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#experimental-studies"><i class="fa fa-check"></i><b>10.6</b> Experimental studies</a></li>
<li class="chapter" data-level="10.7" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#observational-studies"><i class="fa fa-check"></i><b>10.7</b> Observational studies</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#pros-and-cons-of-prospective-vs.-retrospective-studies-planned"><i class="fa fa-check"></i><b>10.7.1</b> Pros and cons of prospective vs. retrospective studies (planned)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html"><i class="fa fa-check"></i><b>11</b> Causal inference with linear models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#linear-models-with-multiple-predictor-variables"><i class="fa fa-check"></i><b>11.1</b> Linear models with multiple predictor variables</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#generic-linear-model-with-two-predictors"><i class="fa fa-check"></i><b>11.1.1</b> Generic linear model with two predictors</a></li>
<li class="chapter" data-level="11.1.2" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#multiple-regression-model-for-the-ice-cream-and-drownings-example"><i class="fa fa-check"></i><b>11.1.2</b> Multiple regression model for the ice cream and drownings example</a></li>
<li class="chapter" data-level="11.1.3" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#prior-predictive-check"><i class="fa fa-check"></i><b>11.1.3</b> Prior predictive check</a></li>
<li class="chapter" data-level="11.1.4" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#fitting-the-multiple-regression-model"><i class="fa fa-check"></i><b>11.1.4</b> Fitting the multiple regression model</a></li>
<li class="chapter" data-level="11.1.5" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#prediction-plots-for-multiple-regression-models"><i class="fa fa-check"></i><b>11.1.5</b> Prediction plots for multiple regression models</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#dag-informed-predictors-categorical-variables-what-multiple-regression-is-doing-with-predictor-residual-plot"><i class="fa fa-check"></i><b>11.2</b> DAG-informed predictors, categorical variables, what multiple regression is doing with predictor residual plot</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="interaction-effects.html"><a href="interaction-effects.html"><i class="fa fa-check"></i><b>12</b> Interaction effects</a></li>
<li class="chapter" data-level="13" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>13</b> Generalized linear models</a></li>
<li class="chapter" data-level="14" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>14</b> Multilevel models</a></li>
<li class="chapter" data-level="15" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html"><i class="fa fa-check"></i><b>15</b> Estimation with frequentist inference</a>
<ul>
<li class="chapter" data-level="15.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#frequentist-estimates-are-point-estimates"><i class="fa fa-check"></i><b>15.1</b> Frequentist estimates are point estimates</a></li>
<li class="chapter" data-level="15.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions"><i class="fa fa-check"></i><b>15.2</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions-are-centered-on-the-true-parameter-value"><i class="fa fa-check"></i><b>15.2.1</b> Sampling distributions are centered on the true parameter value</a></li>
<li class="chapter" data-level="15.2.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions-allow-us-to-estimate-precision"><i class="fa fa-check"></i><b>15.2.2</b> Sampling distributions allow us to estimate precision</a></li>
<li class="chapter" data-level="15.2.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sample-size-affects-the-shape-of-sampling-distributions"><i class="fa fa-check"></i><b>15.2.3</b> Sample size affects the shape of sampling distributions</a></li>
<li class="chapter" data-level="15.2.4" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#summary-points-on-sampling-distributions"><i class="fa fa-check"></i><b>15.2.4</b> Summary points on sampling distributions</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#quantifying-uncertainty-standard-error-and-confidence-intervals"><i class="fa fa-check"></i><b>15.3</b> Quantifying uncertainty: standard error and confidence intervals</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#standard-error"><i class="fa fa-check"></i><b>15.3.1</b> Standard error</a></li>
<li class="chapter" data-level="15.3.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>15.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="15.3.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#the-standard-normal-approximation-does-not-work-well-under-low-sample-size"><i class="fa fa-check"></i><b>15.3.3</b> The standard normal approximation does not work well under low sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html"><i class="fa fa-check"></i><b>16</b> Decision-making with frequentist estimates</a>
<ul>
<li class="chapter" data-level="16.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#framework-of-classical-hypothesis-testing"><i class="fa fa-check"></i><b>16.1</b> Framework of classical hypothesis testing</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#state-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>16.1.1</b> State null and alternative hypotheses</a></li>
<li class="chapter" data-level="16.1.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#assume-the-null-hypothesis-is-true"><i class="fa fa-check"></i><b>16.1.2</b> Assume the null hypothesis is true</a></li>
<li class="chapter" data-level="16.1.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#quantify-the-likelihood-of-the-data-under-the-null-hypothesis-p-values"><i class="fa fa-check"></i><b>16.1.3</b> Quantify the likelihood of the data under the null hypothesis: P-values</a></li>
<li class="chapter" data-level="16.1.4" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#making-a-decision-based-on-the-p-value-and-significance-value"><i class="fa fa-check"></i><b>16.1.4</b> Making a decision based on the P-value and significance value</a></li>
<li class="chapter" data-level="16.1.5" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#decision-errors-happen"><i class="fa fa-check"></i><b>16.1.5</b> Decision errors happen</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#making-decisions-with-confidence-intervals"><i class="fa fa-check"></i><b>16.2</b> Making decisions with confidence intervals</a></li>
<li class="chapter" data-level="16.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#issues-with-the-null-hypothesis-framework"><i class="fa fa-check"></i><b>16.3</b> Issues with the null hypothesis framework</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#significance-testing-reinforces-binary-thinking"><i class="fa fa-check"></i><b>16.3.1</b> Significance testing reinforces binary thinking</a></li>
<li class="chapter" data-level="16.3.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#statistical-testing-reinforces-gamification-in-science"><i class="fa fa-check"></i><b>16.3.2</b> Statistical testing reinforces gamification in science</a></li>
<li class="chapter" data-level="16.3.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#statistical-significance-is-not-the-same-thing-as-practical-significance"><i class="fa fa-check"></i><b>16.3.3</b> Statistical significance is not the same thing as practical significance</a></li>
<li class="chapter" data-level="16.3.4" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#type-i-errors-become-more-likely-with-multiple-tests"><i class="fa fa-check"></i><b>16.3.4</b> Type I errors become more likely with multiple tests</a></li>
<li class="chapter" data-level="16.3.5" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-is-almost-certainly-wrong"><i class="fa fa-check"></i><b>16.3.5</b> The null hypothesis is almost certainly wrong</a></li>
<li class="chapter" data-level="16.3.6" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-focuses-on-data-you-did-not-observe"><i class="fa fa-check"></i><b>16.3.6</b> The null hypothesis focuses on data you did not observe</a></li>
<li class="chapter" data-level="16.3.7" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#a-single-null-and-alternative-hypothesis-is-too-constraining"><i class="fa fa-check"></i><b>16.3.7</b> A single null and alternative hypothesis is too constraining</a></li>
<li class="chapter" data-level="16.3.8" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-p-value-is-not-the-probability-we-want"><i class="fa fa-check"></i><b>16.3.8</b> The P-value is not the probability we want</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Research Design and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimation-with-frequentist-inference" class="section level1 hasAnchor" number="15">
<h1><span class="header-section-number">Chapter 15</span> Estimation with frequentist inference<a href="estimation-with-frequentist-inference.html#estimation-with-frequentist-inference" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Now that we have some basic principles of probability under our belt, we can turn our attention to the fundamental problem of inferential statistics: estimating parameter values from samples and characterizing uncertainty about our estimates. Having some basic understanding of probability was essential to explore the issues related to estimation, precisely because the language in which we will characterize uncertainty about parameter estimates <em>is</em> probability.</p>
<p>To keep things simple, we will explore the foundational principles of estimation in the context of the scientific problem we started to look at last chapter: estimating the prevalence of a disease in a population. We will use this example to develop the principles of estimation with different philosophies of inference, namely the frequentist and Bayesian approaches. Those terms should ring a bell from last chapter, as they represent the two different definitions of probability that we looked at.</p>
<p>Statistics education has been dominated by the frequentist approach. And there’s good reason for that! Much of the scientific literature is dominated by the frequentist approach. In a way the situation has become a positive feedback loop. Frequentist methods are used by many (most?) professional scientists because those are the methods they are taught, and statistics instructors teach frequentist methods because those are the methods that are used. But Bayesian inference is being used more and more in the scientific literature, and for good reasons. Suffice to say that I think it’s time to start teaching both approaches to inference. We’ll start with the frequentist approach over the next two chapters, and then turn to Bayesian inference in the next chapter.</p>
<div id="frequentist-estimates-are-point-estimates" class="section level2 hasAnchor" number="15.1">
<h2><span class="header-section-number">15.1</span> Frequentist estimates are point estimates<a href="estimation-with-frequentist-inference.html#frequentist-estimates-are-point-estimates" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recall the scenario. We have a population of 10,000 people, and we need to estimate the prevalence of a disease to determine if public health interventions will be enforced. Those interventions will be enforced if the prevalence is 10% or greater. We still assume our test is perfect, but we don’t have the time or resources to test all 10,000 people, so will randomly sample individuals for testing. We’ll also assume that anyone who is randomly selected will comply with the test. I know, these aren’t realistic assumptions, but it’s useful to make simplifying assumptions to develop first principles.</p>
<p>OK, let’s further assume that we randomly sample <span class="math inline">\(N = 100\)</span> people for testing. Out of the 100 tests, we find 8 positives and 92 negatives. Based on this single sample, we <strong>estimate</strong> the prevalence of the infection as</p>
<p><span class="math display">\[
\hat{p}_{infected}=\frac{8}{100}=0.08
\]</span></p>
<p>In other words, based on our sample we estimate that 8% of the population is infected. <em>Estimate</em> is a critical word here because we truly don’t know what the actual prevalence of the infection is. We are trying to infer the true prevalence - that is, the parameter value - from a sample of data.</p>
<p>In frequentist inference, we try to draw conclusions about parameters in exactly this way. Frequentist inference assumes at the start that there is some true parameter value. We take a sample of data, and we estimate the parameter(s) of interest with the sample. Those parameter estimates are <strong>point estimates</strong>, in that they represent the single best estimate of the parameters of interest.</p>
<p>Because the frequentist approach assumes there is a single true parameter value, there’s no way we can talk probabilisticaly about pramater values. For example, one might be tempted to ask “How probable is it that the prevalence of the infection is at least 10% given our sample of 8 of 100 infected?”. In other words, we might want to know the conditional probability <span class="math inline">\(P(p\geq0.1|\hat{p}=\frac{8}{100}=0.08)\)</span>. But from a frequentist perspective, this doesn’t make sense. The true prevalence of the infection is either greater than 0.1 or not regardless of the data we observe in our sample. The parameter <span class="math inline">\(p\)</span> is completely fixed.</p>
<p>OK, but what are we supposed to make of our point estimate that 8% of the population is infected? Is it a good estimate or not? To interrogate the quality of an estimate with frequentist inference, we need to dig deeper and examine the concept of a sampling distribution.</p>
</div>
<div id="sampling-distributions" class="section level2 hasAnchor" number="15.2">
<h2><span class="header-section-number">15.2</span> Sampling distributions<a href="estimation-with-frequentist-inference.html#sampling-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The key element of frequentist inference is that it considers an estimate from a single sample to be only one of many possible outcomes. Just imagine repeating the sampling process over and over again. Every new sample of 100 tests will produce varying point estimates becuase of samplign error. We estimated 8% of the population is infected based on our single sample, but if we were to take another random sample, maybe we’d find the estimate is 9%, or 6%, or 11%. In other words, frequentist estimates are random variables!</p>
<p>When we estimate a parameter with a random sample, is it possible that some estimates are more likely than others? Absolutely. Because the estimate is a random variable, it can be described by a probability distribution. In frequentist statistics, the probability distribution used to describe a sample estimate is called the <strong>sampling distribution</strong>.</p>
<p>Let’s assume that the true prevalence of the disease is 11% in our population of 10,000 people. If that’s the case, how likely is it that the estimated prevalence from a sample of 100 people will be 8%, as we saw in our sample? In probability terms, what is <span class="math inline">\(P(\hat{p}=\frac{8}{100}=0.08|p=0.11)\)</span>. You might recognize that in this case, the estimated prevalence <span class="math inline">\(P(\hat{p}\)</span> is a binomial random variable, so we can quantify this probability with the binomial equation:</p>
<p><span class="math display">\[
P(X = 8) = \binom{100}{8} 0.11^8 (1 - 0.11)^{100 - 8}=0.088
\]</span></p>
<p>Of course we can quantify this easily in R:</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="estimation-with-frequentist-inference.html#cb398-1" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">8</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> <span class="fl">0.11</span>)</span></code></pre></div>
<pre><code>## [1] 0.0880522</code></pre>
<p>So we see that when we take a random sample of 100 people from a population with a true prevalence of 11%, the probability of our point estimate being 8% is 0.088. How does that compare to other possible values of the point estimate? Well, we can easily compute the probability of all possible outcomes for the number of positive tests and then plot the resulting distribution (Figure @ref(fig:a01_chunk02)):</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="estimation-with-frequentist-inference.html#cb400-1" tabindex="-1"></a><span class="co">#all possible values of positive tests out of N = 100</span></span>
<span id="cb400-2"><a href="estimation-with-frequentist-inference.html#cb400-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb400-3"><a href="estimation-with-frequentist-inference.html#cb400-3" tabindex="-1"></a></span>
<span id="cb400-4"><a href="estimation-with-frequentist-inference.html#cb400-4" tabindex="-1"></a><span class="co">#probability of each outcome assuming prevalence is 11%</span></span>
<span id="cb400-5"><a href="estimation-with-frequentist-inference.html#cb400-5" tabindex="-1"></a>p.hat <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> x, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> <span class="fl">0.11</span>)</span>
<span id="cb400-6"><a href="estimation-with-frequentist-inference.html#cb400-6" tabindex="-1"></a></span>
<span id="cb400-7"><a href="estimation-with-frequentist-inference.html#cb400-7" tabindex="-1"></a><span class="co">#combine into a data frame</span></span>
<span id="cb400-8"><a href="estimation-with-frequentist-inference.html#cb400-8" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(x, p.hat)</span>
<span id="cb400-9"><a href="estimation-with-frequentist-inference.html#cb400-9" tabindex="-1"></a></span>
<span id="cb400-10"><a href="estimation-with-frequentist-inference.html#cb400-10" tabindex="-1"></a><span class="co">#plot the sampling distribution</span></span>
<span id="cb400-11"><a href="estimation-with-frequentist-inference.html#cb400-11" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> p.hat)) <span class="sc">+</span></span>
<span id="cb400-12"><a href="estimation-with-frequentist-inference.html#cb400-12" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">width =</span> <span class="dv">1</span>, <span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span> </span>
<span id="cb400-13"><a href="estimation-with-frequentist-inference.html#cb400-13" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Number of positives out of N = 100&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Probability&quot;</span>) <span class="sc">+</span></span>
<span id="cb400-14"><a href="estimation-with-frequentist-inference.html#cb400-14" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">30</span>) <span class="sc">+</span></span>
<span id="cb400-15"><a href="estimation-with-frequentist-inference.html#cb400-15" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk02-1.png" alt="Sampling distribution of the estimated prevalence of infection based on a sample of N = 100 individuals from a population where the true prevalence of the infection is 11%." width="70%" />
<p class="caption">
(#fig:a01_chunk02)Sampling distribution of the estimated prevalence of infection based on a sample of N = 100 individuals from a population where the true prevalence of the infection is 11%.
</p>
</div>
<p>The resulting probability distribution (Figure @ref(fig:a01_chunk02)) shows the probability of each possible point estimate for the prevalence of the infection when we take a random sample of N = 100 from a population where the <em>true</em> prevalence is 8%. This is a <em>sampling distribution</em>! Sampling distributions show the probability distribution of all possible values for an <em>estimate</em> of a parameter when we take a random sample from the target population.</p>
<p>This is an extremely important concept. I have tried to make the case that the primary reason we need statistics is to guide decision-making about hypotheses in light of uncertainty. From a frequentist perspective, <strong>the sampling distribution is an illustration of uncertainty about estimates taken from samples.</strong> In this case, it shows us that when we take a random sample of 100 people, we won’t necessarily find 11 positives (to give us an estimate of 11% prevalence) even if the true prevalence of the disease is 11%. It’s certainly possible to get an estimate of 11% from a sample of N = 100, but it’s almost just as likely to get an estimate of 10%, or 12%. Fundamentally these deviations in our estimates from the true parameter value are caused by random sampling error.</p>
<div id="sampling-distributions-are-centered-on-the-true-parameter-value" class="section level3 hasAnchor" number="15.2.1">
<h3><span class="header-section-number">15.2.1</span> Sampling distributions are centered on the true parameter value<a href="estimation-with-frequentist-inference.html#sampling-distributions-are-centered-on-the-true-parameter-value" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One thing you should observe in the sampling distribution in Figure @ref(fig:a01_chunk02) is that the distribution is centered on the true parameter value, 11%. That is a feature of sampling distributions. The expected value of a sampling distribution (the mean) <em>is</em> the true parameter value.</p>
<p>Now, you might be tempted to claim that our estimated prevalence of 8% is an inaccurate estimate. But that’s not quite correct. When judging the accuracy of a parameter estimate from a frequentist perspective, you have to think about the distribution of possible estimates (the sampling distribution) rather than the single estimate you observed. Frequentist estimation is based on the idea of long-run frequencies of outcomes based on many random samples. In practice you only observe one, and because of sampling error, your one estimate is very likely to deviate from the truth. But accuracy of an estimator is judged on the expected value of the estimates, not the single estimate you observed.</p>
<p>This is where things get tricky for frequentist estimation. You have a single estimate in hand, but to judge the accuracy of that estimate, you have to think about the collection of possible, yet unobserved estimates that you would see if you repeated your sampling many times. It’s an abstract idea! Our single estimate of 8% is indeed lower than the truth, but if you conducted sampling over and over again, you would see some estimates that are greater than the truth too. If estimates were consistently lower than the truth, then the estimates would indeed be biased.</p>
<p>I’m sure your wondering, “If I can’t actually observe the sampling distribution, how do I know if my single estimate is accurate?”. Good question! To judge the accuracy of your estimator, you really have to focus on aspects of the sampling design, namely the degree to which the observations you drew from the population were a random selection. Random sampling ensures that estimates - on average, across many samples - will be unbiased. In practice, there’s nothing that we can quantify based on the concept of a sampling distribution that will tell us if your estimate is biased or not. To judge accuracy of estimates, you have to assess the sampling design, and especially assess whether the observations are a random sample.</p>
</div>
<div id="sampling-distributions-allow-us-to-estimate-precision" class="section level3 hasAnchor" number="15.2.2">
<h3><span class="header-section-number">15.2.2</span> Sampling distributions allow us to estimate precision<a href="estimation-with-frequentist-inference.html#sampling-distributions-allow-us-to-estimate-precision" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sampling distributions are abstract and can’t tell us much about whether a single estimate is biased or not, but they can tell us a lot about the precision of our estimates. Indeed, the width of the sampling distribution is a measure of precision. In our example, we can see there’s a reasonable chance of seeing anywhere from 5-16 positives out of 100 tests when the true prevalence is 11%. This variation is analogous to the variation in the number of heads you expect to see out of 10 flips of a fair coin. Although you expect 5 heads, you wouldn’t be surprised to get 3, or 6, or 7 heads. In the same respect, we shouldn’t be too surprised to see an estimated prevalence of 8% from a sample of N = 100 when the true prevalence is 11%. That variation is a feature of the sampling process, and it gets to the heart of uncertainty. When we sample from populations, there is random error in the outcome, and the width of the sampling distribution illustrates the uncertainty we should feel when we consider whether our sample estimate is any good. The wider the sampling distribution, the more uncertainty, and the less confidence we should feel about our estimate being close to the truth.</p>
<p>What factors affect the precision of estimates as represented by the width of the sampling distribution? Let’s look at two: the sample size and variance.</p>
<div id="sample-size-affects-precision" class="section level4 hasAnchor" number="15.2.2.1">
<h4><span class="header-section-number">15.2.2.1</span> Sample size affects precision<a href="estimation-with-frequentist-inference.html#sample-size-affects-precision" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We previously identified sample size as one of the key drivers of precision. With the sampling distribution concept, we can interrogate that idea more precisely (pun intended!). We will continue assuming that the true prevalence of the disease is 11%, but we’re not going to change the size of the sample that we draw from the population to estimate the prevalence. Let’s construct sampling distributions where the sample size is 10, 100, or 1000 people:</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="estimation-with-frequentist-inference.html#cb401-1" tabindex="-1"></a><span class="co">#all possible values of positive tests</span></span>
<span id="cb401-2"><a href="estimation-with-frequentist-inference.html#cb401-2" tabindex="-1"></a>x10 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">10</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb401-3"><a href="estimation-with-frequentist-inference.html#cb401-3" tabindex="-1"></a>x100 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb401-4"><a href="estimation-with-frequentist-inference.html#cb401-4" tabindex="-1"></a>x1000 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1000</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb401-5"><a href="estimation-with-frequentist-inference.html#cb401-5" tabindex="-1"></a></span>
<span id="cb401-6"><a href="estimation-with-frequentist-inference.html#cb401-6" tabindex="-1"></a><span class="co">#probability of each outcome assuming prevalence is 11%</span></span>
<span id="cb401-7"><a href="estimation-with-frequentist-inference.html#cb401-7" tabindex="-1"></a>p.hat10 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> x10, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.11</span>)</span>
<span id="cb401-8"><a href="estimation-with-frequentist-inference.html#cb401-8" tabindex="-1"></a>p.hat100 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> x100, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> <span class="fl">0.11</span>)</span>
<span id="cb401-9"><a href="estimation-with-frequentist-inference.html#cb401-9" tabindex="-1"></a>p.hat1000 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> x1000, <span class="at">size =</span> <span class="dv">1000</span>, <span class="at">prob =</span> <span class="fl">0.11</span>)</span>
<span id="cb401-10"><a href="estimation-with-frequentist-inference.html#cb401-10" tabindex="-1"></a></span>
<span id="cb401-11"><a href="estimation-with-frequentist-inference.html#cb401-11" tabindex="-1"></a><span class="co">#combine into a data frame</span></span>
<span id="cb401-12"><a href="estimation-with-frequentist-inference.html#cb401-12" tabindex="-1"></a>d10 <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">n =</span> <span class="dv">10</span>, <span class="at">p.hat =</span> x10<span class="sc">/</span><span class="dv">10</span>, <span class="at">prob =</span> p.hat10)</span>
<span id="cb401-13"><a href="estimation-with-frequentist-inference.html#cb401-13" tabindex="-1"></a>d100 <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">p.hat =</span> x100<span class="sc">/</span><span class="dv">100</span>, <span class="at">prob =</span> p.hat100)</span>
<span id="cb401-14"><a href="estimation-with-frequentist-inference.html#cb401-14" tabindex="-1"></a>d1000 <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">n =</span> <span class="dv">1000</span>, <span class="at">p.hat =</span> x1000<span class="sc">/</span><span class="dv">1000</span>, <span class="at">prob =</span> p.hat1000)</span>
<span id="cb401-15"><a href="estimation-with-frequentist-inference.html#cb401-15" tabindex="-1"></a>d_all <span class="ot">&lt;-</span> <span class="fu">rbind</span>(d10, d100, d1000)</span></code></pre></div>
<p>And now we can plot the sampling distributions:</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="estimation-with-frequentist-inference.html#cb402-1" tabindex="-1"></a><span class="co">#plot the sampling distribution</span></span>
<span id="cb402-2"><a href="estimation-with-frequentist-inference.html#cb402-2" tabindex="-1"></a><span class="fu">ggplot</span>(d_all, <span class="fu">aes</span>(<span class="at">x =</span> p.hat, <span class="at">y =</span> prob)) <span class="sc">+</span></span>
<span id="cb402-3"><a href="estimation-with-frequentist-inference.html#cb402-3" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">data =</span> d_all[d_all<span class="sc">$</span>n <span class="sc">==</span> <span class="dv">10</span>, ], </span>
<span id="cb402-4"><a href="estimation-with-frequentist-inference.html#cb402-4" tabindex="-1"></a>           <span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">width =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb402-5"><a href="estimation-with-frequentist-inference.html#cb402-5" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">data =</span> d_all[d_all<span class="sc">$</span>n <span class="sc">==</span> <span class="dv">100</span>, ], </span>
<span id="cb402-6"><a href="estimation-with-frequentist-inference.html#cb402-6" tabindex="-1"></a>           <span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">width =</span> <span class="fl">0.01</span>) <span class="sc">+</span></span>
<span id="cb402-7"><a href="estimation-with-frequentist-inference.html#cb402-7" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">data =</span> d_all[d_all<span class="sc">$</span>n <span class="sc">==</span> <span class="dv">1000</span>, ], </span>
<span id="cb402-8"><a href="estimation-with-frequentist-inference.html#cb402-8" tabindex="-1"></a>           <span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">width =</span> <span class="fl">0.001</span>) <span class="sc">+</span></span>
<span id="cb402-9"><a href="estimation-with-frequentist-inference.html#cb402-9" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> n, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>,</span>
<span id="cb402-10"><a href="estimation-with-frequentist-inference.html#cb402-10" tabindex="-1"></a>             <span class="at">labeller =</span> <span class="fu">labeller</span>(<span class="at">n =</span> <span class="cf">function</span>(x) <span class="fu">paste</span>(<span class="st">&quot;N =&quot;</span>, x)))<span class="sc">+</span></span>
<span id="cb402-11"><a href="estimation-with-frequentist-inference.html#cb402-11" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb402-12"><a href="estimation-with-frequentist-inference.html#cb402-12" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Estimated proportion of positives&quot;</span>, </span>
<span id="cb402-13"><a href="estimation-with-frequentist-inference.html#cb402-13" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Probability&quot;</span>, </span>
<span id="cb402-14"><a href="estimation-with-frequentist-inference.html#cb402-14" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb402-15"><a href="estimation-with-frequentist-inference.html#cb402-15" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span> </span>
<span id="cb402-16"><a href="estimation-with-frequentist-inference.html#cb402-16" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>), </span>
<span id="cb402-17"><a href="estimation-with-frequentist-inference.html#cb402-17" tabindex="-1"></a>        <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">size =</span> <span class="dv">11</span>))</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk04-1.png" alt="Sampling distributions of the estimated prevalence of infection based on samples of size N = 10, 100, and 1000 individuals from a population where the true prevalence of the infection is 11%." width="70%" />
<p class="caption">
(#fig:a01_chunk04)Sampling distributions of the estimated prevalence of infection based on samples of size N = 10, 100, and 1000 individuals from a population where the true prevalence of the infection is 11%.
</p>
</div>
<p>What do we notice about the sampling distributions under different sample sizes in Figure @ref(fig:a01_chunk04)? First, each sampling distribution remains centered on the true parameter value of 11% prevalence. The point estimate of a parameter remains an unbiased estimate of the parameter no matter the sample size. In other words, sample size has no effect on the <em>accuracy</em> of estimates.</p>
<p>Second, as the sample size increases, the width of the sampling distribution decreases. We expect the estimated prevalence to change much more from sample to sample when the sample size is 10 than when it is 100 or 1000. Greater sample sizes lead to more precise estimates. This should make sense. After all, if you increase the sample size all the way to the size of the target population, there would be no variation at all in estimates from sample to sample.</p>
<p>The <strong>Law of Large Numbers</strong> states this explicitly, that as the sample size <span class="math inline">\(N\)</span> increases, the point estimate ultimately converges on the true parameter value. Let’s simulate this process to get a good handle on it. Remember that we assumed a target population of 10,000 individuals. Below we will create a dataset of 10000 individuals with infection status classified as 1 (infected) or 0 (not infected), where 11% of the population is infected:</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="estimation-with-frequentist-inference.html#cb403-1" tabindex="-1"></a><span class="co">#create infection status for 10000 people with 11% infected </span></span>
<span id="cb403-2"><a href="estimation-with-frequentist-inference.html#cb403-2" tabindex="-1"></a>status <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1100</span>), <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">8900</span>))</span>
<span id="cb403-3"><a href="estimation-with-frequentist-inference.html#cb403-3" tabindex="-1"></a></span>
<span id="cb403-4"><a href="estimation-with-frequentist-inference.html#cb403-4" tabindex="-1"></a><span class="co">#randomly order the observations </span></span>
<span id="cb403-5"><a href="estimation-with-frequentist-inference.html#cb403-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">124</span>)</span>
<span id="cb403-6"><a href="estimation-with-frequentist-inference.html#cb403-6" tabindex="-1"></a>status <span class="ot">&lt;-</span> <span class="fu">sample</span>(status, <span class="at">replace=</span><span class="cn">FALSE</span>) </span>
<span id="cb403-7"><a href="estimation-with-frequentist-inference.html#cb403-7" tabindex="-1"></a><span class="fu">head</span>(status)</span></code></pre></div>
<pre><code>## [1] 0 1 0 0 0 0</code></pre>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="estimation-with-frequentist-inference.html#cb405-1" tabindex="-1"></a><span class="co">#confirm the proportion infected is 11% </span></span>
<span id="cb405-2"><a href="estimation-with-frequentist-inference.html#cb405-2" tabindex="-1"></a><span class="fu">mean</span>(status)</span></code></pre></div>
<pre><code>## [1] 0.11</code></pre>
<p>Now let’s quantify the point estimate for the proportion infected as we increase the sample size from <span class="math inline">\(N = 1\)</span> to <span class="math inline">\(N = 10000\)</span>. To get a sense for this, we can see above that the first individual is not infected (<code>status</code> = 0), so based on that individual with a sample size of <span class="math inline">\(N = 1\)</span>, the estimated prevalence is 0%. Then we look at the second individual, who is infected (<code>status</code> = 1), making the point estimate <span class="math inline">\(\hat{p}=\frac{1}{2}=0.5\)</span> based on <span class="math inline">\(N = 2\)</span>. The third individual is not infected, making the point estimate <span class="math inline">\(\hat{p}=\frac{1}{3}=0.33\)</span>, and so on. We can compute the point estimate for each individual observation with the code below:</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="estimation-with-frequentist-inference.html#cb407-1" tabindex="-1"></a><span class="co">#creates the cumulative sum from each observation</span></span>
<span id="cb407-2"><a href="estimation-with-frequentist-inference.html#cb407-2" tabindex="-1"></a>status.cumsum <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(status)</span>
<span id="cb407-3"><a href="estimation-with-frequentist-inference.html#cb407-3" tabindex="-1"></a></span>
<span id="cb407-4"><a href="estimation-with-frequentist-inference.html#cb407-4" tabindex="-1"></a><span class="co">#cumulative sample size </span></span>
<span id="cb407-5"><a href="estimation-with-frequentist-inference.html#cb407-5" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">seq_along</span>(status)</span>
<span id="cb407-6"><a href="estimation-with-frequentist-inference.html#cb407-6" tabindex="-1"></a></span>
<span id="cb407-7"><a href="estimation-with-frequentist-inference.html#cb407-7" tabindex="-1"></a><span class="co">#quantify the point estimates</span></span>
<span id="cb407-8"><a href="estimation-with-frequentist-inference.html#cb407-8" tabindex="-1"></a>p.hat.infected <span class="ot">&lt;-</span> status.cumsum<span class="sc">/</span><span class="fu">seq_along</span>(status)</span>
<span id="cb407-9"><a href="estimation-with-frequentist-inference.html#cb407-9" tabindex="-1"></a></span>
<span id="cb407-10"><a href="estimation-with-frequentist-inference.html#cb407-10" tabindex="-1"></a><span class="co">#create a dataframe</span></span>
<span id="cb407-11"><a href="estimation-with-frequentist-inference.html#cb407-11" tabindex="-1"></a>sim.law.large <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(status.cumsum, n, p.hat.infected)</span>
<span id="cb407-12"><a href="estimation-with-frequentist-inference.html#cb407-12" tabindex="-1"></a><span class="fu">head</span>(sim.law.large)</span></code></pre></div>
<pre><code>##   status.cumsum n p.hat.infected
## 1             0 1      0.0000000
## 2             1 2      0.5000000
## 3             1 3      0.3333333
## 4             1 4      0.2500000
## 5             1 5      0.2000000
## 6             1 6      0.1666667</code></pre>
<p>Now let’s graph the estimated proportion against the sample size:</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="estimation-with-frequentist-inference.html#cb409-1" tabindex="-1"></a><span class="fu">ggplot</span>(sim.law.large, <span class="fu">aes</span>(<span class="at">x =</span> n, <span class="at">y =</span> p.hat.infected)) <span class="sc">+</span></span>
<span id="cb409-2"><a href="estimation-with-frequentist-inference.html#cb409-2" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">linewidth=</span><span class="fl">0.7</span>) <span class="sc">+</span>  <span class="co"># Line graph for p.hat.infected</span></span>
<span id="cb409-3"><a href="estimation-with-frequentist-inference.html#cb409-3" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.11</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span>  <span class="co"># Truth line</span></span>
<span id="cb409-4"><a href="estimation-with-frequentist-inference.html#cb409-4" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb409-5"><a href="estimation-with-frequentist-inference.html#cb409-5" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Sample Size (n)&quot;</span>, </span>
<span id="cb409-6"><a href="estimation-with-frequentist-inference.html#cb409-6" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Estimated Proportion Infected&quot;</span>, </span>
<span id="cb409-7"><a href="estimation-with-frequentist-inference.html#cb409-7" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;&quot;</span></span>
<span id="cb409-8"><a href="estimation-with-frequentist-inference.html#cb409-8" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb409-9"><a href="estimation-with-frequentist-inference.html#cb409-9" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb409-10"><a href="estimation-with-frequentist-inference.html#cb409-10" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb409-11"><a href="estimation-with-frequentist-inference.html#cb409-11" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)  <span class="co"># Center the title</span></span>
<span id="cb409-12"><a href="estimation-with-frequentist-inference.html#cb409-12" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk07-1.png" alt="Illustration of the Law of Large numbers, showing that as the sample size approaches the size of the target population, the point estimate converges on the true parameter value." width="70%" />
<p class="caption">
(#fig:a01_chunk07)Illustration of the Law of Large numbers, showing that as the sample size approaches the size of the target population, the point estimate converges on the true parameter value.
</p>
</div>
<p>Figure @ref(fig:a01_chunk07) illustrates the Law of Large numbers nicely. We see that the point estimate of the parameter moves around wildly when sample size is small, but eventually the sample size converges on the true value of 0.11. There are deviations between the point estimate and the true parameter value at basically every sample size below the size of the target population, but these deviations get smaller as the sample size increases. This phenomenon is true when trying to estimate any type of parameter, whether it is a proportion, mean, median, variance, etc.</p>
</div>
<div id="variance-affects-precision" class="section level4 hasAnchor" number="15.2.2.2">
<h4><span class="header-section-number">15.2.2.2</span> Variance affects precision<a href="estimation-with-frequentist-inference.html#variance-affects-precision" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Sample size is not the <em>only</em> factor that affects precision. Precision is also affected by the variance of the underlying random variable. Precision of a point estimate decreases as variance increases. This should make intuitive sense. The idea is that when there’s greater variability in the underying distribution of the random variable, there’s greater potential to select extreme observations into the sample, which increases the variability of the point estimate.</p>
<p>We can see this for our example of estimate disease prevalence. Remember that for the binomial distribution, the variance is determiend by the true proportion: <span class="math inline">\(p(1-p)\)</span> The variance reaches its maximum value when <span class="math inline">\(p = 0.5\)</span>. Figure @ref(fig:a01_chunk08) compares sampling distributions for when the prevalence is 11% vs. 50% with an identical sample size of N=100.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="estimation-with-frequentist-inference.html#cb410-1" tabindex="-1"></a><span class="co">#all possible values of positive tests</span></span>
<span id="cb410-2"><a href="estimation-with-frequentist-inference.html#cb410-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb410-3"><a href="estimation-with-frequentist-inference.html#cb410-3" tabindex="-1"></a></span>
<span id="cb410-4"><a href="estimation-with-frequentist-inference.html#cb410-4" tabindex="-1"></a><span class="co">#probability of each outcome assuming prevalence is 11%</span></span>
<span id="cb410-5"><a href="estimation-with-frequentist-inference.html#cb410-5" tabindex="-1"></a>p11 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> x, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> <span class="fl">0.11</span>)</span>
<span id="cb410-6"><a href="estimation-with-frequentist-inference.html#cb410-6" tabindex="-1"></a>p50 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="at">x =</span> x, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> <span class="fl">0.50</span>)</span>
<span id="cb410-7"><a href="estimation-with-frequentist-inference.html#cb410-7" tabindex="-1"></a></span>
<span id="cb410-8"><a href="estimation-with-frequentist-inference.html#cb410-8" tabindex="-1"></a><span class="co">#combine into a data frame</span></span>
<span id="cb410-9"><a href="estimation-with-frequentist-inference.html#cb410-9" tabindex="-1"></a>d11 <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">p =</span> <span class="dv">11</span>, <span class="at">p.hat =</span> x<span class="sc">/</span><span class="dv">100</span>, <span class="at">prob =</span> p11)</span>
<span id="cb410-10"><a href="estimation-with-frequentist-inference.html#cb410-10" tabindex="-1"></a>d50 <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">p =</span> <span class="dv">50</span>, <span class="at">p.hat =</span> x<span class="sc">/</span><span class="dv">100</span>, <span class="at">prob =</span> p50)</span>
<span id="cb410-11"><a href="estimation-with-frequentist-inference.html#cb410-11" tabindex="-1"></a>d_all <span class="ot">&lt;-</span> <span class="fu">rbind</span>(d11, d50)</span>
<span id="cb410-12"><a href="estimation-with-frequentist-inference.html#cb410-12" tabindex="-1"></a></span>
<span id="cb410-13"><a href="estimation-with-frequentist-inference.html#cb410-13" tabindex="-1"></a><span class="co">#plot the sampling distribution</span></span>
<span id="cb410-14"><a href="estimation-with-frequentist-inference.html#cb410-14" tabindex="-1"></a><span class="fu">ggplot</span>(d_all, <span class="fu">aes</span>(<span class="at">x =</span> p.hat, <span class="at">y =</span> prob)) <span class="sc">+</span></span>
<span id="cb410-15"><a href="estimation-with-frequentist-inference.html#cb410-15" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">data =</span> d_all[d_all<span class="sc">$</span>p <span class="sc">==</span> <span class="dv">11</span>, ], </span>
<span id="cb410-16"><a href="estimation-with-frequentist-inference.html#cb410-16" tabindex="-1"></a>           <span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">width =</span> <span class="fl">0.01</span>) <span class="sc">+</span></span>
<span id="cb410-17"><a href="estimation-with-frequentist-inference.html#cb410-17" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">data =</span> d_all[d_all<span class="sc">$</span>p <span class="sc">==</span> <span class="dv">50</span>, ], </span>
<span id="cb410-18"><a href="estimation-with-frequentist-inference.html#cb410-18" tabindex="-1"></a>           <span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">width =</span> <span class="fl">0.01</span>) <span class="sc">+</span></span>
<span id="cb410-19"><a href="estimation-with-frequentist-inference.html#cb410-19" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> p, <span class="at">ncol =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>, </span>
<span id="cb410-20"><a href="estimation-with-frequentist-inference.html#cb410-20" tabindex="-1"></a>             <span class="at">labeller =</span> <span class="fu">as_labeller</span>(<span class="fu">c</span>(</span>
<span id="cb410-21"><a href="estimation-with-frequentist-inference.html#cb410-21" tabindex="-1"></a>            <span class="st">`</span><span class="at">11</span><span class="st">`</span> <span class="ot">=</span> <span class="st">&quot;p = 0.11, N = 100&quot;</span>,</span>
<span id="cb410-22"><a href="estimation-with-frequentist-inference.html#cb410-22" tabindex="-1"></a>            <span class="st">`</span><span class="at">50</span><span class="st">`</span> <span class="ot">=</span> <span class="st">&quot;p = 0.50, N = 100&quot;</span></span>
<span id="cb410-23"><a href="estimation-with-frequentist-inference.html#cb410-23" tabindex="-1"></a>        ))) <span class="sc">+</span></span>
<span id="cb410-24"><a href="estimation-with-frequentist-inference.html#cb410-24" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb410-25"><a href="estimation-with-frequentist-inference.html#cb410-25" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Estimated proportion of positives&quot;</span>, </span>
<span id="cb410-26"><a href="estimation-with-frequentist-inference.html#cb410-26" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Probability&quot;</span>, </span>
<span id="cb410-27"><a href="estimation-with-frequentist-inference.html#cb410-27" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb410-28"><a href="estimation-with-frequentist-inference.html#cb410-28" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span> </span>
<span id="cb410-29"><a href="estimation-with-frequentist-inference.html#cb410-29" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>), </span>
<span id="cb410-30"><a href="estimation-with-frequentist-inference.html#cb410-30" tabindex="-1"></a>        <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">size =</span> <span class="dv">11</span>))</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk08-1.png" alt="Sampling distributions of the estimated prevalence of infection based on a sample size of 100 when the prevalence of infection is 11% (low variance) vs. 50% (high variance)." width="70%" />
<p class="caption">
(#fig:a01_chunk08)Sampling distributions of the estimated prevalence of infection based on a sample size of 100 when the prevalence of infection is 11% (low variance) vs. 50% (high variance).
</p>
</div>
<p>Figure @ref(fig:a01_chunk08) shows that the sampling distributions are centered in different locations, each being centered on the true parameter value (11% vs. 50%). But what you should also notice is that sampling distribution is wider (less precise) when the prevalence is 50% (higher variance) than when it is 11% (lower variance). The take-home here is that estimates will be less precise when sampling from random variables that have greater variance. Unlike sample size, this isn’t something you can control.</p>
<p>This might make more sense with a different type of variable. Imagine that you’re estimating the mean height of a group of people. We’ll assume height follows a normal distribution where the true mean height is <span class="math inline">\(\mu = 65\)</span> inches. Let’s further assume that we draw a sample of 100 people to estimate the height, but let’s do so from two populations that differ in the variance of height. In one population, we’ll assume the standard deviation is <span class="math inline">\(\sigma = 5\)</span> inches, and in the other population we’ll assume the standard deviation is <span class="math inline">\(sigma = 2\)</span> inches. We can visualize these normal distributions and see that there’s more variation among individual height when <span class="math inline">\(\sigma = 5\)</span> than when <span class="math inline">\(\sigma = 2\)</span> (Figure @ref(fig:a01_chunk09))</p>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk09-1.png" alt="Assumed distributions of height where the mean height is 65 inches and the standard deviation is either 2 or 5 inches." width="70%" />
<p class="caption">
(#fig:a01_chunk09)Assumed distributions of height where the mean height is 65 inches and the standard deviation is either 2 or 5 inches.
</p>
</div>
<p>We now go ahead and generate 10,000 replicate samples of N = 100 from the underlying populations, one where <span class="math inline">\(\mu=65\)</span> and <span class="math inline">\(\sigma=2\)</span> and the other where <span class="math inline">\(\mu=65\)</span> and <span class="math inline">\(\sigma=5\)</span>.</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="estimation-with-frequentist-inference.html#cb411-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb411-2"><a href="estimation-with-frequentist-inference.html#cb411-2" tabindex="-1"></a></span>
<span id="cb411-3"><a href="estimation-with-frequentist-inference.html#cb411-3" tabindex="-1"></a><span class="co">#sample sizes to evaluate</span></span>
<span id="cb411-4"><a href="estimation-with-frequentist-inference.html#cb411-4" tabindex="-1"></a>stdevs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>) </span>
<span id="cb411-5"><a href="estimation-with-frequentist-inference.html#cb411-5" tabindex="-1"></a></span>
<span id="cb411-6"><a href="estimation-with-frequentist-inference.html#cb411-6" tabindex="-1"></a><span class="co">#empty data frame to store results</span></span>
<span id="cb411-7"><a href="estimation-with-frequentist-inference.html#cb411-7" tabindex="-1"></a>sampling_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb411-8"><a href="estimation-with-frequentist-inference.html#cb411-8" tabindex="-1"></a></span>
<span id="cb411-9"><a href="estimation-with-frequentist-inference.html#cb411-9" tabindex="-1"></a><span class="co">#loop to simulate sampling process at each sample size 10000 times</span></span>
<span id="cb411-10"><a href="estimation-with-frequentist-inference.html#cb411-10" tabindex="-1"></a><span class="cf">for</span> (stdev <span class="cf">in</span> stdevs) {</span>
<span id="cb411-11"><a href="estimation-with-frequentist-inference.html#cb411-11" tabindex="-1"></a>  </span>
<span id="cb411-12"><a href="estimation-with-frequentist-inference.html#cb411-12" tabindex="-1"></a>  <span class="co">#draw samples 10,000 times and compute sample mean</span></span>
<span id="cb411-13"><a href="estimation-with-frequentist-inference.html#cb411-13" tabindex="-1"></a>  sample_means <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">10000</span>, <span class="fu">mean</span>(<span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">65</span>, <span class="at">sd =</span> stdev)))</span>
<span id="cb411-14"><a href="estimation-with-frequentist-inference.html#cb411-14" tabindex="-1"></a>  </span>
<span id="cb411-15"><a href="estimation-with-frequentist-inference.html#cb411-15" tabindex="-1"></a>  <span class="co">#store results</span></span>
<span id="cb411-16"><a href="estimation-with-frequentist-inference.html#cb411-16" tabindex="-1"></a>  sampling_results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(sampling_results, </span>
<span id="cb411-17"><a href="estimation-with-frequentist-inference.html#cb411-17" tabindex="-1"></a>                            <span class="fu">data.frame</span>(<span class="at">stdev =</span> stdev, </span>
<span id="cb411-18"><a href="estimation-with-frequentist-inference.html#cb411-18" tabindex="-1"></a>                                       <span class="at">sample_mean =</span> sample_means))</span>
<span id="cb411-19"><a href="estimation-with-frequentist-inference.html#cb411-19" tabindex="-1"></a>}</span>
<span id="cb411-20"><a href="estimation-with-frequentist-inference.html#cb411-20" tabindex="-1"></a></span>
<span id="cb411-21"><a href="estimation-with-frequentist-inference.html#cb411-21" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb411-22"><a href="estimation-with-frequentist-inference.html#cb411-22" tabindex="-1"></a><span class="fu">ggplot</span>(sampling_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_mean)) <span class="sc">+</span></span>
<span id="cb411-23"><a href="estimation-with-frequentist-inference.html#cb411-23" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">bins=</span><span class="dv">50</span>, <span class="at">fill =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb411-24"><a href="estimation-with-frequentist-inference.html#cb411-24" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> stdev, <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">scales =</span> <span class="st">&quot;fixed&quot;</span>,</span>
<span id="cb411-25"><a href="estimation-with-frequentist-inference.html#cb411-25" tabindex="-1"></a>               <span class="at">labeller =</span> <span class="fu">as_labeller</span>(<span class="cf">function</span>(x) <span class="fu">paste</span>(<span class="st">&quot;SD =&quot;</span>, x))) <span class="sc">+</span></span>
<span id="cb411-26"><a href="estimation-with-frequentist-inference.html#cb411-26" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb411-27"><a href="estimation-with-frequentist-inference.html#cb411-27" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sample Mean Height (in)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Probability density&quot;</span> ) <span class="sc">+</span></span>
<span id="cb411-28"><a href="estimation-with-frequentist-inference.html#cb411-28" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb411-29"><a href="estimation-with-frequentist-inference.html#cb411-29" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb411-30"><a href="estimation-with-frequentist-inference.html#cb411-30" tabindex="-1"></a>    <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>), </span>
<span id="cb411-31"><a href="estimation-with-frequentist-inference.html#cb411-31" tabindex="-1"></a>    <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">10</span>, <span class="at">face =</span> <span class="st">&quot;bold&quot;</span>),</span>
<span id="cb411-32"><a href="estimation-with-frequentist-inference.html#cb411-32" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">face =</span> <span class="st">&quot;bold&quot;</span>, <span class="at">hjust =</span> <span class="fl">0.5</span>)</span>
<span id="cb411-33"><a href="estimation-with-frequentist-inference.html#cb411-33" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk10-1.png" alt="Sampling distributions of the estimated mean height from samples of N = 100 when the true mean is 65 inches but the standard deviations of height are either 2 vs. 5." width="70%" />
<p class="caption">
(#fig:a01_chunk10)Sampling distributions of the estimated mean height from samples of N = 100 when the true mean is 65 inches but the standard deviations of height are either 2 vs. 5.
</p>
</div>
<p>Figure @ref(fig:a01_chunk10) shows that while both sampling distributions are centered on the true value of 65 inches (that is, the estimates are accurate), the sampling distribution generated from the population with <span class="math inline">\(\sigma=5\)</span> is much wider than the sampling distribution generated from the population with <span class="math inline">\(\sigma=2\)</span>. In other words, precision is much lower when drawing samples from the population with greater variability of individual height, assuming equivalent sample sizes.</p>
<p>The take-home here is that precision will be greatest and uncertainty will be minimized when drawing large sample sizes from populations that have low variance. While you can control sample size as part of the study design, you can’t control the underlying variance of the random variable being studied. Assuming equivalent sample size, estimates from distributions with more variation will more noisy than estimates from distributions with less variation.</p>
</div>
</div>
<div id="sample-size-affects-the-shape-of-sampling-distributions" class="section level3 hasAnchor" number="15.2.3">
<h3><span class="header-section-number">15.2.3</span> Sample size affects the shape of sampling distributions<a href="estimation-with-frequentist-inference.html#sample-size-affects-the-shape-of-sampling-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Going back to the original comparison of sampling distributions at different sample sizes in Figure @ref(fig:a01_chunk11), you might ahve noticed that the shape of the sampling distribution increasingly resembles a normal distribution as the sample size increases. This happens to be a consequence of the <strong>Central Limit Theorem</strong>, which states that the distribution of a sample estimates will be approximately normal at large sample sizes regardless of the shape of probability distribution for the underlying probability distribution.</p>
<p>Let me illustrate this last point with a different example, this time with a quantitative random variable. Suppose you were interested in estimating the average distance people live from an ice cream shop. We’ll assume that the distribution of distances people live from an ice cream shop is skewed to the right. This means most people live close to an ice cream shop, and fewer and fewer people live far from an ice cream shop. This kind of random variable can be described by a <strong>poisson distribution</strong>, which is a probability distribution that often describes things we can count. Let’s create a graph of the probability distribution assuming that the true mean distance to ice cream shop is 1 km:</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="estimation-with-frequentist-inference.html#cb412-1" tabindex="-1"></a><span class="co">#distances in kilometers</span></span>
<span id="cb412-2"><a href="estimation-with-frequentist-inference.html#cb412-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb412-3"><a href="estimation-with-frequentist-inference.html#cb412-3" tabindex="-1"></a>prob <span class="ot">&lt;-</span> <span class="fu">dpois</span>(<span class="at">x =</span> x, <span class="at">lambda =</span> <span class="dv">1</span>) <span class="co">#lambda is the mean distance</span></span>
<span id="cb412-4"><a href="estimation-with-frequentist-inference.html#cb412-4" tabindex="-1"></a></span>
<span id="cb412-5"><a href="estimation-with-frequentist-inference.html#cb412-5" tabindex="-1"></a><span class="co">#data frame for plotting</span></span>
<span id="cb412-6"><a href="estimation-with-frequentist-inference.html#cb412-6" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(x, prob)</span>
<span id="cb412-7"><a href="estimation-with-frequentist-inference.html#cb412-7" tabindex="-1"></a></span>
<span id="cb412-8"><a href="estimation-with-frequentist-inference.html#cb412-8" tabindex="-1"></a><span class="co"># Plot the probability distribution using ggplot2</span></span>
<span id="cb412-9"><a href="estimation-with-frequentist-inference.html#cb412-9" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> prob)) <span class="sc">+</span></span>
<span id="cb412-10"><a href="estimation-with-frequentist-inference.html#cb412-10" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb412-11"><a href="estimation-with-frequentist-inference.html#cb412-11" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Distance to ice cream shop (km)&quot;</span>,</span>
<span id="cb412-12"><a href="estimation-with-frequentist-inference.html#cb412-12" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Probability&quot;</span>) <span class="sc">+</span></span>
<span id="cb412-13"><a href="estimation-with-frequentist-inference.html#cb412-13" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk11-1.png" alt="Probability distribution of distance to ice cream shop. Distance to ice cream shop was assumed to follow a poisson distribution with a mean of 1 km." width="70%" />
<p class="caption">
(#fig:a01_chunk11)Probability distribution of distance to ice cream shop. Distance to ice cream shop was assumed to follow a poisson distribution with a mean of 1 km.
</p>
</div>
<p>We can clearly see in Figure @ref(fig:a01_chunk11) that the underlying distribution of distances is not normal! It’s strongly skewed to the right and represents a poisson distribution. Now let’s simualate the process of randomly sampling homes to estimate the mean distance people live from an ice cream shop.</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="estimation-with-frequentist-inference.html#cb413-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb413-2"><a href="estimation-with-frequentist-inference.html#cb413-2" tabindex="-1"></a></span>
<span id="cb413-3"><a href="estimation-with-frequentist-inference.html#cb413-3" tabindex="-1"></a><span class="co">#sample sizes to evaluate</span></span>
<span id="cb413-4"><a href="estimation-with-frequentist-inference.html#cb413-4" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>) </span>
<span id="cb413-5"><a href="estimation-with-frequentist-inference.html#cb413-5" tabindex="-1"></a></span>
<span id="cb413-6"><a href="estimation-with-frequentist-inference.html#cb413-6" tabindex="-1"></a><span class="co">#empty data frame to store results</span></span>
<span id="cb413-7"><a href="estimation-with-frequentist-inference.html#cb413-7" tabindex="-1"></a>sampling_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb413-8"><a href="estimation-with-frequentist-inference.html#cb413-8" tabindex="-1"></a><span class="co">#loop to simulate sampling process at each sample size 10000 times</span></span>
<span id="cb413-9"><a href="estimation-with-frequentist-inference.html#cb413-9" tabindex="-1"></a><span class="cf">for</span> (sample_size <span class="cf">in</span> sample_sizes) {</span>
<span id="cb413-10"><a href="estimation-with-frequentist-inference.html#cb413-10" tabindex="-1"></a>  </span>
<span id="cb413-11"><a href="estimation-with-frequentist-inference.html#cb413-11" tabindex="-1"></a>  <span class="co">#draw samples 10,000 times and compute sample mean</span></span>
<span id="cb413-12"><a href="estimation-with-frequentist-inference.html#cb413-12" tabindex="-1"></a>  sample_means <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">10000</span>, <span class="fu">mean</span>(<span class="fu">rpois</span>(sample_size, <span class="at">lambda =</span> <span class="dv">1</span>)))</span>
<span id="cb413-13"><a href="estimation-with-frequentist-inference.html#cb413-13" tabindex="-1"></a>  </span>
<span id="cb413-14"><a href="estimation-with-frequentist-inference.html#cb413-14" tabindex="-1"></a>  <span class="co">#store results</span></span>
<span id="cb413-15"><a href="estimation-with-frequentist-inference.html#cb413-15" tabindex="-1"></a>  sampling_results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(sampling_results, </span>
<span id="cb413-16"><a href="estimation-with-frequentist-inference.html#cb413-16" tabindex="-1"></a>                            <span class="fu">data.frame</span>(<span class="at">sample_size =</span> sample_size, </span>
<span id="cb413-17"><a href="estimation-with-frequentist-inference.html#cb413-17" tabindex="-1"></a>                                       <span class="at">sample_mean =</span> sample_means))</span>
<span id="cb413-18"><a href="estimation-with-frequentist-inference.html#cb413-18" tabindex="-1"></a>}</span>
<span id="cb413-19"><a href="estimation-with-frequentist-inference.html#cb413-19" tabindex="-1"></a></span>
<span id="cb413-20"><a href="estimation-with-frequentist-inference.html#cb413-20" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb413-21"><a href="estimation-with-frequentist-inference.html#cb413-21" tabindex="-1"></a><span class="fu">ggplot</span>(sampling_results, <span class="fu">aes</span>(<span class="at">x =</span> sample_mean)) <span class="sc">+</span></span>
<span id="cb413-22"><a href="estimation-with-frequentist-inference.html#cb413-22" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">fill =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb413-23"><a href="estimation-with-frequentist-inference.html#cb413-23" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> sample_size, <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>,</span>
<span id="cb413-24"><a href="estimation-with-frequentist-inference.html#cb413-24" tabindex="-1"></a>               <span class="at">labeller =</span> <span class="fu">as_labeller</span>(<span class="cf">function</span>(x) <span class="fu">paste</span>(<span class="st">&quot;N =&quot;</span>, x))) <span class="sc">+</span></span>
<span id="cb413-25"><a href="estimation-with-frequentist-inference.html#cb413-25" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb413-26"><a href="estimation-with-frequentist-inference.html#cb413-26" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sample Mean&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Probability density&quot;</span> ) <span class="sc">+</span></span>
<span id="cb413-27"><a href="estimation-with-frequentist-inference.html#cb413-27" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb413-28"><a href="estimation-with-frequentist-inference.html#cb413-28" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb413-29"><a href="estimation-with-frequentist-inference.html#cb413-29" tabindex="-1"></a>    <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>), </span>
<span id="cb413-30"><a href="estimation-with-frequentist-inference.html#cb413-30" tabindex="-1"></a>    <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">10</span>, <span class="at">face =</span> <span class="st">&quot;bold&quot;</span>),</span>
<span id="cb413-31"><a href="estimation-with-frequentist-inference.html#cb413-31" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">face =</span> <span class="st">&quot;bold&quot;</span>, <span class="at">hjust =</span> <span class="fl">0.5</span>),</span>
<span id="cb413-32"><a href="estimation-with-frequentist-inference.html#cb413-32" tabindex="-1"></a>    <span class="at">plot.caption =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">10</span>, <span class="at">hjust =</span> <span class="fl">0.5</span>)</span>
<span id="cb413-33"><a href="estimation-with-frequentist-inference.html#cb413-33" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk12-1.png" alt="Sampling distribution for the estimated mean distance people live from an ice cream shop based on samples of size N = 1, 2, 5, 10, 50, 100, 500, and 1000. Note that the scale of the x-axis varies among plots (becoming more narrow as sample size increases) in order to highlight the shape of each sampling distribution." width="672" />
<p class="caption">
(#fig:a01_chunk12)Sampling distribution for the estimated mean distance people live from an ice cream shop based on samples of size N = 1, 2, 5, 10, 50, 100, 500, and 1000. Note that the scale of the x-axis varies among plots (becoming more narrow as sample size increases) in order to highlight the shape of each sampling distribution.
</p>
</div>
<p>Figure @ref(fig:a01_chunk12) shows that as the sample size increases, the shape of the sampling distribution increasingly resembles a normal distribution. This happens even though the underlying probability distribution for the random variable is not normal. Indeed, we can see that when the sample size is only one, the sampling distribution is identical to the distribution of the underlying variable. But it doesn’t take many observations for the sampling distribution to take on the classic bell shape of a normal distribution.</p>
</div>
<div id="summary-points-on-sampling-distributions" class="section level3 hasAnchor" number="15.2.4">
<h3><span class="header-section-number">15.2.4</span> Summary points on sampling distributions<a href="estimation-with-frequentist-inference.html#summary-points-on-sampling-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>That was a lot! But there’s a reason for that. Understanding the concept of sampling distributions is really important for understanding how frequentist inference is carried out. Let’s wrap up this section by summarizing some fundamental principles of frequentist inference related to sampling:</p>
<ol style="list-style-type: decimal">
<li><p>If we take repeated samples from the same population to estimate a parameter, the estimates from different will not be the same due to random sampling error. The distribution of sample estimates given a specific sample size is the sampling distribution.</p></li>
<li><p>The expected value of the sampling distribution is the true value of the parameter regardless of sample size. Because sample size doesn’t affect statistical accuracy, the primary way to minimize bias in estimates is through research design strategies.</p></li>
<li><p>As sample size increases, the precision of estimates increases, and the more likely a sample estimate will be close to the true parameter value. (Law of Large Numbers)</p></li>
<li><p>The sampling distribution increasingly approximates a noral distribution as the sample size increases (Central Limit Theorem)</p></li>
</ol>
</div>
</div>
<div id="quantifying-uncertainty-standard-error-and-confidence-intervals" class="section level2 hasAnchor" number="15.3">
<h2><span class="header-section-number">15.3</span> Quantifying uncertainty: standard error and confidence intervals<a href="estimation-with-frequentist-inference.html#quantifying-uncertainty-standard-error-and-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we know a) the width of the sampling distribution represents uncertainty about a parameter estimate and b) the sampling distribution is approximately normal under large sample sizes, we can turn to quantifying the degree of uncertainty in estimates from a sample. We’ll quantify uncertainty in two ways, the standard error and confidence intervas.</p>
<div id="standard-error" class="section level3 hasAnchor" number="15.3.1">
<h3><span class="header-section-number">15.3.1</span> Standard error<a href="estimation-with-frequentist-inference.html#standard-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Rather than just visually examining the width of a sampling distribution to gauge precision, we can quantify the variation in a sampling distribution. Recall that the standard deviation represents the variation among values for a random variable that follows a normal distribution. If the sampling distribution has a normal distribution, we can simply quantify the standard deviation of the sampling distribution as a measure of precision. The standard deviation of the sampling distribution is called the <strong>standard error</strong> and is quantified as the ratio of the standard deviation of the underlying random variable to the square root of the sample size:</p>
<p><span class="math display">\[
SE = \frac{SD}{\sqrt{N}}
\]</span></p>
<p>This is a generic formula to quantify the standard error of an estimate taken from a sample when the sampling distribution is approximately normal. It can be applied to estimates of means, proportions, model coefficients, and more. The standard deviation is quantified differently for these parameters, so you will need to substitute <span class="math inline">\(SD\)</span> for the particular standard deviation formula for the parameter of interest. For example, the standard deviation of proportions is quantified as <span class="math inline">\(\sqrt{p(1-p)}\)</span>, so the standard error of a proportion is:</p>
<p><span class="math display">\[
SE_{\hat{p}} = \frac{\sqrt{p(1-p)}}{\sqrt{N}}
\]</span></p>
<p>Consider our goal of estimating the prevalence of infection with a sample of 100 individuals when the true prevalence was 11%. Thus, the standard error is</p>
<p><span class="math display">\[
SE_{\hat{p}} = \frac{\sqrt{0.11(1-0.11)}}{\sqrt{100}} = 0.0312
\]</span></p>
<p>We know the estimate based on our single sample of N = 100 was 8%, which has a straightforward interpretation. But how do we interpret a standard error of 0.03? In a general sense, higher values for the standard error simply indicate more uncertainty (less precision) about the sample estimate. In other words, we should have more confidence in an estimate with a standard error of 0.03 than an estimate with a standard error of 0.1.</p>
<p>But maybe you have noticed there is a problem here. How can you compute the standard error of a sample estimate when you don’t know the true population parameters? Look again at the formula for the standard error of the estimated prevalence. It includes the true prevalence as part of the formula for the standard deviation in the numerator. But we don’t know the true prevalence! We’re working through this process of estimation precisely because we don’t know the true value of the parameter.</p>
<p>So what are we to do? In practice, the best we can do is substitute our estimate(s) for the true parameter value(s) in the formula for the standard deviation. You have to imagine the situation where we really don’t know the true prevalence is 11%. All we know is that we’ve estimated the prevalence to be 8% based on N = 100. We use this information to estimate the standard error as</p>
<p><span class="math display">\[
SE_{\hat{p}} = \frac{\sqrt{\hat{p}(1-\hat{p})}}{\sqrt{N}} =\frac{\sqrt{0.08(1-0.08)}}{\sqrt{100}} = 0.0271
\]</span></p>
<p>You can see the estimated standard error is not that different from the true standard error <a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
</div>
<div id="confidence-intervals" class="section level3 hasAnchor" number="15.3.2">
<h3><span class="header-section-number">15.3.2</span> Confidence intervals<a href="estimation-with-frequentist-inference.html#confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall the empirical rule, which states that for a normal distribution approximately two thirds of observations will be within one standard deviation of the mean, and approximately 95% of observations will be within two standard deviations of the mean. Thus, when we obtain a point estimate of a parameter from a sample and estimate the standard error (i.e., the standard deviation of the sampling distribution), we can use that information to quantify a <em>range</em> of possible values for the true population parameter at a given level of confidence. Such a range is called a <strong>confidence interval</strong>.</p>
<div id="quantifying-confidence-intervals-when-you-know-the-standard-deviation" class="section level4 hasAnchor" number="15.3.2.1">
<h4><span class="header-section-number">15.3.2.1</span> Quantifying confidence intervals when you know the standard deviation<a href="estimation-with-frequentist-inference.html#quantifying-confidence-intervals-when-you-know-the-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Remember the standard normal distribution (<em>Z</em>)? The units of Z in the standard normal are in units of standard deviations. Let’s find the value of Z that includes 95% of observations from the mean (which is 0 in a standard normal):</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="estimation-with-frequentist-inference.html#cb414-1" tabindex="-1"></a><span class="co">#what value of Z has 2.5% of observations below it?</span></span>
<span id="cb414-2"><a href="estimation-with-frequentist-inference.html#cb414-2" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.025</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">lower.tail=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] -1.959964</code></pre>
<p>Here we see that 2.5% of observations are below the value Z = -1.96. Because the normal distribution is symmetric, this means that 2.5% of observations are also above the value Z = 1.96. Figure @ref(fig:a01_chunk14) shows the standard normal distribution highlighting the middle 95% of observations.</p>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk14-1.png" alt="Standard normal distribution showing hte middle 95% of observations between Z = -1.96 and Z = 1.96." width="672" />
<p class="caption">
(#fig:a01_chunk14)Standard normal distribution showing hte middle 95% of observations between Z = -1.96 and Z = 1.96.
</p>
</div>
<p>If we think about a standard normal distribution representing a sampling distribution, by definition there is a 95% chance that a point estimate of a parameter from a randomly drawn sample will be between Z = -1.96 standard errors below the true parameter value and 1.96 standard errors above the true parameter value. The Z score for our particular point estimate is</p>
<p><span class="math display">\[
Z = \frac{\hat{\mu}-\mu}{\sigma_\mu}
\]</span></p>
<p>where <span class="math inline">\(\hat{\mu}\)</span> is the estimated mean, <span class="math inline">\(\mu\)</span> is the true mean, and <span class="math inline">\(\sigma_\mu\)</span> is the true standard error. Thus, it must be the case that in 95% of random samples,</p>
<p><span class="math display">\[
-1.96 &lt; \frac{\hat{\mu}-\mu}{\sigma_\mu} &lt; 1.96
\]</span></p>
<p>Rearranging this inequality, we obtain a 95% confidence interval:</p>
<p><span class="math display">\[
\hat{\mu} -1.96*\sigma_\mu &lt; \mu &lt; \hat{\mu} +1.96*\sigma_\mu
\]</span></p>
<p>The inequality expresses the idea that we should be 95% confident that a point estimate <span class="math inline">\(\hat{\mu}\)</span> from a random sample will be within the range of values defined by <span class="math inline">\(\hat{\mu}\pm 1.96*\sigma_\mu\)</span>.</p>
<p>Can we apply this to our estimated proportion of infection? Yes, we sure we can. Remember that under the central limit theorem, we expect sampling distributions to be approximately normally distributed under large sample size, and N = 100 is a reasonably large sample size. If our point estimate is 0.08 and the true standard error is 0.03, we can be 95% confident that the true parameter value is within the range <span class="math inline">\(0.08\pm 1.96*0.03\)</span>, which corresponds to <span class="math inline">\(0.021 &lt; \mu &lt; 0.139\)</span>.</p>
<p>There’s no reason we have to quantify confidence intervals at a level of 95%. Indeed we can quantify a confidence interval at any degree of confidence using the following general formula:</p>
<p><span class="math display">\[
\hat{\mu}\pm Z_{\alpha/2}*\sigma_\mu \\
\]</span>
where <span class="math inline">\(\alpha\)</span> is the <strong>significance value</strong>. The significance value refers to the probability of observations in the tails, so the level of confidence is <span class="math inline">\(1 - \alpha\)</span>. For example, <span class="math inline">\(\alpha = 0.1\)</span> for a 90% confidence interval. The quantity of <span class="math inline">\(\pm Z_{\alpha}*\sigma_\mu\)</span> is called the <strong>margin of error</strong>.</p>
<p>To quantify a 90% confidence interval for our example of infection prevalence, we simply need to find the value of Z leaving 10% of observations in the tails (5% of observations in each tail). Here’s how we can do it in R:</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="estimation-with-frequentist-inference.html#cb416-1" tabindex="-1"></a><span class="co">#90% confidence level</span></span>
<span id="cb416-2"><a href="estimation-with-frequentist-inference.html#cb416-2" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.1</span></span>
<span id="cb416-3"><a href="estimation-with-frequentist-inference.html#cb416-3" tabindex="-1"></a></span>
<span id="cb416-4"><a href="estimation-with-frequentist-inference.html#cb416-4" tabindex="-1"></a><span class="co">#Z for 90% confidence level</span></span>
<span id="cb416-5"><a href="estimation-with-frequentist-inference.html#cb416-5" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">qnorm</span>(alpha<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">lower.tail=</span><span class="cn">TRUE</span>)) <span class="co">#abs for positive Z</span></span>
<span id="cb416-6"><a href="estimation-with-frequentist-inference.html#cb416-6" tabindex="-1"></a></span>
<span id="cb416-7"><a href="estimation-with-frequentist-inference.html#cb416-7" tabindex="-1"></a><span class="co">#lower confidence limit: point estimate - z*SE</span></span>
<span id="cb416-8"><a href="estimation-with-frequentist-inference.html#cb416-8" tabindex="-1"></a><span class="fl">0.08</span> <span class="sc">-</span> z<span class="sc">*</span><span class="fl">0.03</span></span></code></pre></div>
<pre><code>## [1] 0.03065439</code></pre>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="estimation-with-frequentist-inference.html#cb418-1" tabindex="-1"></a><span class="co">#upper confidence limit: point estimate + z*SE</span></span>
<span id="cb418-2"><a href="estimation-with-frequentist-inference.html#cb418-2" tabindex="-1"></a><span class="fl">0.08</span> <span class="sc">+</span> z<span class="sc">*</span><span class="fl">0.03</span></span></code></pre></div>
<pre><code>## [1] 0.1293456</code></pre>
<p>We see that the 90% confidence interval for the point estimate 0.08 and standard error 0.03 is 3% - 13%. In other words, we can be 90% confident that the true proportion infected is between 3% and 13%. Notice that the range of confindence interval narrows as the confidence level decreases.</p>
</div>
<div id="quantifying-confidence-intervals-when-you-dont-know-the-standard-deviation" class="section level4 hasAnchor" number="15.3.2.2">
<h4><span class="header-section-number">15.3.2.2</span> Quantifying confidence intervals when you don’t know the standard deviation<a href="estimation-with-frequentist-inference.html#quantifying-confidence-intervals-when-you-dont-know-the-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Wait a second! The formula to quantify a confidence interval with the standard normal (Z) assumes that we know the standard deviation (and therefore the standard error) with certainty. We only know the true standard error in this case because we simulated the data, but again, we’re estimating quantities precisely because we don’t know them.</p>
<p>It turns out there’s only a slight modification in our approach when we don’t know the true standard deviation and standard error. But the approach differs when we’re estimating proportions versus means. When we’re estimating proportions with an unknown standard error, all we have to do is substitute the estimated standard error for the true standard error. In other words, a 95% confidence interval for a proportion is quantified as</p>
<p><span class="math display">\[
\hat{p} -1.96*SE_{\hat{p}} &lt; p &lt; \hat{p} +1.96*SE_{\hat{p}}
\]</span></p>
<p>Thus, if all we had was our single sample with 8 out of 100 positive tests, the estimated standard error is 0.0271 (from above), and the 95% confidence interval can be quantified as is <span class="math inline">\(0.08\pm 1.96*0.0271\)</span>, which corresponds to <span class="math inline">\(0.027 &lt; \mu &lt; 0.133\)</span>. That’s it! Really straightforward.</p>
<p>What about when we’re estimating means? For means, things are slightly more complicated. The reason is that the normal distribution has two parameters, the mean and standard deviation, both of which must be estimated with data. In contrast, the standard deviation of a proportion is quantified directly from the value of the proportion itself. Ultimately this means there is slightly more uncertainty when estimating a standard deviation for normally distributed variables compared to binomially distributed variables. That additional uncertainty gets included as part of the process of quantifying the confidence interval.</p>
<p>How does it work? Rather than using the standard normal distribution, we use a normal probability distribution that has <em>slightly</em> heavier tails (i.e., slightly wider) compard to the standard normal distribution. This modified distribution is called a <strong>t-distribution</strong>. The degree to which more probability is added to the tails of a <em>t</em>-distribution relative to a standard normal is dependent on sample size. When the sample size is low, the standard deviation is being estimated with less precision, and more probability density is added to the tails to reflect greater uncertainty.</p>
<p>The particular shape of a <em>t</em> distribution is specified by the <strong>degrees of freedom</strong>, which in this case is defined as <span class="math inline">\(df=N-1\)</span>. Thus, the appropriate <em>t</em>-distribution for a sample of size N = 50 has <span class="math inline">\(df = 50 - 1 = 49\)</span>. As the sample size increases, the <em>t</em>-distribution converges on the standard normal distribution, which can be seen in Figure @ref(fig:a01_chunk16).</p>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk16-1.png" alt="Comparisong of t-distributions with varying degrees of freedom to the standard normal distribution (Z)" width="672" />
<p class="caption">
(#fig:a01_chunk16)Comparisong of t-distributions with varying degrees of freedom to the standard normal distribution (Z)
</p>
</div>
<p>Now that you have a sense for how the <em>t</em>-distribution compares to the standard normal, let’s look at how confidence intervals are quantified with the <em>t</em>-distribution.</p>
<p><span class="math display">\[
\hat{\mu}\pm t_{\alpha/2,df}*SE_\mu
\]</span></p>
<p>The formula is largely the same as before, except we’ve replaced the <em>Z</em> with a <em>t</em> distribution at a specified significance level <em>and</em> degrees of freedom (<span class="math inline">\(t_{\alpha,df}\)</span>), and we’ve replaced the true standard error with our estimate of the standard error (<span class="math inline">\(SE_\mu\)</span>).</p>
<p>Let’s work through an example. Suppose you’re thinking about ice cream again, and you’re interested in estimating the average weight of a single scoop of ice cream from your local ice cream parlor. You decide to go to the parlor on 10 randomly selected days and times, and you order a single scoop and weight it. The code chunk below creates a vector of the weights for 10 ice cream cones assuming a true normal distribution of weight with mean 113 g and standard deviation 15 g. A 95% confidence interval is then computed for the estimated weight:</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="estimation-with-frequentist-inference.html#cb420-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb420-2"><a href="estimation-with-frequentist-inference.html#cb420-2" tabindex="-1"></a></span>
<span id="cb420-3"><a href="estimation-with-frequentist-inference.html#cb420-3" tabindex="-1"></a><span class="co">#sample size</span></span>
<span id="cb420-4"><a href="estimation-with-frequentist-inference.html#cb420-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb420-5"><a href="estimation-with-frequentist-inference.html#cb420-5" tabindex="-1"></a></span>
<span id="cb420-6"><a href="estimation-with-frequentist-inference.html#cb420-6" tabindex="-1"></a><span class="co">#ice cream weights (g) in sample of N = 10</span></span>
<span id="cb420-7"><a href="estimation-with-frequentist-inference.html#cb420-7" tabindex="-1"></a>ic <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> <span class="dv">113</span>, <span class="at">sd =</span> <span class="dv">15</span>)</span>
<span id="cb420-8"><a href="estimation-with-frequentist-inference.html#cb420-8" tabindex="-1"></a></span>
<span id="cb420-9"><a href="estimation-with-frequentist-inference.html#cb420-9" tabindex="-1"></a><span class="co">#estimated mean</span></span>
<span id="cb420-10"><a href="estimation-with-frequentist-inference.html#cb420-10" tabindex="-1"></a>ic.mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(ic)</span>
<span id="cb420-11"><a href="estimation-with-frequentist-inference.html#cb420-11" tabindex="-1"></a>ic.mean</span></code></pre></div>
<pre><code>## [1] 114.1194</code></pre>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="estimation-with-frequentist-inference.html#cb422-1" tabindex="-1"></a><span class="co">#estimated standard deviation</span></span>
<span id="cb422-2"><a href="estimation-with-frequentist-inference.html#cb422-2" tabindex="-1"></a>ic.sd <span class="ot">&lt;-</span> <span class="fu">sd</span>(ic)</span>
<span id="cb422-3"><a href="estimation-with-frequentist-inference.html#cb422-3" tabindex="-1"></a></span>
<span id="cb422-4"><a href="estimation-with-frequentist-inference.html#cb422-4" tabindex="-1"></a><span class="co">#estimated standard error</span></span>
<span id="cb422-5"><a href="estimation-with-frequentist-inference.html#cb422-5" tabindex="-1"></a>ic.se <span class="ot">&lt;-</span> ic.sd<span class="sc">/</span><span class="fu">sqrt</span>(n)</span>
<span id="cb422-6"><a href="estimation-with-frequentist-inference.html#cb422-6" tabindex="-1"></a>ic.se</span></code></pre></div>
<pre><code>## [1] 4.524195</code></pre>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="estimation-with-frequentist-inference.html#cb424-1" tabindex="-1"></a><span class="co">#95% confidence level</span></span>
<span id="cb424-2"><a href="estimation-with-frequentist-inference.html#cb424-2" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb424-3"><a href="estimation-with-frequentist-inference.html#cb424-3" tabindex="-1"></a></span>
<span id="cb424-4"><a href="estimation-with-frequentist-inference.html#cb424-4" tabindex="-1"></a><span class="co">#t for 95% confidence level and df = n-1</span></span>
<span id="cb424-5"><a href="estimation-with-frequentist-inference.html#cb424-5" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">qt</span>(alpha<span class="sc">/</span><span class="dv">2</span>, <span class="at">df =</span> n<span class="dv">-1</span>, <span class="at">lower.tail=</span><span class="cn">TRUE</span>)) <span class="co">#abs for positive t</span></span>
<span id="cb424-6"><a href="estimation-with-frequentist-inference.html#cb424-6" tabindex="-1"></a>t</span></code></pre></div>
<pre><code>## [1] 2.262157</code></pre>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="estimation-with-frequentist-inference.html#cb426-1" tabindex="-1"></a><span class="co">#lower confidence limit: point estimate - t*SE</span></span>
<span id="cb426-2"><a href="estimation-with-frequentist-inference.html#cb426-2" tabindex="-1"></a>ic.mean <span class="sc">-</span> t<span class="sc">*</span>ic.se</span></code></pre></div>
<pre><code>## [1] 103.8849</code></pre>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="estimation-with-frequentist-inference.html#cb428-1" tabindex="-1"></a><span class="co">#upper confidence limit: point estimate + t*SE</span></span>
<span id="cb428-2"><a href="estimation-with-frequentist-inference.html#cb428-2" tabindex="-1"></a>ic.mean <span class="sc">+</span> t<span class="sc">*</span>ic.se</span></code></pre></div>
<pre><code>## [1] 124.3538</code></pre>
<p>We can see that the estimated (<code>p.hat</code>) mean weight is 113.02 g, the estimated standard error (<code>se</code>) is 3.66, the appropriate <em>t</em> value based on the degrees of freedom is 2.26, and the resulting confidence interval is 104.7 - 121.3 g. You should notice that the <em>t</em> value in this case, 2.26, is greater than the <em>Z</em> of 1.96 for a 95% level of confidence. This reflects added uncertainty for estimating the standard deviation, and therefore the standard error, and ultimately results in a slightly wider confidence interval than compared to the interval based on a known standard error.</p>
</div>
<div id="interpreting-confidence-intervals" class="section level4 hasAnchor" number="15.3.2.3">
<h4><span class="header-section-number">15.3.2.3</span> Interpreting confidence intervals<a href="estimation-with-frequentist-inference.html#interpreting-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>OK, back to prevalence of the infection. Based on our sample of N = 100 individuals, we estimated the prevalence was 8% with a 95% confidence interval of 2.7 - 13.3%. In other words, we can be 95% confident that true proportion infected is between 2.7% and 13.3%. I am purposely NOT saying that there’s a 95% <em>probability</em> that the true proportion infected is between 2.7% and 13.3%.</p>
<p>Why can’t we interpret our confidence interval in terms of probability? Well, this turns out to be one of the quirks of frequentist estimation. The frequentist definition of probability is about long-run frequencies! In order to determine confidence intervals probabilistically, you have to imagine have hundreds of thousands of confidence intervals from hundreds of thousands of random samples. If we have many 95% confidence intervals from many random samples, then we expect 95% of the confidence intervals to include the true population parameter. But any individual confidence interval? A frequentist would say that the true parmaeter is either in that single confidence interval, or it is not, so there is no probability to speak of for a single iteration.</p>
<p>We can simulate this situation to see exactly what I mean. We’ll use the <code>rbinom</code> function to simulate 1000 random samples of N = 100 individuals when the probability of infection is 11%, then quantify a 95% confidence interval for each random sample, and finally quantify the proportion of confidence intervals that include 11%.</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="estimation-with-frequentist-inference.html#cb430-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">124</span>)</span>
<span id="cb430-2"><a href="estimation-with-frequentist-inference.html#cb430-2" tabindex="-1"></a></span>
<span id="cb430-3"><a href="estimation-with-frequentist-inference.html#cb430-3" tabindex="-1"></a><span class="co">#10000 random samples of N = 100</span></span>
<span id="cb430-4"><a href="estimation-with-frequentist-inference.html#cb430-4" tabindex="-1"></a>sims <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb430-5"><a href="estimation-with-frequentist-inference.html#cb430-5" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.05</span></span>
<span id="cb430-6"><a href="estimation-with-frequentist-inference.html#cb430-6" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb430-7"><a href="estimation-with-frequentist-inference.html#cb430-7" tabindex="-1"></a>x.sims <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> sims, <span class="at">size =</span> n, <span class="at">prob =</span> <span class="fl">0.11</span>)</span>
<span id="cb430-8"><a href="estimation-with-frequentist-inference.html#cb430-8" tabindex="-1"></a></span>
<span id="cb430-9"><a href="estimation-with-frequentist-inference.html#cb430-9" tabindex="-1"></a>lcl <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, sims)</span>
<span id="cb430-10"><a href="estimation-with-frequentist-inference.html#cb430-10" tabindex="-1"></a>ucl <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, sims)</span>
<span id="cb430-11"><a href="estimation-with-frequentist-inference.html#cb430-11" tabindex="-1"></a></span>
<span id="cb430-12"><a href="estimation-with-frequentist-inference.html#cb430-12" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>sims){</span>
<span id="cb430-13"><a href="estimation-with-frequentist-inference.html#cb430-13" tabindex="-1"></a>  x <span class="ot">&lt;-</span> x.sims[i]</span>
<span id="cb430-14"><a href="estimation-with-frequentist-inference.html#cb430-14" tabindex="-1"></a>  p.hat <span class="ot">&lt;-</span> x<span class="sc">/</span>n</span>
<span id="cb430-15"><a href="estimation-with-frequentist-inference.html#cb430-15" tabindex="-1"></a>  se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(p.hat<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p.hat))<span class="sc">/</span><span class="fu">sqrt</span>(n)</span>
<span id="cb430-16"><a href="estimation-with-frequentist-inference.html#cb430-16" tabindex="-1"></a>  z <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">qnorm</span>(alpha<span class="sc">/</span><span class="dv">2</span>, <span class="at">lower.tail=</span><span class="cn">TRUE</span>))</span>
<span id="cb430-17"><a href="estimation-with-frequentist-inference.html#cb430-17" tabindex="-1"></a>  lcl[i] <span class="ot">&lt;-</span> p.hat <span class="sc">-</span> z<span class="sc">*</span>se</span>
<span id="cb430-18"><a href="estimation-with-frequentist-inference.html#cb430-18" tabindex="-1"></a>  ucl[i] <span class="ot">&lt;-</span> p.hat <span class="sc">+</span> z<span class="sc">*</span>se</span>
<span id="cb430-19"><a href="estimation-with-frequentist-inference.html#cb430-19" tabindex="-1"></a>}</span>
<span id="cb430-20"><a href="estimation-with-frequentist-inference.html#cb430-20" tabindex="-1"></a></span>
<span id="cb430-21"><a href="estimation-with-frequentist-inference.html#cb430-21" tabindex="-1"></a>contains.truth <span class="ot">&lt;-</span> lcl<span class="sc">&lt;=</span><span class="fl">0.11</span> <span class="sc">&amp;</span> ucl<span class="sc">&gt;=</span><span class="fl">0.11</span></span>
<span id="cb430-22"><a href="estimation-with-frequentist-inference.html#cb430-22" tabindex="-1"></a><span class="fu">mean</span>(contains.truth)</span></code></pre></div>
<pre><code>## [1] 0.939</code></pre>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="estimation-with-frequentist-inference.html#cb432-1" tabindex="-1"></a><span class="co">#plot 20-randomly selected confidence intervals</span></span>
<span id="cb432-2"><a href="estimation-with-frequentist-inference.html#cb432-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">26</span>) <span class="co"># Ensure reproducibility for sampling</span></span>
<span id="cb432-3"><a href="estimation-with-frequentist-inference.html#cb432-3" tabindex="-1"></a>indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>sims, <span class="dv">20</span>)</span>
<span id="cb432-4"><a href="estimation-with-frequentist-inference.html#cb432-4" tabindex="-1"></a>ci.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb432-5"><a href="estimation-with-frequentist-inference.html#cb432-5" tabindex="-1"></a>  <span class="at">Interval =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>,  <span class="co"># Vertical positions</span></span>
<span id="cb432-6"><a href="estimation-with-frequentist-inference.html#cb432-6" tabindex="-1"></a>  <span class="at">LCL =</span> lcl[indices],</span>
<span id="cb432-7"><a href="estimation-with-frequentist-inference.html#cb432-7" tabindex="-1"></a>  <span class="at">UCL =</span> ucl[indices],</span>
<span id="cb432-8"><a href="estimation-with-frequentist-inference.html#cb432-8" tabindex="-1"></a>  <span class="at">ContainsTruth =</span> contains.truth[indices]</span>
<span id="cb432-9"><a href="estimation-with-frequentist-inference.html#cb432-9" tabindex="-1"></a>)</span>
<span id="cb432-10"><a href="estimation-with-frequentist-inference.html#cb432-10" tabindex="-1"></a></span>
<span id="cb432-11"><a href="estimation-with-frequentist-inference.html#cb432-11" tabindex="-1"></a><span class="fu">ggplot</span>(ci.data, <span class="fu">aes</span>(<span class="at">y =</span> Interval, <span class="at">xmin =</span> LCL, <span class="at">xmax =</span> UCL, <span class="at">color =</span> ContainsTruth)) <span class="sc">+</span></span>
<span id="cb432-12"><a href="estimation-with-frequentist-inference.html#cb432-12" tabindex="-1"></a>  <span class="fu">geom_errorbarh</span>(<span class="at">height =</span> <span class="fl">0.3</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span>  <span class="co"># Plot horizontal confidence intervals</span></span>
<span id="cb432-13"><a href="estimation-with-frequentist-inference.html#cb432-13" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.11</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span>  <span class="co"># Add reference line</span></span>
<span id="cb432-14"><a href="estimation-with-frequentist-inference.html#cb432-14" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;TRUE&quot;</span> <span class="ot">=</span> <span class="st">&quot;black&quot;</span>, <span class="st">&quot;FALSE&quot;</span> <span class="ot">=</span> <span class="st">&quot;#E6AB02&quot;</span>)) <span class="sc">+</span>  <span class="co"># Highlight intervals</span></span>
<span id="cb432-15"><a href="estimation-with-frequentist-inference.html#cb432-15" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb432-16"><a href="estimation-with-frequentist-inference.html#cb432-16" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb432-17"><a href="estimation-with-frequentist-inference.html#cb432-17" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Proportion Infected&quot;</span>,</span>
<span id="cb432-18"><a href="estimation-with-frequentist-inference.html#cb432-18" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Randomly selected 95% CIs&quot;</span>,</span>
<span id="cb432-19"><a href="estimation-with-frequentist-inference.html#cb432-19" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;Contains true proportion (11%)&quot;</span></span>
<span id="cb432-20"><a href="estimation-with-frequentist-inference.html#cb432-20" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb432-21"><a href="estimation-with-frequentist-inference.html#cb432-21" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb432-22"><a href="estimation-with-frequentist-inference.html#cb432-22" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">&quot;top&quot;</span>,</span>
<span id="cb432-23"><a href="estimation-with-frequentist-inference.html#cb432-23" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),  <span class="co"># Remove y-axis labels for clarity</span></span>
<span id="cb432-24"><a href="estimation-with-frequentist-inference.html#cb432-24" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb432-25"><a href="estimation-with-frequentist-inference.html#cb432-25" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="appendix01_estimation_freq_files/figure-html/a01_chunk19-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:a01_chunk19)TODO: caption.
</p>
</div>
<p>Figure @ref(fig:a01_chunk19) shows 20 randomly selected 95% confidence intervals for the proportion infected, highlighting confidence intervals that either do or do not include the true value of 11% infected. Note that of the 20 randomly-selected confidence intervals, 19 of 20 contain the truth, which is what we expect for a 95% confidence interval. If we look at the entire sample of 1000 random samples, 93.9% of them contained the true parameter of 11%. Why wasn’t it exactly 95%? Well, there’s sampling error even in our simulation process because we’re not generating an infinite number of samples <a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p>So the only time you should interpret frequentist confidence intervals probabilistically is when you have many confidence intervals. Which, of course, is almost never. We usually have a single point estimate and confidence interval based on a single sample. When that’s the case, all we can do is say we are 95% confident (or whatever level of confidence is quantified) that the true parameter value is in the interval. This is a source of great frustration and misunderstanding, so if that’s how you feel, you are in good company! You might even be asking yourself, what does it even mean to say we are”95% confident” about the true parameter being in a single interval? Good question. To me, it sort of sounds like a strength of belief, almost like a Bayesian interpretation of probability. Stay tuned.</p>
</div>
</div>
<div id="the-standard-normal-approximation-does-not-work-well-under-low-sample-size" class="section level3 hasAnchor" number="15.3.3">
<h3><span class="header-section-number">15.3.3</span> The standard normal approximation does not work well under low sample size<a href="estimation-with-frequentist-inference.html#the-standard-normal-approximation-does-not-work-well-under-low-sample-size" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The methods we’ve used in this section to quantify confidence intervals assume that the sampling distribution for an estimate follows an (approximately) normal distribution. This works well for continuous variables with underlying normal distributions, and it can even work well for random variables that don’t have an underlying normal distribution. Indeed, we quantified a confidence interval for a categorical variable (proportion infected) assuming an approximately normal sampling distribution. As we now know from the central limit theorem this works well under reasonably large sample sizes.</p>
<p>So what is a large sample size? Well, there are some general rules of thumb. When estimating proportions for categorical variables, the central limit theorem application generally works when <span class="math inline">\(np \geq 10\)</span> and <span class="math inline">\(n(1-p) \geq 10\)</span>. For example, in our example random sample where N = 100 and <em>p</em> = 0.11, these conditions are (barely) satisfied: <span class="math inline">\(np = 100*0.11 = 11\)</span> and <span class="math inline">\(n(1-p) = 100*(1-0.11) = 89\)</span>. Of course, when you’re estimating the proportion, you don’t actually know the true proportion! In that case, you can use the estimated proportion to check if the rule of thumb holds.</p>
<p>For our sample where we observed 8 out of 100 infected individuals, the rule would not hold: <span class="math inline">\(100*0.08 = 8\)</span>. What then? There are many alternative methods that have been applied for estimating confidence intervals for proportions under low sample size (or extreme values of the proportion near 0 or 1). For example, one approach to quantifying a 95% confidence interval for a proportion when <span class="math inline">\(np &lt; 10\)</span> or <span class="math inline">\(n(1-p) &lt; 10\)</span> is the Agresti-Coull Method. This method makes adjustments to the sample size (<span class="math inline">\(n&#39;=n+4\)</span>) and number of successes (<span class="math inline">\(x&#39;=x+2\)</span>) to compute an adjusted proportion (<span class="math inline">\(p&#39;=\frac{x&#39;}{n&#39;}\)</span>), which can then be used to quantify an adjusted standard error and confidence interval by replacing <span class="math inline">\(p\)</span> and <span class="math inline">\(n\)</span> with <span class="math inline">\(p&#39;\)</span> and <span class="math inline">\(n&#39;\)</span> in the formulas above. The <code>binom</code> package also has a function, <code>binom.confint</code> that can quantify an Agresti-Coull confidence interval directly by setting the <code>methods</code> argument to <code>ac</code>:</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="estimation-with-frequentist-inference.html#cb433-1" tabindex="-1"></a><span class="co">#agresti coull confidence interval</span></span>
<span id="cb433-2"><a href="estimation-with-frequentist-inference.html#cb433-2" tabindex="-1"></a><span class="fu">binom.confint</span>(<span class="at">x =</span> <span class="dv">8</span><span class="sc">+</span><span class="dv">2</span>, <span class="at">n =</span> <span class="dv">100</span><span class="sc">+</span><span class="dv">4</span>, <span class="at">conf.level=</span><span class="fl">0.95</span>, <span class="at">methods=</span><span class="st">&quot;ac&quot;</span>)</span></code></pre></div>
<pre><code>##          method  x   n       mean     lower     upper
## 1 agresti-coull 10 104 0.09615385 0.0513591 0.1697197</code></pre>
<p>You can see in this case that the confidence interval is a adjusted a bit higher compared to the interval we quantified.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>It’s a little awkward that the standard error estimate here is <em>lower</em> than the true value. This is actually a known bias under low sample size. Variances tend to be underestimated at low sample size, leading to lower estimates of the standard error at low sample sizes. There are different types of bias-correction factors that can be employed to adjust for this issue, but here we stick with the basic calculation of a standard deviation for a proportion for simplicity.<a href="estimation-with-frequentist-inference.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>It turns out there’s also a little bias due to the tendency to underestimate the standard deviation at low sample size.<a href="estimation-with-frequentist-inference.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multilevel-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="decision-making-with-frequentist-estimates.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true,
    "toc_depth": 2
  },
  "toolbar": {
    "position": "fixed"
  },
  "info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
