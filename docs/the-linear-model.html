<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 The linear model | Research Design and Statistics</title>
  <meta name="description" content="An introduction to research design and statistics" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 The linear model | Research Design and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="An introduction to research design and statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 The linear model | Research Design and Statistics" />
  
  <meta name="twitter:description" content="An introduction to research design and statistics" />
  

<meta name="author" content="Bradley J. Cosentino" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bayesian-workflow.html"/>
<link rel="next" href="graphical-causal-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#work-in-progress"><i class="fa fa-check"></i>Work in progress</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#copyright"><i class="fa fa-check"></i>Copyright</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the Author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html"><i class="fa fa-check"></i><b>1</b> Why Statistics? The Problem of Uncertainty</a>
<ul>
<li class="chapter" data-level="1.1" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#the-nature-of-science"><i class="fa fa-check"></i><b>1.1</b> The nature of science</a></li>
<li class="chapter" data-level="1.2" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#goals-of-scientific-research"><i class="fa fa-check"></i><b>1.2</b> Goals of scientific research</a></li>
<li class="chapter" data-level="1.3" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#three-general-goals-of-scientific-research"><i class="fa fa-check"></i><b>1.3</b> Three general goals of scientific research</a></li>
<li class="chapter" data-level="1.4" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#research-design-and-statistical-analysis-depend-on-your-goal"><i class="fa fa-check"></i><b>1.4</b> Research design and statistical analysis depend on your goal</a></li>
<li class="chapter" data-level="1.5" data-path="why-statistics-the-problem-of-uncertainty.html"><a href="why-statistics-the-problem-of-uncertainty.html#you-cant-escape-uncertainty-in-science"><i class="fa fa-check"></i><b>1.5</b> You can’t escape uncertainty in science</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html"><i class="fa fa-check"></i><b>2</b> Scientific workflow: Connecting ideas to data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#research-questions"><i class="fa fa-check"></i><b>2.1</b> Research questions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#clarify-your-primary-goal-description-prediction-or-explanation"><i class="fa fa-check"></i><b>2.1.1</b> Clarify your primary goal: description, prediction, or explanation?</a></li>
<li class="chapter" data-level="2.1.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#identify-the-scope-of-inference-the-who-what-when-and-where-of-your-study."><i class="fa fa-check"></i><b>2.1.2</b> Identify the scope of inference: The who, what, when, and where of your study.</a></li>
<li class="chapter" data-level="2.1.3" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-it-interesting"><i class="fa fa-check"></i><b>2.1.3</b> Make it interesting</a></li>
<li class="chapter" data-level="2.1.4" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-it-answerable-with-data"><i class="fa fa-check"></i><b>2.1.4</b> Make it answerable with data</a></li>
<li class="chapter" data-level="2.1.5" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#ground-it-in-theory"><i class="fa fa-check"></i><b>2.1.5</b> Ground it in theory</a></li>
<li class="chapter" data-level="2.1.6" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#make-sure-its-feasible"><i class="fa fa-check"></i><b>2.1.6</b> Make sure it’s feasible</a></li>
<li class="chapter" data-level="2.1.7" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#avoid-analyzing-the-data-before-stating-your-question"><i class="fa fa-check"></i><b>2.1.7</b> Avoid analyzing the data before stating your question</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#connecting-ideas-to-data"><i class="fa fa-check"></i><b>2.2</b> Connecting ideas to data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#theory"><i class="fa fa-check"></i><b>2.2.1</b> Theory</a></li>
<li class="chapter" data-level="2.2.2" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#research-question"><i class="fa fa-check"></i><b>2.2.2</b> Research question</a></li>
<li class="chapter" data-level="2.2.3" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#generative-model"><i class="fa fa-check"></i><b>2.2.3</b> Generative model</a></li>
<li class="chapter" data-level="2.2.4" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#study-design"><i class="fa fa-check"></i><b>2.2.4</b> Study design</a></li>
<li class="chapter" data-level="2.2.5" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#estimand"><i class="fa fa-check"></i><b>2.2.5</b> Estimand</a></li>
<li class="chapter" data-level="2.2.6" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#target-population"><i class="fa fa-check"></i><b>2.2.6</b> Target population</a></li>
<li class="chapter" data-level="2.2.7" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#sample-data"><i class="fa fa-check"></i><b>2.2.7</b> Sample data</a></li>
<li class="chapter" data-level="2.2.8" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#statistical-model"><i class="fa fa-check"></i><b>2.2.8</b> Statistical model</a></li>
<li class="chapter" data-level="2.2.9" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#estimate"><i class="fa fa-check"></i><b>2.2.9</b> Estimate</a></li>
<li class="chapter" data-level="2.2.10" data-path="scientific-workflow-connecting-ideas-to-data.html"><a href="scientific-workflow-connecting-ideas-to-data.html#summary"><i class="fa fa-check"></i><b>2.2.10</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html"><i class="fa fa-check"></i><b>3</b> Introduction to Data and R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#an-introduction-to-data"><i class="fa fa-check"></i><b>3.1</b> An introduction to data</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#variables-and-observations"><i class="fa fa-check"></i><b>3.1.1</b> Variables and observations</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#types-of-variables"><i class="fa fa-check"></i><b>3.1.2</b> Types of variables</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#relationships-between-variables"><i class="fa fa-check"></i><b>3.1.3</b> Relationships between variables</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#variable-naming-conventions-and-metadata"><i class="fa fa-check"></i><b>3.1.4</b> Variable naming conventions and metadata</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#introduction-to-r"><i class="fa fa-check"></i><b>3.2</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>3.2.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#the-rstudio-interface"><i class="fa fa-check"></i><b>3.2.2</b> The RStudio Interface</a></li>
<li class="chapter" data-level="3.2.3" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#basic-data-manipulation-in-r"><i class="fa fa-check"></i><b>3.2.3</b> Basic data manipulation in R</a></li>
<li class="chapter" data-level="3.2.4" data-path="introduction-to-data-and-r.html"><a href="introduction-to-data-and-r.html#scripting"><i class="fa fa-check"></i><b>3.2.4</b> Scripting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="describing-data.html"><a href="describing-data.html"><i class="fa fa-check"></i><b>4</b> Describing data</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="describing-data.html"><a href="describing-data.html#defining-the-population"><i class="fa fa-check"></i><b>4.0.1</b> Defining the population</a></li>
<li class="chapter" data-level="4.0.2" data-path="describing-data.html"><a href="describing-data.html#loading-data-into-r"><i class="fa fa-check"></i><b>4.0.2</b> Loading data into R</a></li>
<li class="chapter" data-level="4.0.3" data-path="describing-data.html"><a href="describing-data.html#inspecting-the-dataset"><i class="fa fa-check"></i><b>4.0.3</b> Inspecting the dataset</a></li>
<li class="chapter" data-level="4.0.4" data-path="describing-data.html"><a href="describing-data.html#describing-single-qualitative-variables"><i class="fa fa-check"></i><b>4.0.4</b> Describing single qualitative variables</a></li>
<li class="chapter" data-level="4.0.5" data-path="describing-data.html"><a href="describing-data.html#describing-single-quantitative-variables"><i class="fa fa-check"></i><b>4.0.5</b> Describing single quantitative variables</a></li>
<li class="chapter" data-level="4.0.6" data-path="describing-data.html"><a href="describing-data.html#describing-relationships-between-variables"><i class="fa fa-check"></i><b>4.0.6</b> Describing relationships between variables</a></li>
<li class="chapter" data-level="4.0.7" data-path="describing-data.html"><a href="describing-data.html#associations-between-quantitative-variables"><i class="fa fa-check"></i><b>4.0.7</b> Associations between quantitative variables</a></li>
<li class="chapter" data-level="4.0.8" data-path="describing-data.html"><a href="describing-data.html#associations-between-quantitative-and-qualitative-variables"><i class="fa fa-check"></i><b>4.0.8</b> Associations between quantitative and qualitative variables</a></li>
<li class="chapter" data-level="4.0.9" data-path="describing-data.html"><a href="describing-data.html#associations-between-qualitative-variables"><i class="fa fa-check"></i><b>4.0.9</b> Associations between qualitative variables</a></li>
<li class="chapter" data-level="4.0.10" data-path="describing-data.html"><a href="describing-data.html#this-is-just-the-beginning"><i class="fa fa-check"></i><b>4.0.10</b> This is just the beginning</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html"><i class="fa fa-check"></i><b>5</b> Uncertainty from sampling</a>
<ul>
<li class="chapter" data-level="5.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#sampling-requires-estimation"><i class="fa fa-check"></i><b>5.1</b> Sampling requires estimation</a></li>
<li class="chapter" data-level="5.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#parameters-estimates-estimands"><i class="fa fa-check"></i><b>5.2</b> Parameters, estimates, estimands</a></li>
<li class="chapter" data-level="5.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#sources-of-uncertainty-from-sampling"><i class="fa fa-check"></i><b>5.3</b> Sources of uncertainty from sampling</a></li>
<li class="chapter" data-level="5.4" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#accuracy-and-precision"><i class="fa fa-check"></i><b>5.4</b> Accuracy and precision</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#accuracy"><i class="fa fa-check"></i><b>5.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.4.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#precision"><i class="fa fa-check"></i><b>5.4.2</b> Precision</a></li>
<li class="chapter" data-level="5.4.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#considering-accuracy-and-precision-together"><i class="fa fa-check"></i><b>5.4.3</b> Considering accuracy and precision together</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#maximizing-accuracy-and-precision-of-estimates"><i class="fa fa-check"></i><b>5.5</b> Maximizing accuracy and precision of estimates</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#random-sampling"><i class="fa fa-check"></i><b>5.5.1</b> Random sampling</a></li>
<li class="chapter" data-level="5.5.2" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#replication"><i class="fa fa-check"></i><b>5.5.2</b> Replication</a></li>
<li class="chapter" data-level="5.5.3" data-path="uncertainty-from-sampling.html"><a href="uncertainty-from-sampling.html#take-home-points"><i class="fa fa-check"></i><b>5.5.3</b> Take-home points</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html"><i class="fa fa-check"></i><b>6</b> Probability as the Language of Uncertainty</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#defining-probability"><i class="fa fa-check"></i><b>6.1</b> Defining probability</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#frequentist-definition"><i class="fa fa-check"></i><b>6.1.1</b> Frequentist definition</a></li>
<li class="chapter" data-level="6.1.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#bayesian-definition"><i class="fa fa-check"></i><b>6.1.2</b> Bayesian definition</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#probability-rules"><i class="fa fa-check"></i><b>6.2</b> Probability rules</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#individual-events"><i class="fa fa-check"></i><b>6.2.1</b> Individual events</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#joint-events"><i class="fa fa-check"></i><b>6.2.2</b> Joint events</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#general-addition-rule"><i class="fa fa-check"></i><b>6.2.3</b> General addition rule</a></li>
<li class="chapter" data-level="6.2.4" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#quantifying-marginal-probabilities"><i class="fa fa-check"></i><b>6.2.4</b> Quantifying marginal probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-probability-distributions"><i class="fa fa-check"></i><b>6.3</b> Sampling from probability distributions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-populations-is-probabalistic"><i class="fa fa-check"></i><b>6.3.1</b> Sampling from populations is probabalistic</a></li>
<li class="chapter" data-level="6.3.2" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#discrete-random-variables"><i class="fa fa-check"></i><b>6.3.2</b> Discrete random variables</a></li>
<li class="chapter" data-level="6.3.3" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.3.3</b> Continuous random variables</a></li>
<li class="chapter" data-level="6.3.4" data-path="probability-as-the-language-of-uncertainty.html"><a href="probability-as-the-language-of-uncertainty.html#sampling-from-probability-distributions-1"><i class="fa fa-check"></i><b>6.3.4</b> Sampling from probability distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>7</b> Estimation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimation.html"><a href="estimation.html#scientific-workflow-for-the-problem"><i class="fa fa-check"></i><b>7.1</b> Scientific workflow for the problem</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimation.html"><a href="estimation.html#theory-and-the-research-question"><i class="fa fa-check"></i><b>7.1.1</b> Theory and the research question</a></li>
<li class="chapter" data-level="7.1.2" data-path="estimation.html"><a href="estimation.html#generative-model-and-estimand"><i class="fa fa-check"></i><b>7.1.2</b> Generative model and estimand</a></li>
<li class="chapter" data-level="7.1.3" data-path="estimation.html"><a href="estimation.html#statistical-model-and-estimate"><i class="fa fa-check"></i><b>7.1.3</b> Statistical model and estimate</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimation.html"><a href="estimation.html#bayes-theorem"><i class="fa fa-check"></i><b>7.2</b> Bayes Theorem</a></li>
<li class="chapter" data-level="7.3" data-path="estimation.html"><a href="estimation.html#applying-bayes-theorem-to-statistical-analysis"><i class="fa fa-check"></i><b>7.3</b> Applying Bayes Theorem to statistical analysis</a></li>
<li class="chapter" data-level="7.4" data-path="estimation.html"><a href="estimation.html#steps-of-estimation-with-bayesian-inference"><i class="fa fa-check"></i><b>7.4</b> Steps of estimation with Bayesian inference</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="estimation.html"><a href="estimation.html#specify-the-prior-distribution"><i class="fa fa-check"></i><b>7.4.1</b> Specify the prior distribution</a></li>
<li class="chapter" data-level="7.4.2" data-path="estimation.html"><a href="estimation.html#quantify-the-likelihood-of-the-data"><i class="fa fa-check"></i><b>7.4.2</b> Quantify the likelihood of the data</a></li>
<li class="chapter" data-level="7.4.3" data-path="estimation.html"><a href="estimation.html#quantify-the-total-probability-of-the-data-marginal-likelihood"><i class="fa fa-check"></i><b>7.4.3</b> Quantify the total probability of the data (marginal likelihood)</a></li>
<li class="chapter" data-level="7.4.4" data-path="estimation.html"><a href="estimation.html#quantify-the-posterior-distribution"><i class="fa fa-check"></i><b>7.4.4</b> Quantify the posterior distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="estimation.html"><a href="estimation.html#summarizing-the-posterior-distribution"><i class="fa fa-check"></i><b>7.5</b> Summarizing the posterior distribution</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="estimation.html"><a href="estimation.html#sampling-from-the-posterior-distribution"><i class="fa fa-check"></i><b>7.5.1</b> Sampling from the posterior distribution</a></li>
<li class="chapter" data-level="7.5.2" data-path="estimation.html"><a href="estimation.html#central-tendency-and-variance"><i class="fa fa-check"></i><b>7.5.2</b> Central tendency and variance</a></li>
<li class="chapter" data-level="7.5.3" data-path="estimation.html"><a href="estimation.html#intervals"><i class="fa fa-check"></i><b>7.5.3</b> Intervals</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="estimation.html"><a href="estimation.html#specifying-priors"><i class="fa fa-check"></i><b>7.6</b> Specifying priors</a></li>
<li class="chapter" data-level="7.7" data-path="estimation.html"><a href="estimation.html#decision-making"><i class="fa fa-check"></i><b>7.7</b> Decision making</a></li>
<li class="chapter" data-level="7.8" data-path="estimation.html"><a href="estimation.html#specifying-and-fitting-statistical-models-with-bayes"><i class="fa fa-check"></i><b>7.8</b> Specifying and fitting statistical models with Bayes</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="estimation.html"><a href="estimation.html#statistical-model-specification"><i class="fa fa-check"></i><b>7.8.1</b> Statistical model specification</a></li>
<li class="chapter" data-level="7.8.2" data-path="estimation.html"><a href="estimation.html#fitting-models-with-brms"><i class="fa fa-check"></i><b>7.8.2</b> Fitting models with <em>brms</em></a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="estimation.html"><a href="estimation.html#estimation-for-a-continuous-random-variable"><i class="fa fa-check"></i><b>7.9</b> Estimation for a continuous random variable</a></li>
<li class="chapter" data-level="7.10" data-path="estimation.html"><a href="estimation.html#next-steps"><i class="fa fa-check"></i><b>7.10</b> Next steps</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html"><i class="fa fa-check"></i><b>8</b> Bayesian Workflow</a>
<ul>
<li class="chapter" data-level="8.1" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#prior-distribution-choices"><i class="fa fa-check"></i><b>8.1</b> Prior distribution choices</a></li>
<li class="chapter" data-level="8.2" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#prior-predictive-checks"><i class="fa fa-check"></i><b>8.2</b> Prior predictive checks</a></li>
<li class="chapter" data-level="8.3" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>8.3</b> Posterior predictive checks</a></li>
<li class="chapter" data-level="8.4" data-path="bayesian-workflow.html"><a href="bayesian-workflow.html#next-steps-1"><i class="fa fa-check"></i><b>8.4</b> Next steps</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="the-linear-model.html"><a href="the-linear-model.html"><i class="fa fa-check"></i><b>9</b> The linear model</a>
<ul>
<li class="chapter" data-level="9.1" data-path="the-linear-model.html"><a href="the-linear-model.html#statistical-models"><i class="fa fa-check"></i><b>9.1</b> Statistical models</a></li>
<li class="chapter" data-level="9.2" data-path="the-linear-model.html"><a href="the-linear-model.html#linear-model"><i class="fa fa-check"></i><b>9.2</b> Linear model</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="the-linear-model.html"><a href="the-linear-model.html#basic-structure-of-the-linear-model"><i class="fa fa-check"></i><b>9.2.1</b> Basic structure of the linear model</a></li>
<li class="chapter" data-level="9.2.2" data-path="the-linear-model.html"><a href="the-linear-model.html#fitting-the-linear-model-in-brms"><i class="fa fa-check"></i><b>9.2.2</b> Fitting the linear model in brms</a></li>
<li class="chapter" data-level="9.2.3" data-path="the-linear-model.html"><a href="the-linear-model.html#how-a-frequentist-might-do-it"><i class="fa fa-check"></i><b>9.2.3</b> How a frequentist might do it</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="the-linear-model.html"><a href="the-linear-model.html#linear-models-with-categorical-predictors"><i class="fa fa-check"></i><b>9.3</b> Linear models with categorical predictors</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="the-linear-model.html"><a href="the-linear-model.html#binary-explanatory-variables"><i class="fa fa-check"></i><b>9.3.1</b> Binary explanatory variables</a></li>
<li class="chapter" data-level="9.3.2" data-path="the-linear-model.html"><a href="the-linear-model.html#categorical-predictors-with-more-than-two-categories"><i class="fa fa-check"></i><b>9.3.2</b> Categorical predictors with more than two categories</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html"><i class="fa fa-check"></i><b>10</b> Graphical Causal Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>10.1</b> Directed acyclic graphs (DAGs)</a></li>
<li class="chapter" data-level="10.2" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#three-causal-structures-in-dags"><i class="fa fa-check"></i><b>10.2</b> Three causal structures in DAGs</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-fork-confounders"><i class="fa fa-check"></i><b>10.2.1</b> The fork: confounders</a></li>
<li class="chapter" data-level="10.2.2" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-pipe-mediators"><i class="fa fa-check"></i><b>10.2.2</b> The pipe: mediators</a></li>
<li class="chapter" data-level="10.2.3" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#the-inverted-fork-colliders"><i class="fa fa-check"></i><b>10.2.3</b> The inverted fork: colliders</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#closing-backdoor-paths"><i class="fa fa-check"></i><b>10.3</b> Closing backdoor paths</a></li>
<li class="chapter" data-level="10.4" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#like-all-models-dags-require-assumptions"><i class="fa fa-check"></i><b>10.4</b> Like all models, DAGs require assumptions</a></li>
<li class="chapter" data-level="10.5" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#types-of-study-designs"><i class="fa fa-check"></i><b>10.5</b> Types of Study Designs</a></li>
<li class="chapter" data-level="10.6" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#experimental-studies"><i class="fa fa-check"></i><b>10.6</b> Experimental studies</a></li>
<li class="chapter" data-level="10.7" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#observational-studies"><i class="fa fa-check"></i><b>10.7</b> Observational studies</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="graphical-causal-models.html"><a href="graphical-causal-models.html#pros-and-cons-of-prospective-vs.-retrospective-studies-planned"><i class="fa fa-check"></i><b>10.7.1</b> Pros and cons of prospective vs. retrospective studies (planned)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html"><i class="fa fa-check"></i><b>11</b> Causal inference with linear models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#linear-models-with-multiple-predictor-variables"><i class="fa fa-check"></i><b>11.1</b> Linear models with multiple predictor variables</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#generic-linear-model-with-two-predictors"><i class="fa fa-check"></i><b>11.1.1</b> Generic linear model with two predictors</a></li>
<li class="chapter" data-level="11.1.2" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#multiple-regression-model-for-the-ice-cream-and-drownings-example"><i class="fa fa-check"></i><b>11.1.2</b> Multiple regression model for the ice cream and drownings example</a></li>
<li class="chapter" data-level="11.1.3" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#prior-predictive-check"><i class="fa fa-check"></i><b>11.1.3</b> Prior predictive check</a></li>
<li class="chapter" data-level="11.1.4" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#fitting-the-multiple-regression-model"><i class="fa fa-check"></i><b>11.1.4</b> Fitting the multiple regression model</a></li>
<li class="chapter" data-level="11.1.5" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#prediction-plots-for-multiple-regression-models"><i class="fa fa-check"></i><b>11.1.5</b> Prediction plots for multiple regression models</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="causal-inference-with-linear-models.html"><a href="causal-inference-with-linear-models.html#dag-informed-predictors-categorical-variables-what-multiple-regression-is-doing-with-predictor-residual-plot"><i class="fa fa-check"></i><b>11.2</b> DAG-informed predictors, categorical variables, what multiple regression is doing with predictor residual plot</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="interaction-effects.html"><a href="interaction-effects.html"><i class="fa fa-check"></i><b>12</b> Interaction effects</a></li>
<li class="chapter" data-level="13" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>13</b> Generalized linear models</a></li>
<li class="chapter" data-level="14" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>14</b> Multilevel models</a></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html"><i class="fa fa-check"></i><b>A</b> Estimation with frequentist inference</a>
<ul>
<li class="chapter" data-level="A.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#frequentist-estimates-are-point-estimates"><i class="fa fa-check"></i><b>A.1</b> Frequentist estimates are point estimates</a></li>
<li class="chapter" data-level="A.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions"><i class="fa fa-check"></i><b>A.2</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions-are-centered-on-the-true-parameter-value"><i class="fa fa-check"></i><b>A.2.1</b> Sampling distributions are centered on the true parameter value</a></li>
<li class="chapter" data-level="A.2.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sampling-distributions-allow-us-to-estimate-precision"><i class="fa fa-check"></i><b>A.2.2</b> Sampling distributions allow us to estimate precision</a></li>
<li class="chapter" data-level="A.2.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#sample-size-affects-the-shape-of-sampling-distributions"><i class="fa fa-check"></i><b>A.2.3</b> Sample size affects the shape of sampling distributions</a></li>
<li class="chapter" data-level="A.2.4" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#summary-points-on-sampling-distributions"><i class="fa fa-check"></i><b>A.2.4</b> Summary points on sampling distributions</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#quantifying-uncertainty-standard-error-and-confidence-intervals"><i class="fa fa-check"></i><b>A.3</b> Quantifying uncertainty: standard error and confidence intervals</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#standard-error"><i class="fa fa-check"></i><b>A.3.1</b> Standard error</a></li>
<li class="chapter" data-level="A.3.2" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#confidence-intervals"><i class="fa fa-check"></i><b>A.3.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="A.3.3" data-path="estimation-with-frequentist-inference.html"><a href="estimation-with-frequentist-inference.html#the-standard-normal-approximation-does-not-work-well-under-low-sample-size"><i class="fa fa-check"></i><b>A.3.3</b> The standard normal approximation does not work well under low sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html"><i class="fa fa-check"></i><b>B</b> Decision-making with frequentist estimates</a>
<ul>
<li class="chapter" data-level="B.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#framework-of-classical-hypothesis-testing"><i class="fa fa-check"></i><b>B.1</b> Framework of classical hypothesis testing</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#state-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>B.1.1</b> State null and alternative hypotheses</a></li>
<li class="chapter" data-level="B.1.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#assume-the-null-hypothesis-is-true"><i class="fa fa-check"></i><b>B.1.2</b> Assume the null hypothesis is true</a></li>
<li class="chapter" data-level="B.1.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#quantify-the-likelihood-of-the-data-under-the-null-hypothesis-p-values"><i class="fa fa-check"></i><b>B.1.3</b> Quantify the likelihood of the data under the null hypothesis: P-values</a></li>
<li class="chapter" data-level="B.1.4" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#making-a-decision-based-on-the-p-value-and-significance-value"><i class="fa fa-check"></i><b>B.1.4</b> Making a decision based on the P-value and significance value</a></li>
<li class="chapter" data-level="B.1.5" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#decision-errors-happen"><i class="fa fa-check"></i><b>B.1.5</b> Decision errors happen</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#making-decisions-with-confidence-intervals"><i class="fa fa-check"></i><b>B.2</b> Making decisions with confidence intervals</a></li>
<li class="chapter" data-level="B.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#issues-with-the-null-hypothesis-framework"><i class="fa fa-check"></i><b>B.3</b> Issues with the null hypothesis framework</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#significance-testing-reinforces-binary-thinking"><i class="fa fa-check"></i><b>B.3.1</b> Significance testing reinforces binary thinking</a></li>
<li class="chapter" data-level="B.3.2" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#statistical-testing-reinforces-gamification-in-science"><i class="fa fa-check"></i><b>B.3.2</b> Statistical testing reinforces gamification in science</a></li>
<li class="chapter" data-level="B.3.3" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#statistical-significance-is-not-the-same-thing-as-practical-significance"><i class="fa fa-check"></i><b>B.3.3</b> Statistical significance is not the same thing as practical significance</a></li>
<li class="chapter" data-level="B.3.4" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#type-i-errors-become-more-likely-with-multiple-tests"><i class="fa fa-check"></i><b>B.3.4</b> Type I errors become more likely with multiple tests</a></li>
<li class="chapter" data-level="B.3.5" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-is-almost-certainly-wrong"><i class="fa fa-check"></i><b>B.3.5</b> The null hypothesis is almost certainly wrong</a></li>
<li class="chapter" data-level="B.3.6" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-null-hypothesis-focuses-on-data-you-did-not-observe"><i class="fa fa-check"></i><b>B.3.6</b> The null hypothesis focuses on data you did not observe</a></li>
<li class="chapter" data-level="B.3.7" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#a-single-null-and-alternative-hypothesis-is-too-constraining"><i class="fa fa-check"></i><b>B.3.7</b> A single null and alternative hypothesis is too constraining</a></li>
<li class="chapter" data-level="B.3.8" data-path="decision-making-with-frequentist-estimates.html"><a href="decision-making-with-frequentist-estimates.html#the-p-value-is-not-the-probability-we-want"><i class="fa fa-check"></i><b>B.3.8</b> The P-value is not the probability we want</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Research Design and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-linear-model" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> The linear model<a href="the-linear-model.html#the-linear-model" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<ul>
<li>change this chapter to use the BAC example in HW9</li>
</ul>
<p>Over the last few chapters we have examined the process of estimating unknown quantities from samples with frequentist and Bayesian inference. Sample estimates vary in their quality, and we’ve emphasized the importance of quantifying metrics of uncertainty for our estimates, such as credible or confidence intervals. To this point the quantities we have estimated are very simple, such as a single proportion or mean characterizing a population. But what happens when life isn’t so simple? What if we’re not simply interested in the prevalence of an infection in a single city, but rather variation in the prevalence of the infection among cities? What if the variation in the prevalence among cities is affected by population density?</p>
<p>The same reasoning applies to population means for continuous variables. Suppose you are a real estate broker, and you’re interested in the average price at which a home sells. It would be inadequate to estimate a single mean price for all homes, because you know home price is affected by a variety of factors, such as square footage. Thus, what you really need to do is estimate the mean home price at different levels of square footage.</p>
<p>In this chapter we will start developing a tool for situations like this where we want to link a mean (or a proportion) to other measurements. The tool we will use is the <strong>generalized linear model</strong>. The GLM is the powerhouse of statistical analysis. It’s flexible enough to allow us to estimate the simplest of quantities, such as a single mean or proportion, but also to link a response variable to other measurements. We can use GLMs to examine the relationship between two variables in a simple experiment, and we can use to examine the relaitonship between two variables while adjusting for other variables, often a necessity in observational designs. We can use the GLM for situations where we expect a relationship to be constant, or in situations where the relationship between variables depends on a third variable. The bottom line is that GLMs are extremely flexible, and as such, they will be the focus of the remainder of this book.</p>
<p>In light of the criticisms of frequentist inference with null hypothesis significance testing, all the examples in the remainder of the book will be presented initially with Bayesian estimation procedures. However, because students of statistics should know how to interpret studies using frequentist inference, each example will include a short “How a Frequentist Would Analyze It” section.</p>
<div id="statistical-models" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Statistical models<a href="the-linear-model.html#statistical-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The rest of this book is about designing statistical models to estimate quantities of interest. A <strong>model</strong> is just a simplified representation of some phenomenon of interest. We’ve already seen models in the form of DAGs, which represent our scientific model of how variables are causally related to each other. As scientific models, DAGs are largely conceptual in nature. Science is about confronting our ideas with data, and so we need a model to help us make that link. That’s where <strong>statistical models</strong> enter the picture. Statistical models are quantitative representations of our scientific models. They can consist of an equation, or a set of equations, that describe single variables, and more often in causal inference, the relationship between variables.</p>
<p>Let’s develop the idea of a statistical model with an example. In this chapter we will look at the the growth of perennial ryegrass, which is native to Europe and Asia but has been cultivated and introduced around the world. Ryegrass can be considered an invasive species in that it can outcompete native plants. We’re going to look at the growth rate of ryegrass as measured in the lab, using data from (<a href="https://doi.org/10.1034/j.1399-3054.2002.1140312.x">Inderjit et al. 2002</a>).</p>
<p>Let’s go ahead and load the data. This is actually only a subset of N = 9 observations. You’ll see there are two variables in the data frame, <code>conc</code> and <code>rootl</code>, and for now we’ll focus our attention on <code>rootl</code>, which is the root length of ryegrass measured in cm.</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="the-linear-model.html#cb266-1" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/ryegrass_sub.csv&quot;</span>)</span>
<span id="cb266-2"><a href="the-linear-model.html#cb266-2" tabindex="-1"></a><span class="fu">print</span>(d)</span></code></pre></div>
<pre><code>##      rootl conc
## 1 8.355556 0.94
## 2 6.914286 0.94
## 3 7.750000 0.94
## 4 6.871429 1.88
## 5 6.450000 1.88
## 6 5.922222 1.88
## 7 1.925000 3.75
## 8 2.885714 3.75
## 9 4.233333 3.75</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="the-linear-model.html#cb268-1" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> d, <span class="fu">aes</span>(<span class="at">x =</span> rootl)) <span class="sc">+</span></span>
<span id="cb268-2"><a href="the-linear-model.html#cb268-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.5</span>, <span class="at">fill =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb268-3"><a href="the-linear-model.html#cb268-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Root length (cm)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Frequency&quot;</span>) <span class="sc">+</span></span>
<span id="cb268-4"><a href="the-linear-model.html#cb268-4" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk01-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk01)TODO: caption.
</p>
</div>
<p>The histogram doesn’t tell us much with only nine observations, but we do know root length is a continuous random variable. Root length in this dataset is being used to measure the growth of ryegrass in the lab. Growth rates and plant size typically exhibit bell-shaped, approximately normal distributions. Indeed, any attribute that is influenced by many processes with non-trivial effects (e.g., many genes and environmental factors) tends to exhibit an approximately normal distribution. So we will generate a simple statistical model that describes root length with a normal distribution.</p>
<p>We will follow the approach outlined in McElreath (2020) to define statistical models, which involves:</p>
<ol style="list-style-type: decimal">
<li>Identify the observed variables. These are the data we collect from samples.</li>
<li>Identify the unobserved parameters. These are the unknown quantities we wish to estimate with the data.</li>
<li>Define how the observed data are generated. This can be a simple as defining a single variable as a random variable from a particular probaiblity distribution, or we can define variables in terms of other variables.</li>
<li>For Bayesian analysis, define our prior distributions for each unknown parameter.</li>
</ol>
<p>Let’s apply this to our ryegrass example. To start, we are simply describing the observed root length data as a random variable drawn from a normal distribution. The normal distribution has two parameters that we need to estimate: the mean and the standard deviation. Thus, in our model, we need a line to describe root length as a random variable, and two lines to define the prior distributions for each of the unknown parameters. Here’s the model we will use:</p>
<p><span class="math display">\[
\begin{array}{l}
r_i \sim \mathrm{Normal}(\mu, \sigma) \\
\mu \sim \mathrm{Normal}(5, 2) \\
\sigma \sim \mathrm{Uniform}(0, 5)
\end{array}
\]</span></p>
<p>Let’s walk through each line of our statistical model. First we have <span class="math inline">\(r_i \sim \mathrm{Normal}(\mu, \sigma)\)</span>. Here we are defining the observed values of root length for each individual <em>i</em> (<span class="math inline">\(r_i\)</span>) as a random variable following a normal distribution with parameters mean = <span class="math inline">\(\mu\)</span> and standard deviation = <span class="math inline">\(\sigma\)</span>. Remember the tilde symbol (~) defines a relationship as <strong>stochastic</strong>, which means that the observed values <span class="math inline">\(r_i\)</span> are probabalistic rather than being determiend with certainty. The normal distribution with its parameters defines the probability of drawing particulare values of root length. We don’t know what those parameter values are, so we will have to estimate them. In the context of Bayesian estimation, this line represents the likelihood.</p>
<p>The second and third lines are prior distributions. In Bayesian estimation, every parameter in the statistical model requires a prior. Even though we might be more interested in the mean root length than its variation, we’re assuming root length has a normal distribution, and the normal distibution has two parameters (mean and standard deviation). When we assume a variable is drawn from a particular probability distribution, we have to estimate the parmaeters for that probability distribution whether we want them or not. That’s why it’s useful to differentiate between types of parameters, the estimands being the parameters that we are most interested in.</p>
<p>Now consider what each prior distribution says. The first prior is for the mean root length: <span class="math inline">\(\mu \sim \mathrm{Normal}(5, 2)\)</span>. This defines the probability of the mean taking on different values with a normal distribution, specifically a normal distribution with a mean of 5 and standard deviation of 2. Effetively what this means is that - prior to analyzing the data - I think the most plausible values for the mean root lenght are around 5 cm. The mean could be greater or less than 5 cm, but 5 cm is the most likely value (as the mean of the normal distribution). Of course we can say exatly how likely the other values are. Following hte empricail rule, I’m assuming that there’s a 95% chance that the mean root length is between 1 and 9 cm. Values outside those bounds collectively have only a 5% probability.</p>
<p>How did I know to use those particular values for the normal prior (mean = 5, standard deviation = 2). This is where domain knowledge is helpful. Based on prior knowledge from people who have worked with ryegrass in this kind of experimental setting (growing plants in petri dishes), we know the mean root lenghts are going to be relatively small, likely somewhere in the range of 0-10 cm. The values at the extremes of that range are much less likely than values in the middle - indeed, it’s not even possible to have a root length of 0 cm. The normal distribution captures that prior knowledge nicely (albeit imperfectly, as every model is imperfect).</p>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk02,%20-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk02, )TODO: caption.
</p>
</div>
<p>Remember that Bayesian inference combines the prior and likelihood to quantify the posterior distributions for each a parameter. We’re going to use <code>brms</code> to do just that, but before doing so, it can be very useful to do that’s called a <strong>prior predictive simulation</strong>. The idea is that we can use the prior distributions to simulate data to get a senes for what the prior distributions imply about what the data should look like. For the ryegrass example, the idea is to get a sense for the different possible combinations of the mean and standard deviation of root length, and the resulting distribution of root length implied by the priors:</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="the-linear-model.html#cb269-1" tabindex="-1"></a><span class="co">#from https://bookdown.org/content/4857/geocentric-models.html#a-language-for-describing-models</span></span>
<span id="cb269-2"><a href="the-linear-model.html#cb269-2" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb269-3"><a href="the-linear-model.html#cb269-3" tabindex="-1"></a></span>
<span id="cb269-4"><a href="the-linear-model.html#cb269-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb269-5"><a href="the-linear-model.html#cb269-5" tabindex="-1"></a></span>
<span id="cb269-6"><a href="the-linear-model.html#cb269-6" tabindex="-1"></a><span class="co">#randomly draw means from the prior</span></span>
<span id="cb269-7"><a href="the-linear-model.html#cb269-7" tabindex="-1"></a>mu.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb269-8"><a href="the-linear-model.html#cb269-8" tabindex="-1"></a></span>
<span id="cb269-9"><a href="the-linear-model.html#cb269-9" tabindex="-1"></a><span class="co">#randomly draw SDs from the prior</span></span>
<span id="cb269-10"><a href="the-linear-model.html#cb269-10" tabindex="-1"></a>sigma.sim <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">5</span>)</span>
<span id="cb269-11"><a href="the-linear-model.html#cb269-11" tabindex="-1"></a></span>
<span id="cb269-12"><a href="the-linear-model.html#cb269-12" tabindex="-1"></a><span class="co">#randomly draw values of root length from the combined means and SDs</span></span>
<span id="cb269-13"><a href="the-linear-model.html#cb269-13" tabindex="-1"></a>r.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu.sim, <span class="at">sd =</span> sigma.sim)</span>
<span id="cb269-14"><a href="the-linear-model.html#cb269-14" tabindex="-1"></a></span>
<span id="cb269-15"><a href="the-linear-model.html#cb269-15" tabindex="-1"></a><span class="co">#plot the simulated root lenth distribution</span></span>
<span id="cb269-16"><a href="the-linear-model.html#cb269-16" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">r.sim =</span> r.sim)</span>
<span id="cb269-17"><a href="the-linear-model.html#cb269-17" tabindex="-1"></a></span>
<span id="cb269-18"><a href="the-linear-model.html#cb269-18" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> r.sim)) <span class="sc">+</span></span>
<span id="cb269-19"><a href="the-linear-model.html#cb269-19" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;darkblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb269-20"><a href="the-linear-model.html#cb269-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Implied distribution of root length from priors&quot;</span>,</span>
<span id="cb269-21"><a href="the-linear-model.html#cb269-21" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Root length (cm)&quot;</span>,</span>
<span id="cb269-22"><a href="the-linear-model.html#cb269-22" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb269-23"><a href="the-linear-model.html#cb269-23" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk03-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk03)TODO: caption.
</p>
</div>
<p>We can see the distribution of root length implied by the priors has a mean right around 5 cm as expected, so that’s good. But what’s not good is that the variation around that mean is unrealistic. The priors are implying a non-trivial chance of seeing root lengths that are 0 or negative! Good thing we did this prior predictive simulation. This is exactly why you’d do such a thing; to see if the priors you assumed are realistic. Clearly the priors we’re using can be improved. Let’s tighten things up with a revised statsitical model:</p>
<p><span class="math display">\[
\begin{array}{l}
r_i \sim \mathrm{Normal}(\mu, \sigma) \\
\mu \sim \mathrm{Normal}(5, 1) \\
\sigma \sim \mathrm{Uniform}(0, 3)
\end{array}
\]</span></p>
<p>Do you see what changed? The normal prior for the mean now implies a 95% chance of the mean being 3-7 cm, and we’ve reduced the upper bound of the standard deviation from 5 cm to 3 cm. Let’s see if that implies a more realistic distribution of heights:</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="the-linear-model.html#cb270-1" tabindex="-1"></a><span class="co">#from https://bookdown.org/content/4857/geocentric-models.html#a-language-for-describing-models</span></span>
<span id="cb270-2"><a href="the-linear-model.html#cb270-2" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb270-3"><a href="the-linear-model.html#cb270-3" tabindex="-1"></a></span>
<span id="cb270-4"><a href="the-linear-model.html#cb270-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb270-5"><a href="the-linear-model.html#cb270-5" tabindex="-1"></a></span>
<span id="cb270-6"><a href="the-linear-model.html#cb270-6" tabindex="-1"></a><span class="co">#randomly draw means from the prior</span></span>
<span id="cb270-7"><a href="the-linear-model.html#cb270-7" tabindex="-1"></a>mu.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb270-8"><a href="the-linear-model.html#cb270-8" tabindex="-1"></a></span>
<span id="cb270-9"><a href="the-linear-model.html#cb270-9" tabindex="-1"></a><span class="co">#randomly draw SDs from the prior</span></span>
<span id="cb270-10"><a href="the-linear-model.html#cb270-10" tabindex="-1"></a>sigma.sim <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">3</span>)</span>
<span id="cb270-11"><a href="the-linear-model.html#cb270-11" tabindex="-1"></a></span>
<span id="cb270-12"><a href="the-linear-model.html#cb270-12" tabindex="-1"></a><span class="co">#randomly draw values of root length from the combined means and SDs</span></span>
<span id="cb270-13"><a href="the-linear-model.html#cb270-13" tabindex="-1"></a>r.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu.sim, <span class="at">sd =</span> sigma.sim)</span>
<span id="cb270-14"><a href="the-linear-model.html#cb270-14" tabindex="-1"></a></span>
<span id="cb270-15"><a href="the-linear-model.html#cb270-15" tabindex="-1"></a><span class="co">#plot the simulated root lenth distribution</span></span>
<span id="cb270-16"><a href="the-linear-model.html#cb270-16" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">r.sim =</span> r.sim)</span>
<span id="cb270-17"><a href="the-linear-model.html#cb270-17" tabindex="-1"></a></span>
<span id="cb270-18"><a href="the-linear-model.html#cb270-18" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> r.sim)) <span class="sc">+</span></span>
<span id="cb270-19"><a href="the-linear-model.html#cb270-19" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">color =</span> <span class="st">&quot;darkblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb270-20"><a href="the-linear-model.html#cb270-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Implied distribution of root length from priors&quot;</span>,</span>
<span id="cb270-21"><a href="the-linear-model.html#cb270-21" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Root length (cm)&quot;</span>,</span>
<span id="cb270-22"><a href="the-linear-model.html#cb270-22" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb270-23"><a href="the-linear-model.html#cb270-23" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk04-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk04)TODO: caption.
</p>
</div>
<p>There are still some negative values implied by the priors, but now they are quite rare. One of the reasons we continue to see some very small proportion of negative root lengths is that we’re assuming a normal distribution for root length, and the normal distribution can have negative values. As we’ll see later in the book, there are other probability distributions that may be more effective. In this case, it would be helpful to use a probability distribution that has a bell-shaped curve, but that does not allow negative values. Stay tuned. For now, this prior distribution will suffice. Let’s proceed with estimation in <code>brms</code>:</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="the-linear-model.html#cb271-1" tabindex="-1"></a><span class="co">#specify model formula</span></span>
<span id="cb271-2"><a href="the-linear-model.html#cb271-2" tabindex="-1"></a>m1.formula <span class="ot">&lt;-</span> <span class="fu">bf</span>(rootl <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb271-3"><a href="the-linear-model.html#cb271-3" tabindex="-1"></a>                <span class="at">family =</span> gaussian) <span class="co">#defines root length as a normal random var</span></span>
<span id="cb271-4"><a href="the-linear-model.html#cb271-4" tabindex="-1"></a></span>
<span id="cb271-5"><a href="the-linear-model.html#cb271-5" tabindex="-1"></a><span class="co">#specify priors</span></span>
<span id="cb271-6"><a href="the-linear-model.html#cb271-6" tabindex="-1"></a>m1.prior <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">5</span>, <span class="dv">1</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb271-7"><a href="the-linear-model.html#cb271-7" tabindex="-1"></a>             <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">3</span>), <span class="at">class =</span> sigma, <span class="at">lb=</span><span class="dv">0</span>, <span class="at">ub=</span><span class="dv">3</span>))</span>
<span id="cb271-8"><a href="the-linear-model.html#cb271-8" tabindex="-1"></a>              </span>
<span id="cb271-9"><a href="the-linear-model.html#cb271-9" tabindex="-1"></a><span class="co">#compute the posterior</span></span>
<span id="cb271-10"><a href="the-linear-model.html#cb271-10" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">brm</span>(<span class="at">data =</span> d,</span>
<span id="cb271-11"><a href="the-linear-model.html#cb271-11" tabindex="-1"></a>         <span class="at">formula =</span> m1.formula,</span>
<span id="cb271-12"><a href="the-linear-model.html#cb271-12" tabindex="-1"></a>         <span class="at">prior =</span> m1.prior,</span>
<span id="cb271-13"><a href="the-linear-model.html#cb271-13" tabindex="-1"></a>         <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb271-14"><a href="the-linear-model.html#cb271-14" tabindex="-1"></a>         <span class="at">seed=</span><span class="dv">123</span>)</span>
<span id="cb271-15"><a href="the-linear-model.html#cb271-15" tabindex="-1"></a></span>
<span id="cb271-16"><a href="the-linear-model.html#cb271-16" tabindex="-1"></a><span class="fu">print</span>(m1)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity 
## Formula: rootl ~ 1 
##    Data: d (Number of observations: 9) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Regression Coefficients:
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     5.45      0.59     4.28     6.63 1.00     2069     1990
## 
## Further Distributional Parameters:
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     2.25      0.40     1.51     2.94 1.00     1568     1287
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Let’s walk through this. We’ve defined the likelihood with the <code>bf</code> function, where the formula <code>rootl ~ 1</code> tells <code>brms</code> that we want to fit a model with only an intercept, which in this case is a fancy way of saying we want the overall meam (this will make more sense later this chapter!). We’re assuming <code>rootl</code> is a normal random variable with <code>family = gaussian</code>. We then define our priors. In <code>brms</code>, each parameter getting a prior needs a distribution for the prior (<code>normal</code> for the mean, <code>uniform</code> for the stanard deviation in this case), and we specify the type of parameter with the <code>class</code> argument, here being an <code>Intercept</code> for the mean and <code>sigma</code> for the standard deviation. After fitting this model, we see the mean of the posterior distribution for root length is 5.45, and the 95% credible interval is 4.28-6.63. In other words, there’s a 95% probability that the mean root length is between 4.28 and 6.63. We can execute the <code>plot</code> function on our model object to see a graph of the posterior distributions and a plot that helps us diagnose whether the model is converged:</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="the-linear-model.html#cb273-1" tabindex="-1"></a><span class="fu">plot</span>(m1)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk06-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk06)TODO: caption.
</p>
</div>
<p>The left panel shows the posterior distributions for the mean (<code>b_Intercept</code>) and standard deviation (<code>sigma</code>) parameters, and the right side of the panel shows <strong>trace plots</strong> for each panel. Trace plots allow you to view the value of each parameter for each iteration of the model in each chain. What we’re looking for here is relative consistency in the parameter values among the chains, that is <strong>convergence</strong> of the parameter values. These trace plots indicate solid convergence because the values for each chain overlap extensively and hover around a common value. Numerically, the <code>Rhat</code> values near 1 also indicate convergence.</p>
<p>Remember that we can also draw samples from the posterior distribution to compute any quantity of interest. For example, suppose we want to estimate the probability that the mean root length is greater than 5 cm. We just need to extract the samples from the posterior and find the proportion of values greater than 5 for the mean:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="the-linear-model.html#cb274-1" tabindex="-1"></a><span class="co">#posterior samples</span></span>
<span id="cb274-2"><a href="the-linear-model.html#cb274-2" tabindex="-1"></a>m1.post <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">as_draws_df</span>(m1))</span>
<span id="cb274-3"><a href="the-linear-model.html#cb274-3" tabindex="-1"></a><span class="fu">head</span>(m1.post)</span></code></pre></div>
<pre><code>##   b_Intercept    sigma Intercept    lprior      lp__ .chain .iteration .draw
## 1    5.051680 2.925563  5.051680 -2.018886 -25.07558      1          1     1
## 2    4.882915 2.430660  4.882915 -2.024405 -22.87511      1          2     2
## 3    5.939409 1.763796  5.939409 -2.458796 -22.51164      1          3     3
## 4    5.695199 2.873104  5.695199 -2.259202 -24.50022      1          4     4
## 5    6.694626 2.061946  6.694626 -3.453430 -24.31155      1          5     5
## 6    6.645777 2.094947  6.645777 -3.371841 -24.11954      1          6     6</code></pre>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="the-linear-model.html#cb276-1" tabindex="-1"></a><span class="co">#probability that the proportion infected is greater than 10%</span></span>
<span id="cb276-2"><a href="the-linear-model.html#cb276-2" tabindex="-1"></a><span class="fu">mean</span>(m1.post<span class="sc">$</span>b_Intercept <span class="sc">&gt;</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>## [1] 0.77825</code></pre>
<p>We see there’s a 78% chance that the mean root length is &gt;5 cm.</p>
</div>
<div id="linear-model" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Linear model<a href="the-linear-model.html#linear-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="basic-structure-of-the-linear-model" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Basic structure of the linear model<a href="the-linear-model.html#basic-structure-of-the-linear-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As it turns out, the researchers who generated the data we just analyzed were not simply interested in describing the mean growth rate of ryegrass. Because ryegrass can be invasive, they were interested in understanding the effect of a new herbicide on ryegrass growth. Each petri dish with ryegrass was randomly assigned an herbicide concentration, and they measured root length as an index of plant growth. This is a simple experimental design in which all other resource levels were controlled (e.g., water, light, nutrients). Because there were no concerns about post-treatment bias (e.g., non-random dropout), we can represent the scientific model with a simple DAG:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:c09f1"></span>
<img src="ch09_linearModels_files/figure-html/c09f1-1.png" alt="Initial DAG for the causal effect of greenspace on mental health." width="288" />
<p class="caption">
Figure 9.1: Initial DAG for the causal effect of greenspace on mental health.
</p>
</div>
<p>Recall that our DAG is a scientific model of factors affecting root length. Like any model, it’s a simplified representation of the system in that we are proposing the only non-trivial cause of root length variation is herbicide concentration. In reality we know there are plenty of other factors that affect plant growth - water, light, nutrients, etc. Those factors were controlled in this experiment, such that the different petri dishes were assigned identical levels of resources regardless of herbicide concentration. Because of measurement error, the resource levels won’t be perfectly identical. Some petri dishes will inevitably receive a few microliters more or less of water, for example. That variation may well affect root length, but because the impact is expected to be so miniscule, we leave causes like that out of the DAG. Again, models are simplified representations of reality.</p>
<p>Given our scientific model, how should we analyze the data? We need a statistical model that captures the nature of the relationship between root length and herbicide concentration. As we saw in Chapter 3, when we have two variables that are quantitative, we can use a scatterplot to visualize the association between those variables. Let’s start there:</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="the-linear-model.html#cb278-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb278-2"><a href="the-linear-model.html#cb278-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb278-3"><a href="the-linear-model.html#cb278-3" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb278-4"><a href="the-linear-model.html#cb278-4" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb278-5"><a href="the-linear-model.html#cb278-5" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb278-6"><a href="the-linear-model.html#cb278-6" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb278-7"><a href="the-linear-model.html#cb278-7" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb278-8"><a href="the-linear-model.html#cb278-8" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk08-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk08)TODO: caption.
</p>
</div>
<p>We can see there were three levels of herbicide concentration assigned to three replicates for nine total observations. Visually it looks like there is a negative relationship between root length and herbicide concentration, root length decreases as herbicide concentration increases. We need a statistical model to estimate that association. Linear models are extremely useful for this task.</p>
<p>In our initial statistical model, we assumed that the root length values were drawn from a common normal distribution with a single mean and standard deviation. The scatterplot above suggests that’s not a good assumption. It looks like the average root length is high when little herbicide is applied, whereas average root length is high when a lot of herbicide is applied. We need a statistical model that allows the root length values to be drawn from distributions that have different means, where the mean root length depends on the herbicide concentration. Let’s revise the statistical model to do just that:</p>
<p><span class="math display">\[
\begin{array}{l}
r_i \sim \mathrm{Normal}(\mu_i, \sigma) \\
\mu_i = \alpha + \beta x_i \\
\alpha \sim \mathrm{Normal}(5, 2) \\
\beta \sim \mathrm{Normal}(0, 1) \\
\sigma \sim \mathrm{Uniform}(0, 3)
\end{array}
\]</span></p>
<p>Again let’s walk through the components:</p>
<ul>
<li><p><strong>Likelihood</strong> (<span class="math inline">\(r_i \sim \mathrm{Normal}(\mu_i, \sigma)\)</span>: Remember the likelihood is simply the probability of the data given the parameter values. How likely are the observed root length values given the mean and standard deviation for the ryegrass distribution? But there’s one big change here. Did you notice the mean parameter now has a subscript (<em>i)</em>? Rather than assuming we have a single normal distribution that describes all the root length values, we’re now saying that the observed root length for individual <em>i</em> is drawn from a unique normal distribution with its own mean.</p></li>
<li><p><strong>Linear model</strong> (<span class="math inline">\(\mu_i = \alpha + \beta x_i\)</span>): Our first linear model! This model defines how the unique mean for each individual <em>i</em> is determined. The model says the mean root length for each individual <em>i</em> is a linear function of two parameters: an intercept (<span class="math inline">\(\alpha\)</span>) and a slope (<span class="math inline">\(\beta\)</span>). You might remember from basic algebra that a line is defined by a simple equation <span class="math inline">\(y = mx + b\)</span>. That’s exactly what we have here, just with different labels for the parameters. What is each component of the linear model saying? The slope (<span class="math inline">\(\beta\)</span>) represents the expected change in the mean root length (<span class="math inline">\(\mu_i\)</span>) for each 1-unit change in <span class="math inline">\(x_i\)</span>. The value <span class="math inline">\(x_i\)</span> here represents the herbicide concentration that each individual <em>i</em> receives. Thus, the slope represents the expected change in the mean root length when the herbicide concentration increases by 1 mM. The intercept (<span class="math inline">\(\alpha\)</span>) represents the expected mean root length when the herbicide concentration is 0. That should make sense. When <span class="math inline">\(x_i=0\)</span>, the slope term in the linear model simply drops out, leaving just the intercept. Together, the intercept and slope determine the mean root length for the distributions from which each observed root length <em>i</em> is drawn.</p></li>
<li><p><strong>Priors:</strong> Remember that each parameter in a statistical model must have a prior distribution, reflecting our belief about the possible values of those parameters prior to analyzing the data. We may not be interested in all the parameters in the model. If our research question is whether the herbicide affects root length, the estimand is the slope (<span class="math inline">\(\beta\)</span>), but we still need to estimate the other parameters to estimate the slope. Let’s walk through the prior for each parameter:</p>
<ul>
<li><p><strong>Intercept</strong> (<span class="math inline">\(\alpha\)</span>): Here we are specifying a normal prior for the intercept with a mean of 5 and standard deviation of 2. That reflects our prior belief that there’s a 95% probability the mean root length is between 1 and 10 cm when there’s no herbicide applied. In this case we increased the standard deviation of the prior back from 1 to 2 to allow for a wider prior distribution given that we are no longer estimating the grand mean, but the mean when no herbicide is applied.</p></li>
<li><p><strong>Slope</strong> (<span class="math inline">\(\beta\)</span>): What is the expected change in mean root length with a 1 mM increase in herbicide concentration? Our normal prior with mean = 0 and standard deviation = 1 implies that the most likely value of the slope is 0, and there’s a 95% chance that the change in root length is between -2 and 2 cm as herbicide concentration increases by 1 mM. Biologically, the researchers very likely expect the root length will decrease as herbicide concentration increases. If much of literature supports such a negative effect, then it may be wise to use a prior that has more probability weighted towards negative effects. On the other hand, this is a new herbicide, and there’s a question about whether it works, so it’s possible that there’s no effect. Given that possibility, we choose to center the prior around 0. Even if we center the prior for the slope around 0, we would still want to use an appropriate standard deviation to limit the range of slopes to values we think are realistic. For example, it wouldn’t make sense to allow for a slope that allows a 100-cm change in root length per one unit increase in mM, when the range in root length values is 0-20 cm. So we restrict the variance in the prior distribution to a range of effect we think is plausible.</p></li>
<li><p><strong>Standard deviation</strong> (<span class="math inline">\(\sigma\)</span>). The standard deviation represents the expected variation in root length values around the expected mean. Any deviation in root length from the expected mean predicted by herbicide concentration represents variation that can’t be explained by herbicide concentration. For example, imagine the expected mean root length is 4 cm when the herbicide concentration is 1 mM. Not every plant with 1 mM herbicide applied will have exactly 4 cm root length. There will be deviations around the expected mean of 4 cm. Those deviations are called <strong>residual errors</strong> (or just “residuals”). Residual variation is always expected in systems that have multiple causes. Some of the variation around the expected mean based on herbicide concentration could be due to minor variation in water, light availability, or other resources. Some of the residual variation may simply be measurement error, and some may simply be random, not having obvious causes). The standard deviation parameter specifies the expected magnitude of the variation in observed root length round the expected mean based on herbicide concentration. Because there’s no <em>i</em> subscript on teh standard deviation, we’re assuming a common magnitude of residual error no matter what the mean root length may be. In this case, we’ve retained the same uniform prior distribution that we used in our more simple analysis that assumed a common normal distribution for all values of root length.</p></li>
</ul></li>
</ul>
</div>
<div id="fitting-the-linear-model-in-brms" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Fitting the linear model in brms<a href="the-linear-model.html#fitting-the-linear-model-in-brms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s go ahead and use a prior predictive simulation to see what the priors imply about the relationship between root length and herbicide concentration. Here all we do is simulate values of the intercept and slope from the priors, then plot them. I’ve limited the number of simulations to N = 100 to ensure that we can visualize the lines in the resulting graph.</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="the-linear-model.html#cb279-1" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb279-2"><a href="the-linear-model.html#cb279-2" tabindex="-1"></a></span>
<span id="cb279-3"><a href="the-linear-model.html#cb279-3" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb279-4"><a href="the-linear-model.html#cb279-4" tabindex="-1"></a></span>
<span id="cb279-5"><a href="the-linear-model.html#cb279-5" tabindex="-1"></a><span class="co">#intercept</span></span>
<span id="cb279-6"><a href="the-linear-model.html#cb279-6" tabindex="-1"></a>alpha.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb279-7"><a href="the-linear-model.html#cb279-7" tabindex="-1"></a></span>
<span id="cb279-8"><a href="the-linear-model.html#cb279-8" tabindex="-1"></a><span class="co">#slope</span></span>
<span id="cb279-9"><a href="the-linear-model.html#cb279-9" tabindex="-1"></a>beta.sim <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb279-10"><a href="the-linear-model.html#cb279-10" tabindex="-1"></a></span>
<span id="cb279-11"><a href="the-linear-model.html#cb279-11" tabindex="-1"></a><span class="co">#values of x (herbicide concentration)</span></span>
<span id="cb279-12"><a href="the-linear-model.html#cb279-12" tabindex="-1"></a>x_vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb279-13"><a href="the-linear-model.html#cb279-13" tabindex="-1"></a></span>
<span id="cb279-14"><a href="the-linear-model.html#cb279-14" tabindex="-1"></a><span class="co"># Create a data frame with all lines</span></span>
<span id="cb279-15"><a href="the-linear-model.html#cb279-15" tabindex="-1"></a>lines_df <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">x =</span> x_vals, <span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span>n) <span class="sc">%&gt;%</span></span>
<span id="cb279-16"><a href="the-linear-model.html#cb279-16" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> alpha.sim[id] <span class="sc">+</span> beta.sim[id] <span class="sc">*</span> x)</span>
<span id="cb279-17"><a href="the-linear-model.html#cb279-17" tabindex="-1"></a></span>
<span id="cb279-18"><a href="the-linear-model.html#cb279-18" tabindex="-1"></a><span class="co"># Plot using ggplot</span></span>
<span id="cb279-19"><a href="the-linear-model.html#cb279-19" tabindex="-1"></a><span class="fu">ggplot</span>(lines_df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">group =</span> id)) <span class="sc">+</span></span>
<span id="cb279-20"><a href="the-linear-model.html#cb279-20" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span>  <span class="co"># Adjust transparency and color</span></span>
<span id="cb279-21"><a href="the-linear-model.html#cb279-21" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb279-22"><a href="the-linear-model.html#cb279-22" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb279-23"><a href="the-linear-model.html#cb279-23" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Root length (cm)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb279-24"><a href="the-linear-model.html#cb279-24" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk09-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk09)TODO: caption.
</p>
</div>
<p>The graph of the prior predictive simulations shows the priors allow for both positive and negative relationships between root length and herbicide concentration. The priors also allow for a range in the expected rooth length when the herbicide concentration is 0 (the intercept). One thing I don’t like about these priors is that in some simulations they allow for relationships with negative expected values of root length, which of course is not possible. But the vast majority of the simulations appear realistic, and for our purposes this is sufficient to combine with the data to estimate the posterior.</p>
<p>To estimate the posterior in <code>brms</code>, we need to use the formula to specify the linear model. The formula we’ll use here is <code>rootl ~ 1 + conc</code>, where <code>1</code> represents the intercept, and <code>conc</code> represents the slope for the effect of herbicide concentration. We use the <code>+</code> operator to add the slope for <code>conc</code> to the model. Then we just need to make sure each parameter has a prior. Slope parameters are denoted <code>class = b</code> when defining priors in <code>brms</code>. Here’s the code to estimate the posterior:</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="the-linear-model.html#cb280-1" tabindex="-1"></a><span class="co">#specify model formula</span></span>
<span id="cb280-2"><a href="the-linear-model.html#cb280-2" tabindex="-1"></a>m2.formula <span class="ot">&lt;-</span> <span class="fu">bf</span>(rootl <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> conc,</span>
<span id="cb280-3"><a href="the-linear-model.html#cb280-3" tabindex="-1"></a>                <span class="at">family =</span> gaussian) <span class="co">#defines root length as a normal random var</span></span>
<span id="cb280-4"><a href="the-linear-model.html#cb280-4" tabindex="-1"></a></span>
<span id="cb280-5"><a href="the-linear-model.html#cb280-5" tabindex="-1"></a><span class="co">#specify priors</span></span>
<span id="cb280-6"><a href="the-linear-model.html#cb280-6" tabindex="-1"></a>m2.prior <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">5</span>, <span class="dv">2</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb280-7"><a href="the-linear-model.html#cb280-7" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> b),</span>
<span id="cb280-8"><a href="the-linear-model.html#cb280-8" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">3</span>), <span class="at">class =</span> sigma, <span class="at">lb=</span><span class="dv">0</span>, <span class="at">ub=</span><span class="dv">3</span>))</span>
<span id="cb280-9"><a href="the-linear-model.html#cb280-9" tabindex="-1"></a>              </span>
<span id="cb280-10"><a href="the-linear-model.html#cb280-10" tabindex="-1"></a><span class="co">#compute the posterior</span></span>
<span id="cb280-11"><a href="the-linear-model.html#cb280-11" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">brm</span>(<span class="at">data =</span> d,</span>
<span id="cb280-12"><a href="the-linear-model.html#cb280-12" tabindex="-1"></a>         <span class="at">formula =</span> m2.formula,</span>
<span id="cb280-13"><a href="the-linear-model.html#cb280-13" tabindex="-1"></a>         <span class="at">prior =</span> m2.prior,</span>
<span id="cb280-14"><a href="the-linear-model.html#cb280-14" tabindex="-1"></a>         <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb280-15"><a href="the-linear-model.html#cb280-15" tabindex="-1"></a>         <span class="at">seed=</span><span class="dv">123</span>)</span>
<span id="cb280-16"><a href="the-linear-model.html#cb280-16" tabindex="-1"></a></span>
<span id="cb280-17"><a href="the-linear-model.html#cb280-17" tabindex="-1"></a><span class="fu">print</span>(m2)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity 
## Formula: rootl ~ 1 + conc 
##    Data: d (Number of observations: 9) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Regression Coefficients:
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     9.05      0.74     7.32    10.36 1.00     2046     1725
## conc         -1.54      0.30    -2.06    -0.86 1.00     2056     1547
## 
## Further Distributional Parameters:
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.00      0.36     0.55     1.93 1.00     1615     1636
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>How do we interpret the output? Remember that the summary for <code>brms</code> models shows the mean (<code>Estimate</code>), standard deviation (<code>Est.Error</code>) and 95% credible interval (<code>l-95% CI</code> and <code>u-95% CI</code>) for each parameter. We’re also given metrics to evaluate whether the parameters have converged to consistent values, an <code>Rhat</code> near 1 implying convergence. Based on the summary output, we can see the mean of the posterior for the intercept is 9.05, implying the most likely value of root length is 9.05 cm when no herbicide is applied. The line for <code>conc</code> supplies summary statistics for the slope for the effect of herbicide concentration on root length. We see the most likely value is -1.54, implying that for every one unit increase in herbicide concentration, root length declines by 1.54 cm on average. Notably the 95% credible interval is (-2.06, -0.86), suggesting the posterior distribution for the slope is broadly negative. We can confirm as much by plotting the posterior distributions:</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="the-linear-model.html#cb282-1" tabindex="-1"></a><span class="fu">plot</span>(m2)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk11-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk11)TODO: caption.
</p>
</div>
<p>Indeed, we see a posterior distribution that is entirely negative for the slope. This is strong evidence that the herbicide has a negative effect on root length, and that the suppression of plant growth increases with increasing herbicide concentration. We can also see from the traceplots that there is excellent convergence of the three parameters in our model (the third being the residual error).</p>
<p>Plots of the posterior distributions and tables summarizing those posterior distributions are helpful for summarizing the output for simple models like ours. But usually it’s even more helpful to visualize the output of our model graphically. Our primary interest is in the relationship between root length and herbicide concentration, so we should make a plot that shows what the posterior distribution implies about that relationship. Lets re-create our scatterplot for root length and herbicide concentration, but now we’ll add a line to the graph representing the association between root length and herbicide based on the posterior means. To do so, we’re going to first use the <code>fitted</code> function to predict the expected values of root length for different values of herbicide concentration. Let’s start with that:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="the-linear-model.html#cb283-1" tabindex="-1"></a><span class="co">#values of herbicide concentration for which to predict root length</span></span>
<span id="cb283-2"><a href="the-linear-model.html#cb283-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(d<span class="sc">$</span>conc), <span class="fu">max</span>(d<span class="sc">$</span>conc), <span class="at">length.out=</span><span class="dv">100</span>)</span>
<span id="cb283-3"><a href="the-linear-model.html#cb283-3" tabindex="-1"></a></span>
<span id="cb283-4"><a href="the-linear-model.html#cb283-4" tabindex="-1"></a><span class="co">#predict values of root length for each value of herbicide</span></span>
<span id="cb283-5"><a href="the-linear-model.html#cb283-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">fitted</span>(m2, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">conc =</span> x))</span>
<span id="cb283-6"><a href="the-linear-model.html#cb283-6" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">conc =</span> x, y)</span>
<span id="cb283-7"><a href="the-linear-model.html#cb283-7" tabindex="-1"></a><span class="fu">head</span>(fit)</span></code></pre></div>
<pre><code>##        conc Estimate Est.Error     Q2.5    Q97.5
## 1 0.9400000 7.598360 0.5021902 6.480100 8.530201
## 2 0.9683838 7.554646 0.4959052 6.456589 8.478159
## 3 0.9967677 7.510932 0.4896868 6.433725 8.428845
## 4 1.0251515 7.467218 0.4835377 6.410807 8.375627
## 5 1.0535354 7.423504 0.4774606 6.383898 8.315237
## 6 1.0819192 7.379791 0.4714582 6.354950 8.265914</code></pre>
<p>What is the <code>fitted</code> function doing? It’s taking each value of <code>x</code> and plugging it into the linear model formula to compute the expected mean root length. For example, when herbicide concentration is <span class="math inline">\(x = 0.94\)</span>, the expected mean root length is <span class="math inline">\(y = 9.05 - 1.54*0.94 = 7.6\)</span> based on the posterior mean for the intercept (9.05) and slope (-1.54). But remember with Bayesian inference the estimate is not a single point, but an entire distribution. The <code>fitted</code> function computes the expected mean root length from the values of <span class="math inline">\(x\)</span> across every sample for the posterior distribution, and it provides summary statistics of the variation around the posterior mean, namely the standard deviation (<code>Est.Error</code>) and a 95% credible interval (<code>Q2.5</code> and <code>Q97.5</code>).</p>
<p>Now let’s make our scatterplot and add the posterior mean predictions. All we do here is take the code for our original scatterplot, and we add the function <code>geom_line</code> to add the prediction line:</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="the-linear-model.html#cb285-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb285-2"><a href="the-linear-model.html#cb285-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb285-3"><a href="the-linear-model.html#cb285-3" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> fit, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> Estimate)) <span class="sc">+</span></span>
<span id="cb285-4"><a href="the-linear-model.html#cb285-4" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb285-5"><a href="the-linear-model.html#cb285-5" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb285-6"><a href="the-linear-model.html#cb285-6" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb285-7"><a href="the-linear-model.html#cb285-7" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb285-8"><a href="the-linear-model.html#cb285-8" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb285-9"><a href="the-linear-model.html#cb285-9" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk13-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk13)TODO: caption.
</p>
</div>
<p>It’s worth bearing in mind that this prediction line represents the posterior mean, so it doesn’t communicate the uncertainty about our estimate. To see what I mean, let’s add prediction lines for a selection of the posterior samples to get a sense for the variation To do so, we need to first extract the samples with <code>as_draws_df</code>:</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="the-linear-model.html#cb286-1" tabindex="-1"></a>m2.post <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(m2)</span>
<span id="cb286-2"><a href="the-linear-model.html#cb286-2" tabindex="-1"></a><span class="fu">head</span>(m2.post)</span></code></pre></div>
<pre><code>## # A draws_df: 6 iterations, 1 chains, and 6 variables
##   b_Intercept b_conc sigma Intercept lprior lp__
## 1         9.6   -1.8  0.56       5.6   -5.4  -17
## 2         9.4   -1.5  1.18       6.2   -4.9  -17
## 3         8.2   -1.3  1.30       5.4   -4.5  -18
## 4         7.8   -1.1  0.88       5.4   -4.3  -18
## 5         9.8   -1.9  0.81       5.7   -5.4  -16
## 6         9.7   -1.8  1.02       5.8   -5.3  -16
## # ... hidden reserved variables {&#39;.chain&#39;, &#39;.iteration&#39;, &#39;.draw&#39;}</code></pre>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="the-linear-model.html#cb288-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb288-2"><a href="the-linear-model.html#cb288-2" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">data =</span> m2.post, </span>
<span id="cb288-3"><a href="the-linear-model.html#cb288-3" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">intercept =</span> b_Intercept, <span class="at">slope =</span> b_conc),</span>
<span id="cb288-4"><a href="the-linear-model.html#cb288-4" tabindex="-1"></a>              <span class="at">linewidth=</span><span class="fl">0.1</span>, <span class="at">alpha=</span><span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb288-5"><a href="the-linear-model.html#cb288-5" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> fit, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> Estimate), <span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb288-6"><a href="the-linear-model.html#cb288-6" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb288-7"><a href="the-linear-model.html#cb288-7" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb288-8"><a href="the-linear-model.html#cb288-8" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb288-9"><a href="the-linear-model.html#cb288-9" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb288-10"><a href="the-linear-model.html#cb288-10" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb288-11"><a href="the-linear-model.html#cb288-11" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb288-12"><a href="the-linear-model.html#cb288-12" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk15-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk15)TODO: caption.
</p>
</div>
<p>This plot shows the prediction line for every single posterior sample from our model. I leveraged the <code>geom_abline</code> function to make this easy, as it automatically adds a line to the graph based on a supplied intercept and slope. I made the line width small and the lines transparent (<code>alpha = 0.3</code>) so that you could see the the points, the posterior mean prediction, and where most of the lines are concentrated. What we see is that the posterior mean prediction is in the center of the cluster, and the variation around it represents uncertainty. The more variation in the predictions from individual samples, the more uncertainty we have about the estimated relationship. Including predictions from each draw of the posterior can effective for displaying uncertainty, but an alternative would be to plot a credible interval at a particular level of probability around the posterior mean prediciton. Here’s the same plot but with a 95% credible interval for the prediction line:</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="the-linear-model.html#cb289-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb289-2"><a href="the-linear-model.html#cb289-2" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data =</span> fit,</span>
<span id="cb289-3"><a href="the-linear-model.html#cb289-3" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> Estimate, <span class="at">ymin =</span> Q2<span class="fl">.5</span>, <span class="at">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb289-4"><a href="the-linear-model.html#cb289-4" tabindex="-1"></a>              <span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb289-5"><a href="the-linear-model.html#cb289-5" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">linewidth =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb289-6"><a href="the-linear-model.html#cb289-6" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb289-7"><a href="the-linear-model.html#cb289-7" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb289-8"><a href="the-linear-model.html#cb289-8" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb289-9"><a href="the-linear-model.html#cb289-9" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb289-10"><a href="the-linear-model.html#cb289-10" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb289-11"><a href="the-linear-model.html#cb289-11" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb289-12"><a href="the-linear-model.html#cb289-12" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk16-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk16)TODO: caption.
</p>
</div>
<p>Here we’re drawing on the predictions we made with the <code>fitted</code> function, which computed the 95% credible interval. The <code>geom_smooth</code> function adds the prediction line and a shaded area for the 95% credible interval.</p>
<p>It’s important to note that the variation in the prediction lines and the credible interval we just plotted both represent uncertainty about the <em>expected mean</em> value of the response variable at each value of the explanatory variable. In the context of our statistical model, these represent uncertainty about the values of <span class="math inline">\(\mu_i\)</span>. What if we wanted to represent uncertainty about the observed values of the response variable? We can clearly see that not all the points are exactly the same as the mean root length at a given herbicide concentration. There is residual variation in root length unexplained by herbicide concentration. How do we represent uncertainty about the individual values of root length?</p>
<p>To quantify uncertainty about the individual values of root length, we need to consider the standard deviation parameter, which represents the variation in root length values around the expected mean. In <code>brms</code>, the <code>fitted</code> function we used before only makes predictions about the mean of the response variable, and it quantifies uncertainty only about that mean. The<code>predict</code> function allows us to quantify uncertainty about the individual values of the response variable, collectively considering the mean and the standard deviation. It works much like the <code>fitted</code> function:</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="the-linear-model.html#cb290-1" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">predict</span>(m2, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">conc =</span> x))</span>
<span id="cb290-2"><a href="the-linear-model.html#cb290-2" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">cbind.data.frame</span>(<span class="at">conc =</span> x, y)</span>
<span id="cb290-3"><a href="the-linear-model.html#cb290-3" tabindex="-1"></a><span class="fu">head</span>(pred)</span></code></pre></div>
<pre><code>##        conc Estimate Est.Error     Q2.5    Q97.5
## 1 0.9400000 7.585479  1.133356 5.198950 9.701865
## 2 0.9683838 7.526634  1.166065 5.125505 9.812272
## 3 0.9967677 7.506209  1.185859 5.172469 9.809129
## 4 1.0251515 7.450557  1.161147 5.058929 9.727346
## 5 1.0535354 7.448916  1.154815 5.082123 9.682222
## 6 1.0819192 7.378764  1.155527 5.023748 9.561848</code></pre>
<p>Notice that although the estimated values are similar to the estimates from <code>fitted</code>, the credible intervals are much wider here because they consider the uncertainty in the mean and the individual observaitons around the mean. We call this interval the <span class="math display">\[prediction interval\]</span>. Let’s go ahead and plot it:</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="the-linear-model.html#cb292-1" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb292-2"><a href="the-linear-model.html#cb292-2" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> pred, </span>
<span id="cb292-3"><a href="the-linear-model.html#cb292-3" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> Estimate, <span class="at">ymin =</span> Q2<span class="fl">.5</span>, <span class="at">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb292-4"><a href="the-linear-model.html#cb292-4" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;grey83&quot;</span>) <span class="sc">+</span></span>
<span id="cb292-5"><a href="the-linear-model.html#cb292-5" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data =</span> fit,</span>
<span id="cb292-6"><a href="the-linear-model.html#cb292-6" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> Estimate, <span class="at">ymin =</span> Q2<span class="fl">.5</span>, <span class="at">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb292-7"><a href="the-linear-model.html#cb292-7" tabindex="-1"></a>              <span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb292-8"><a href="the-linear-model.html#cb292-8" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">linewidth =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb292-9"><a href="the-linear-model.html#cb292-9" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb292-10"><a href="the-linear-model.html#cb292-10" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb292-11"><a href="the-linear-model.html#cb292-11" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb292-12"><a href="the-linear-model.html#cb292-12" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb292-13"><a href="the-linear-model.html#cb292-13" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb292-14"><a href="the-linear-model.html#cb292-14" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb292-15"><a href="the-linear-model.html#cb292-15" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk18-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk18)TODO: caption.
</p>
</div>
<p>Here we’ve used the <code>geom_ribbon</code> function to add the prediction interval to the last version of our figure. This figure now shows the observed data (red points), the posterior mean prediction line (solid black line), uncertainty in the predicted mean (95% credible interval in dark gray shading), and uncertainty in the individual observations (95% prediction interval in light gray shading). Whereas the credible interval shows uncertainty about the expected mean, the 95% prediction interval in light gray shows where we would expect 95% of the root length values to occur at any particular value of herbicide concentration.</p>
</div>
<div id="how-a-frequentist-might-do-it" class="section level3 hasAnchor" number="9.2.3">
<h3><span class="header-section-number">9.2.3</span> How a frequentist might do it<a href="the-linear-model.html#how-a-frequentist-might-do-it" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s look at how we would fit the same model with frequentist inference. When we fit a linear model with frequentist inference, we use the data to compute point estimates for the intercept and slope. Remember the idea in frequentist inference is that if we were to repeat sampling and estimate the intercept and slope over and over again, we would see variation in the estimates due to sampling error. So in addition to computing point estimates for the linear model parmaeters, we’ll also compute the standard error and confidence intervals for those parameters as indices of uncertainty.</p>
<p>In R we can fit a linear model with the <code>lm</code> function, using a formula with the <code>~</code> operator to specify the relationship of the response variable to the explanatory variable. Just like in <code>brms</code>, the response variable is specified first on the left of the tilde, and the explanatory variable on the right of the tilde. I’ve included a <code>1</code> on the right side of the formula to specify an intercept as I did in <code>brms</code>, but note that the <code>lm</code> includes an intercept by default, so <code>rootl ~ conc</code> would produce the same output.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="the-linear-model.html#cb293-1" tabindex="-1"></a><span class="co">#fit the linear model</span></span>
<span id="cb293-2"><a href="the-linear-model.html#cb293-2" tabindex="-1"></a>m.f <span class="ot">&lt;-</span> <span class="fu">lm</span>(rootl <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> conc, <span class="at">data =</span> d)</span>
<span id="cb293-3"><a href="the-linear-model.html#cb293-3" tabindex="-1"></a><span class="fu">summary</span>(m.f)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rootl ~ 1 + conc, data = d)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.15416 -0.29959 -0.05154  0.55401  1.15418 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   9.3813     0.5592  16.776 6.54e-07 ***
## conc         -1.6806     0.2253  -7.459 0.000142 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7894 on 7 degrees of freedom
## Multiple R-squared:  0.8882, Adjusted R-squared:  0.8723 
## F-statistic: 55.64 on 1 and 7 DF,  p-value: 0.0001421</code></pre>
<p>The key part of the model is under the heading <code>Coefficients</code>, where we see point estimates (<code>Estimate</code>) and the standard error (<code>Std. Error</code>) for the intercept and slope. The point estimate for the intercept is 9.38, whereas the slope estimate is -1.68. In addition to providing the point estimate and the standard error, the <code>lm</code> function computes a null hypothesis test for the intercept and slope. For both the intercept and slope, the null hypothesis is that the parameter value is 0. Often that doesn’t make too much sense for the intercept. After all, it woudln’t make sense for root length to be 0 when herbicide is applied. The slope is the main parameter where the null hypothesis is of interest. A slope of 0 implies no relationship between root length and herbicide concentration.</p>
<p>The particular test statistics for testing the null hypothesis in this case is the <em>t</em> value, which we have seen before. Effectively this is a “t-test” for the null hypothesis that the slope is 0, where <span class="math inline">\(t = \frac{b - \beta}{SE_b}\)</span>, with <span class="math inline">\(\beta\)</span> being the null hypothesized value for the slope, and <span class="math inline">\(b\)</span> being the estimated slope. Here R reports a <em>t</em> value of -7.46, which we could just recreate as <span class="math inline">\(t = \frac{b - \beta}{SE_b} = \frac{-1.6806 - 0}{0.2253}=-7.459.\)</span> The degrees of freedom for a linear model like this is <em>n-2</em>, and we see the <em>P</em>-value reported is 0.00142. With a significance value of 0.05, we would reject the null hypothesis and conclude there’s a significant negative relationship between root length and herbicide concentration.</p>
<p>In addition to the standard error and null hypothesis test, we can obtain confidence intervals for the regression coefficients:</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="the-linear-model.html#cb295-1" tabindex="-1"></a><span class="co">#confidence intervals</span></span>
<span id="cb295-2"><a href="the-linear-model.html#cb295-2" tabindex="-1"></a><span class="fu">confint</span>(m.f, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##                 2.5 %    97.5 %
## (Intercept)  8.058986 10.703562
## conc        -2.213322 -1.147807</code></pre>
<p>We can also create a scatterplot with the best-fit line and a shaded area corresponding to the confidence interval for the predicted mean root length, as well as a prediction interval for the distribution of observed values around the expected mean.</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="the-linear-model.html#cb297-1" tabindex="-1"></a><span class="co">#values of herbicide concentration for which to predict root length</span></span>
<span id="cb297-2"><a href="the-linear-model.html#cb297-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(d<span class="sc">$</span>conc), <span class="fu">max</span>(d<span class="sc">$</span>conc), <span class="at">length.out=</span><span class="dv">100</span>)</span>
<span id="cb297-3"><a href="the-linear-model.html#cb297-3" tabindex="-1"></a></span>
<span id="cb297-4"><a href="the-linear-model.html#cb297-4" tabindex="-1"></a><span class="co"># Get confidence and prediction intervals</span></span>
<span id="cb297-5"><a href="the-linear-model.html#cb297-5" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(m.f, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">conc=</span>x), </span>
<span id="cb297-6"><a href="the-linear-model.html#cb297-6" tabindex="-1"></a>                 <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb297-7"><a href="the-linear-model.html#cb297-7" tabindex="-1"></a>preds_pi <span class="ot">&lt;-</span> <span class="fu">predict</span>(m.f, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">conc=</span>x), </span>
<span id="cb297-8"><a href="the-linear-model.html#cb297-8" tabindex="-1"></a>                    <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb297-9"><a href="the-linear-model.html#cb297-9" tabindex="-1"></a></span>
<span id="cb297-10"><a href="the-linear-model.html#cb297-10" tabindex="-1"></a><span class="co"># Combine into a data frame for plotting</span></span>
<span id="cb297-11"><a href="the-linear-model.html#cb297-11" tabindex="-1"></a>pred_df <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">conc=</span>x, </span>
<span id="cb297-12"><a href="the-linear-model.html#cb297-12" tabindex="-1"></a>                 <span class="at">fit =</span> preds[, <span class="st">&quot;fit&quot;</span>],</span>
<span id="cb297-13"><a href="the-linear-model.html#cb297-13" tabindex="-1"></a>                 <span class="at">lwr_ci =</span> preds[, <span class="st">&quot;lwr&quot;</span>],</span>
<span id="cb297-14"><a href="the-linear-model.html#cb297-14" tabindex="-1"></a>                 <span class="at">upr_ci =</span> preds[, <span class="st">&quot;upr&quot;</span>],</span>
<span id="cb297-15"><a href="the-linear-model.html#cb297-15" tabindex="-1"></a>                 <span class="at">lwr_pi =</span> preds_pi[, <span class="st">&quot;lwr&quot;</span>],</span>
<span id="cb297-16"><a href="the-linear-model.html#cb297-16" tabindex="-1"></a>                 <span class="at">upr_pi =</span> preds_pi[, <span class="st">&quot;upr&quot;</span>])</span>
<span id="cb297-17"><a href="the-linear-model.html#cb297-17" tabindex="-1"></a></span>
<span id="cb297-18"><a href="the-linear-model.html#cb297-18" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb297-19"><a href="the-linear-model.html#cb297-19" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> rootl)) <span class="sc">+</span></span>
<span id="cb297-20"><a href="the-linear-model.html#cb297-20" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> pred_df, </span>
<span id="cb297-21"><a href="the-linear-model.html#cb297-21" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> fit, <span class="at">ymin =</span> lwr_ci, <span class="at">ymax =</span> upr_ci),</span>
<span id="cb297-22"><a href="the-linear-model.html#cb297-22" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;grey83&quot;</span>) <span class="sc">+</span></span>
<span id="cb297-23"><a href="the-linear-model.html#cb297-23" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">data =</span> pred_df,</span>
<span id="cb297-24"><a href="the-linear-model.html#cb297-24" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> conc, <span class="at">y =</span> fit, <span class="at">ymin =</span> lwr_pi, <span class="at">ymax =</span> upr_pi),</span>
<span id="cb297-25"><a href="the-linear-model.html#cb297-25" tabindex="-1"></a>              <span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb297-26"><a href="the-linear-model.html#cb297-26" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">linewidth =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb297-27"><a href="the-linear-model.html#cb297-27" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb297-28"><a href="the-linear-model.html#cb297-28" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb297-29"><a href="the-linear-model.html#cb297-29" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Herbicide concentration (mM)&quot;</span>,</span>
<span id="cb297-30"><a href="the-linear-model.html#cb297-30" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Root Length (cm)&quot;</span></span>
<span id="cb297-31"><a href="the-linear-model.html#cb297-31" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb297-32"><a href="the-linear-model.html#cb297-32" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="sc">+</span> </span>
<span id="cb297-33"><a href="the-linear-model.html#cb297-33" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk21-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk21)TODO: caption.
</p>
</div>
<p>Note that we use the <code>predict</code> function here to compute the confidence and prediction intervals, specifying each with the <code>interval</code> argument. At a surface level the output is similar to the Bayesian output, mainly because this is a very simple model with only weakly informative prior distribution. But remember that the interpretation is very different from the Bayesian ouptut. We can’t interpret the frequentist output as the probability that the parmater value takes on a particular value, or the probability that the parameter value is in some interval. Indeed, the interpretation of the P-value is that it would be very unlikely (P = 0.000142) to get an estimated slope of -1.68, or more extreme slopes, assuming the true slope is exactly 0. Setting aside teh value of using prior information in the estimation process, even with an uninformative prior the Bayesian output can be interpreted more intuitively as the probability of the hypothessis (any particular value of the slope) given the data we observed.</p>
<p>I’d liek to point out two other pieces of the model output that are commonly referred to in the literature. First, the <code>lm</code> computes an <code>R-squared</code> value. The <span class="math inline">\(R^2\)</span> value is called the <strong>coefficient of determination</strong>, and it measures the proportion of the variation in the response variable “explained” by the explanatory variable. In other words, of all the variation observed among root length, what proportion of that variation is explained by herbicide concentration? The adjusted <span class="math inline">\(R^2\)</span> (usually preferred) is 0.8723, indicating that 87.23% of the variation in root length is explained by herbicide concentration. Essentially the <span class="math inline">\(R^2\)</span> value reflects how much scatter there is in the observed values of the response variable around the prediction line (i.e., the expected mean root length for each value of herbicide concentration. The less scatter, the higher the <span class="math inline">\(R^2\)</span>. Indeed, if all the points fell on the line, <span class="math inline">\(R^2\)</span> would be 1. Essentially <span class="math inline">\(R^2\)</span> gives us a quantitative estimate of the predictive ability of the explanatory variable.</p>
<p>Second, the output reports some basic information about the residuals. Indeed, that scatter around the prediction line is residual variation. The residuals simply measure how far each observed data point is away from the expected mean for its herbicide concentration. When the herbicide concentration is 1.88 mM, the expected mean root length is <span class="math inline">\(\mu_i = 9.3813 -1.6806 \cdot 1.88 = 6.22\)</span>. Let’s see the root lengths we observed at 1.88 mM herbicide concetration:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="the-linear-model.html#cb298-1" tabindex="-1"></a>d[d<span class="sc">$</span>conc<span class="sc">==</span><span class="fl">1.88</span>,]</span></code></pre></div>
<pre><code>##      rootl conc
## 4 6.871429 1.88
## 5 6.450000 1.88
## 6 5.922222 1.88</code></pre>
<p>None of them are exactly 6.22. The unexplained, residual variation is just the difference between each observed value and the expected mean: <span class="math inline">\(e_i = r_i - \hat{\mu_i}\)</span>, where <span class="math inline">\(e_i\)</span> is the residual. For the three observations where herbicide concentration is 1.88 mM, the residuals are:</p>
<p><span class="math display">\[
\begin{array}{l}
e_1 = 6.78 - 6.22 = 0.56 \\
e_2 = 6.45 - 6.22 = 0.23 \\
e_3 = 5.92 - 6.22 = -0.30
\end{array}
\]</span></p>
<p>Notice that the residuals are positive when the observed value is greater than the expected mean, and negative when the observed value is less than the expected mean. The linear model that we used assumes that the residuals have a normal distribution with a mean of 0 and a standard deviation of <span class="math inline">\(\sigma\)</span>. When you fit a linear model with frequentist inference with the <code>lm</code> function, it provides some summary statistics for the residuals. But we can easily compute and analyzed the residuals with the <code>residuals</code> function:</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="the-linear-model.html#cb300-1" tabindex="-1"></a>m.f.res <span class="ot">&lt;-</span> <span class="fu">residuals</span>(m.f)</span>
<span id="cb300-2"><a href="the-linear-model.html#cb300-2" tabindex="-1"></a><span class="fu">head</span>(m.f.res)</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  0.55401210 -0.88725775 -0.05154346  0.64961581  0.22818724 -0.29959054</code></pre>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="the-linear-model.html#cb302-1" tabindex="-1"></a><span class="fu">mean</span>(m.f.res)</span></code></pre></div>
<pre><code>## [1] -2.467162e-17</code></pre>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="the-linear-model.html#cb304-1" tabindex="-1"></a><span class="fu">sd</span>(m.f.res)</span></code></pre></div>
<pre><code>## [1] 0.7384323</code></pre>
<p>We can see the estimated mean residual is basically 0, and the estimated standard deviation is 0.74. If we had a bigger sample size, we might also generate a histogram of the residuals to evaluate whether the distribution is approximately normal, which is what the model assumes.</p>
</div>
</div>
<div id="linear-models-with-categorical-predictors" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Linear models with categorical predictors<a href="the-linear-model.html#linear-models-with-categorical-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Linear models are flexible and can be modified to accomodate different types of data. So far we’ve looked at a simple model when we have a continuous response variable and a continuous predictor variable. In this section we look at what happens when the response is continous and the explanatory variable is categorical.</p>
<div id="binary-explanatory-variables" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Binary explanatory variables<a href="the-linear-model.html#binary-explanatory-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s revisit the dataset on color morphology of red-backed salamanders. These salamanders have two primary color morphs, striped and unstriped, that have been shown to vary in a number of other phenotypic traits. In this section let’s examine if color morphology affects the size of adult salamanders, measured as the snout-vent-length (SVL). First we load the data:</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="the-linear-model.html#cb306-1" tabindex="-1"></a>tail <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/plci_tails.csv&quot;</span>)</span></code></pre></div>
<p>We begin by plotting the tail autotomy data and comparing between morphs, using the</p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="the-linear-model.html#cb307-1" tabindex="-1"></a><span class="fu">ggplot</span>(tail, <span class="fu">aes</span>(<span class="at">x =</span> morph, <span class="at">y =</span> length.cm)) <span class="sc">+</span></span>
<span id="cb307-2"><a href="the-linear-model.html#cb307-2" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> <span class="fl">0.1</span>, <span class="at">shape =</span> <span class="dv">1</span>, <span class="fu">aes</span>(<span class="at">color =</span> morph)) <span class="sc">+</span></span>
<span id="cb307-3"><a href="the-linear-model.html#cb307-3" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;striped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb307-4"><a href="the-linear-model.html#cb307-4" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sex&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Snout-vent-length (cm)&quot;</span>, <span class="at">color =</span> <span class="st">&quot;morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb307-5"><a href="the-linear-model.html#cb307-5" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb307-6"><a href="the-linear-model.html#cb307-6" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk25-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk25)TODO: caption.
</p>
</div>
<p>We need to fit a model that allows us to estimate the mean SVL for each color morph and compare the mean between morphs. Here’s our statistical model:</p>
<p><span class="math display">\[
\begin{array}{l}
l_i \sim \mathrm{Normal}(\mu_i, \sigma) \\
\mu_i = \alpha_{j} \\
\alpha_{j} \sim \mathrm{Normal}(3.5, 0.5) \\
\sigma \sim \mathrm{Exponential}(3)
\end{array}
\]</span></p>
<p>We assume the lengths (<em>l</em>) for each individual <em>i</em> follow a normal distribution with mean <span class="math inline">\(\mu_i\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. The second line says the expected mean for each individual <em>i</em> is defined by the mean for its morph, <span class="math inline">\(\alpha_j\)</span>, where <em>j</em> represents an index for each color morph. Thus each individual <em>i</em> is either striped or unstriped, and we assume separate meeans for each morph. We assume a normal prior for the means of each sex with mean = 3.5 cm and standard deviation = 0.5 lb, reflecting the prior belief of a ~95% probability that the mean SVL will be between 2.5 and 4.5 for each morph. For the standard deviation parameter we assume an exponential prior. This is the first time we’ve seen an exponential distribution. The exponential distribution is handy for standard deviations because it is bounded at zero and has only positive values. The probabiity density is greatest at 0, and density declines with greater values, with the rate of decline specified by a single rate parameter (greater values indicate steeper rates of decline). The exponential function is considered a regularizing prior for standard deviations because it favors smaller values. Here we choose a an exponential prior with rate parameter 1 for the standard deviation of SVL.</p>
<p>A simple way to code categorical explanatory variables is by specifying a numerical index value for each category. This is simple a way of representing each category as an integer value. Let’s define the striped morph as 1 and unstriped as 2:</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="the-linear-model.html#cb308-1" tabindex="-1"></a>tail<span class="sc">$</span>morph.i <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(tail<span class="sc">$</span>morph <span class="sc">==</span> <span class="st">&quot;striped&quot;</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb308-2"><a href="the-linear-model.html#cb308-2" tabindex="-1"></a>tail<span class="sc">$</span>morph.i <span class="ot">&lt;-</span> <span class="fu">factor</span>(tail<span class="sc">$</span>morph.i)</span></code></pre></div>
<p>One way to handle categorical predictor variables<em>index variable</em>. An index variable represents each category as an integer value. We also define the index variable, <code>morph.i</code> as a factor variable, which is required by <code>brms</code>.</p>
<p>We begin the analysis with a prior predictive check:</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="the-linear-model.html#cb309-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># for reproducibility</span></span>
<span id="cb309-2"><a href="the-linear-model.html#cb309-2" tabindex="-1"></a></span>
<span id="cb309-3"><a href="the-linear-model.html#cb309-3" tabindex="-1"></a><span class="co">#draw 1000 values of the mean striped length from the prior</span></span>
<span id="cb309-4"><a href="the-linear-model.html#cb309-4" tabindex="-1"></a>striped_mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="at">mean =</span> <span class="fl">3.5</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb309-5"><a href="the-linear-model.html#cb309-5" tabindex="-1"></a></span>
<span id="cb309-6"><a href="the-linear-model.html#cb309-6" tabindex="-1"></a><span class="co">#draw 1000 values of the mean festriped weight from the prior</span></span>
<span id="cb309-7"><a href="the-linear-model.html#cb309-7" tabindex="-1"></a>unstriped_mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="at">mean =</span> <span class="fl">3.5</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)</span>
<span id="cb309-8"><a href="the-linear-model.html#cb309-8" tabindex="-1"></a></span>
<span id="cb309-9"><a href="the-linear-model.html#cb309-9" tabindex="-1"></a><span class="co">#draw 1000 values of the standard deviation in weight from the prior</span></span>
<span id="cb309-10"><a href="the-linear-model.html#cb309-10" tabindex="-1"></a>sample_sigma <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">1000</span>, <span class="dv">3</span>)</span>
<span id="cb309-11"><a href="the-linear-model.html#cb309-11" tabindex="-1"></a></span>
<span id="cb309-12"><a href="the-linear-model.html#cb309-12" tabindex="-1"></a><span class="co">#draw values of individual weights for stripeds and festripeds</span></span>
<span id="cb309-13"><a href="the-linear-model.html#cb309-13" tabindex="-1"></a>prior_striped_l <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, striped_mu, sample_sigma)</span>
<span id="cb309-14"><a href="the-linear-model.html#cb309-14" tabindex="-1"></a>prior_unstriped_l <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, unstriped_mu, sample_sigma)</span>
<span id="cb309-15"><a href="the-linear-model.html#cb309-15" tabindex="-1"></a></span>
<span id="cb309-16"><a href="the-linear-model.html#cb309-16" tabindex="-1"></a><span class="co">#combine to a dataframe</span></span>
<span id="cb309-17"><a href="the-linear-model.html#cb309-17" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">prior_striped_l =</span> prior_striped_l,</span>
<span id="cb309-18"><a href="the-linear-model.html#cb309-18" tabindex="-1"></a>                 <span class="at">prior_unstriped_l =</span> prior_unstriped_l)</span>
<span id="cb309-19"><a href="the-linear-model.html#cb309-19" tabindex="-1"></a></span>
<span id="cb309-20"><a href="the-linear-model.html#cb309-20" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb309-21"><a href="the-linear-model.html#cb309-21" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> df<span class="sc">$</span>prior_striped_l, <span class="at">fill =</span> <span class="st">&quot;striped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb309-22"><a href="the-linear-model.html#cb309-22" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> df<span class="sc">$</span>prior_unstriped_l, <span class="at">fill =</span> <span class="st">&quot;unstriped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb309-23"><a href="the-linear-model.html#cb309-23" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;striped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb309-24"><a href="the-linear-model.html#cb309-24" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;SVL (cm)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;Morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb309-25"><a href="the-linear-model.html#cb309-25" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="ch09_linearModels_files/figure-html/c09_chunk27-1.png" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>We see the priors imply no difference in the distribution of individual SVLs, but certainly they allow for it. The only issue here is that the priors imply a few negative values for SVL, which of course doesn’t make sense. However those observations are extremely rare, and we proceed to fit the model:</p>
<p>Let’s go ahead look at how we fit the model with <code>brms</code>. We already have the data organized in the dataframe <code>tail</code>, so we can can get right to defining our model and priors.</p>
<p>All we want here is the estimation of a mean for each group, so we don’t want to estimate a typical intercept. To suppress the intercept estimation in <code>brms</code>, we use the <code>0 + ...</code> syntax. Adding <code>0 + morph.i</code> syntax tells <code>brms</code> to compute a separate intercept for each index value of the <code>morph.i</code> factor variable. As such, when we define the priors for the means, we do so by specifying <code>class = b</code> (rather than <code>Intercept</code>).</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="the-linear-model.html#cb310-1" tabindex="-1"></a><span class="co">#specify model formula</span></span>
<span id="cb310-2"><a href="the-linear-model.html#cb310-2" tabindex="-1"></a>m2.formula <span class="ot">&lt;-</span> <span class="fu">bf</span>(length.cm <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> morph.i,</span>
<span id="cb310-3"><a href="the-linear-model.html#cb310-3" tabindex="-1"></a>                <span class="at">family =</span> gaussian)  </span>
<span id="cb310-4"><a href="the-linear-model.html#cb310-4" tabindex="-1"></a></span>
<span id="cb310-5"><a href="the-linear-model.html#cb310-5" tabindex="-1"></a><span class="co">#specify priors</span></span>
<span id="cb310-6"><a href="the-linear-model.html#cb310-6" tabindex="-1"></a>m2.prior <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="fl">3.5</span>, <span class="fl">0.5</span>), <span class="at">class =</span> b),</span>
<span id="cb310-7"><a href="the-linear-model.html#cb310-7" tabindex="-1"></a>              <span class="fu">prior</span>(<span class="fu">exponential</span>(<span class="dv">3</span>), <span class="at">class=</span>sigma))</span>
<span id="cb310-8"><a href="the-linear-model.html#cb310-8" tabindex="-1"></a>              </span>
<span id="cb310-9"><a href="the-linear-model.html#cb310-9" tabindex="-1"></a><span class="co">#compute the posterior</span></span>
<span id="cb310-10"><a href="the-linear-model.html#cb310-10" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">brm</span>(<span class="at">data =</span> tail,</span>
<span id="cb310-11"><a href="the-linear-model.html#cb310-11" tabindex="-1"></a>         <span class="at">formula =</span> m2.formula,</span>
<span id="cb310-12"><a href="the-linear-model.html#cb310-12" tabindex="-1"></a>         <span class="at">prior =</span> m2.prior,</span>
<span id="cb310-13"><a href="the-linear-model.html#cb310-13" tabindex="-1"></a>         <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb310-14"><a href="the-linear-model.html#cb310-14" tabindex="-1"></a>         <span class="at">seed=</span><span class="dv">123</span>)</span>
<span id="cb310-15"><a href="the-linear-model.html#cb310-15" tabindex="-1"></a></span>
<span id="cb310-16"><a href="the-linear-model.html#cb310-16" tabindex="-1"></a><span class="fu">plot</span>(m2)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk28-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk28)TODO: caption.
</p>
</div>
<p>We see the plot function returns posterior distributions for three parameters, including the mean for each morph and the standard deviation. The means for each morph are labeled with the appropriate index level, specifically <code>morph.i1</code> for striped and <code>morph.i2</code> for unstriped. The traceplots look pretty good, so we turn our attention to the model summary:</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="the-linear-model.html#cb311-1" tabindex="-1"></a><span class="fu">print</span>(m2)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity 
## Formula: length.cm ~ 0 + morph.i 
##    Data: tail (Number of observations: 40) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Regression Coefficients:
##          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## morph.i1     3.75      0.08     3.58     3.91 1.00     3509     2932
## morph.i2     3.46      0.08     3.29     3.62 1.00     3670     2422
## 
## Further Distributional Parameters:
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.37      0.04     0.30     0.47 1.00     3474     2613
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>It looks like the mean SVL of the posterior for striped morph is 3.75 g, with a 95% credible interval from 3.58 to 3.91 g. In contrast, the mean of the posterior for unstriped morph is 3.46 cm, with a 95% credible interval of 3.29 to 3.62.</p>
<p>Is there a difference in the mean SVL between color morphs? The posterior distributions overlap somethwat, we we can see by the 95% credible intervals. But we don’t need to visually look for overlap of posterior distributions. We can use the samples of the mean SVL for each morph to derive values that allow us to make the dcomparison between morph explicit. Let’s first extract the samples and plot the posterior distributions for hte mean of each morph.</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="the-linear-model.html#cb313-1" tabindex="-1"></a><span class="co">#extract the posterior samples</span></span>
<span id="cb313-2"><a href="the-linear-model.html#cb313-2" tabindex="-1"></a>m2.post <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(m2)</span>
<span id="cb313-3"><a href="the-linear-model.html#cb313-3" tabindex="-1"></a><span class="fu">head</span>(m2.post)</span></code></pre></div>
<pre><code>## # A draws_df: 6 iterations, 1 chains, and 5 variables
##   b_morph.i1 b_morph.i2 sigma lprior lp__
## 1        3.9        3.5  0.37  -0.83  -19
## 2        3.8        3.5  0.37  -0.69  -18
## 3        3.8        3.6  0.40  -0.69  -18
## 4        3.8        3.3  0.35  -0.56  -18
## 5        3.7        3.6  0.35  -0.50  -17
## 6        3.7        3.5  0.42  -0.69  -18
## # ... hidden reserved variables {&#39;.chain&#39;, &#39;.iteration&#39;, &#39;.draw&#39;}</code></pre>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="the-linear-model.html#cb315-1" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb315-2"><a href="the-linear-model.html#cb315-2" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb315-3"><a href="the-linear-model.html#cb315-3" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> m2.post<span class="sc">$</span>b_morph.i1, <span class="at">fill =</span> <span class="st">&quot;striped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb315-4"><a href="the-linear-model.html#cb315-4" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> m2.post<span class="sc">$</span>b_morph.i2, <span class="at">fill =</span> <span class="st">&quot;unstriped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb315-5"><a href="the-linear-model.html#cb315-5" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;striped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb315-6"><a href="the-linear-model.html#cb315-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Mean SVL (cm)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;Morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb315-7"><a href="the-linear-model.html#cb315-7" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="ch09_linearModels_files/figure-html/c09_chunk30-1.png" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>We can see in the plot what we thought was apparent in the credibel intervals: the bulk of the posterior distribution for mean SVL for striped is greater than unstriped, but there is some overlap. If we are really interested in the difference between the mean SVL of each morph, we should quantify that difference directly from the samples and examine the posterior distribution of the difference in means. This is as simple is adding a new column to <code>m2.post</code> as the difference in means between the morphs, then we can summarize that posterior distribution. This is called a <strong>contrast</strong>.</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="the-linear-model.html#cb316-1" tabindex="-1"></a><span class="co">#calculate the contrast as mean striped - mean unstriped</span></span>
<span id="cb316-2"><a href="the-linear-model.html#cb316-2" tabindex="-1"></a>m2.post<span class="sc">$</span>morph.delta <span class="ot">&lt;-</span> m2.post<span class="sc">$</span>b_morph.i1 <span class="sc">-</span> m2.post<span class="sc">$</span>b_morph.i2</span>
<span id="cb316-3"><a href="the-linear-model.html#cb316-3" tabindex="-1"></a></span>
<span id="cb316-4"><a href="the-linear-model.html#cb316-4" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb316-5"><a href="the-linear-model.html#cb316-5" tabindex="-1"></a><span class="fu">ggplot</span>(m2.post, <span class="fu">aes</span>(<span class="at">x =</span> morph.delta)) <span class="sc">+</span></span>
<span id="cb316-6"><a href="the-linear-model.html#cb316-6" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;slategray&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb316-7"><a href="the-linear-model.html#cb316-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Difference in mean SVL (cm; Stirped - Unstriped)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb316-8"><a href="the-linear-model.html#cb316-8" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk31-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk31)TODO: caption.
</p>
</div>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="the-linear-model.html#cb317-1" tabindex="-1"></a><span class="co">#mean and credible interval</span></span>
<span id="cb317-2"><a href="the-linear-model.html#cb317-2" tabindex="-1"></a><span class="fu">mean</span>(m2.post<span class="sc">$</span>morph.delta)</span></code></pre></div>
<pre><code>## [1] 0.2888998</code></pre>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="the-linear-model.html#cb319-1" tabindex="-1"></a><span class="fu">quantile</span>(m2.post<span class="sc">$</span>morph.delta, <span class="at">probs=</span><span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##       2.5%      97.5% 
## 0.06143877 0.51822613</code></pre>
<p>We mean of the derived posterior difference in means between morphs is 0.29, with a 95% credible interval of 0.06 to 0.52 cm. Thus, There’s a 95% probability that the mean SVL for striped morph is at least 0.06 cm greater than the unstriped morph. We could also compute the probability of the mean for each morph being greater than the other:</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="the-linear-model.html#cb321-1" tabindex="-1"></a><span class="co">#probability of mean striped &gt; mean unstriped</span></span>
<span id="cb321-2"><a href="the-linear-model.html#cb321-2" tabindex="-1"></a><span class="fu">mean</span>(m2.post<span class="sc">$</span>morph.delta<span class="sc">&gt;</span><span class="dv">0</span>)</span></code></pre></div>
<pre><code>## [1] 0.99125</code></pre>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="the-linear-model.html#cb323-1" tabindex="-1"></a><span class="co">#probability of mean untriped &gt; mean striped</span></span>
<span id="cb323-2"><a href="the-linear-model.html#cb323-2" tabindex="-1"></a><span class="fu">mean</span>(m2.post<span class="sc">$</span>morph.delta<span class="sc">&lt;</span><span class="dv">0</span>)</span></code></pre></div>
<pre><code>## [1] 0.00875</code></pre>
<p>We find a 99% chance the mean SVL for striped is greater than unstriped.</p>
<p>In addition to examining the posterior distribution for the mean SVL, we can also examine the posterior distribution for the individual SVL values.</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="the-linear-model.html#cb325-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb325-2"><a href="the-linear-model.html#cb325-2" tabindex="-1"></a></span>
<span id="cb325-3"><a href="the-linear-model.html#cb325-3" tabindex="-1"></a><span class="co"># Simulate one weight per posterior sample</span></span>
<span id="cb325-4"><a href="the-linear-model.html#cb325-4" tabindex="-1"></a>post_s_w <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">nrow</span>(m2.post), <span class="at">mean =</span> m2.post<span class="sc">$</span>b_morph.i1, <span class="at">sd =</span> m2.post<span class="sc">$</span>sigma)</span>
<span id="cb325-5"><a href="the-linear-model.html#cb325-5" tabindex="-1"></a>post_u_w <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">nrow</span>(m2.post), <span class="at">mean =</span> m2.post<span class="sc">$</span>b_morph.i2, <span class="at">sd =</span> m2.post<span class="sc">$</span>sigma)</span>
<span id="cb325-6"><a href="the-linear-model.html#cb325-6" tabindex="-1"></a></span>
<span id="cb325-7"><a href="the-linear-model.html#cb325-7" tabindex="-1"></a><span class="co"># Create data frame for plotting</span></span>
<span id="cb325-8"><a href="the-linear-model.html#cb325-8" tabindex="-1"></a>df_post <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">post_s_w =</span> post_s_w,</span>
<span id="cb325-9"><a href="the-linear-model.html#cb325-9" tabindex="-1"></a>                      <span class="at">post_u_w =</span> post_u_w)</span>
<span id="cb325-10"><a href="the-linear-model.html#cb325-10" tabindex="-1"></a></span>
<span id="cb325-11"><a href="the-linear-model.html#cb325-11" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb325-12"><a href="the-linear-model.html#cb325-12" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> df_post<span class="sc">$</span>post_s_w, <span class="at">fill =</span> <span class="st">&quot;striped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb325-13"><a href="the-linear-model.html#cb325-13" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> df_post<span class="sc">$</span>post_u_w, <span class="at">fill =</span> <span class="st">&quot;unstriped&quot;</span>), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb325-14"><a href="the-linear-model.html#cb325-14" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;striped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb325-15"><a href="the-linear-model.html#cb325-15" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Individual weight (lb)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;Morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb325-16"><a href="the-linear-model.html#cb325-16" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="ch09_linearModels_files/figure-html/c09_chunk33-1.png" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>Here the <code>rnorm</code> function is generating a random SVL for each color morph drawn from a distribution specified by the sampled mean and standard deviation from the posterior distributions for striped and unstriped morphs. Plotting the density of those 10,000 SVLs for each morph allows us to visualize the posterior distributions of individual SVL by morph. We can clearly see that the center of the distributions is greater for the striped than unstriped morph (as we saw previously), but that individual weights overlap quite a bit between color morphs.</p>
<p>We can also quantify a contrast for the individual SVLs. This gives us the posterior distribution of differences in <em>individual</em> SVLs between color morphs:</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="the-linear-model.html#cb326-1" tabindex="-1"></a><span class="co">#posterior distribution for difference in individual weights (contrast)</span></span>
<span id="cb326-2"><a href="the-linear-model.html#cb326-2" tabindex="-1"></a>df_post<span class="sc">$</span>l_contrast <span class="ot">&lt;-</span> df_post<span class="sc">$</span>post_s_w <span class="sc">-</span> df_post<span class="sc">$</span>post_u_w</span>
<span id="cb326-3"><a href="the-linear-model.html#cb326-3" tabindex="-1"></a></span>
<span id="cb326-4"><a href="the-linear-model.html#cb326-4" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb326-5"><a href="the-linear-model.html#cb326-5" tabindex="-1"></a><span class="fu">ggplot</span>(df_post, <span class="fu">aes</span>(<span class="at">x =</span> l_contrast)) <span class="sc">+</span></span>
<span id="cb326-6"><a href="the-linear-model.html#cb326-6" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">fill =</span> <span class="st">&quot;slategray&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb326-7"><a href="the-linear-model.html#cb326-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Difference in individual SVL (cm; Striped - Unstriped)&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb326-8"><a href="the-linear-model.html#cb326-8" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk34-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk34)TODO: caption.
</p>
</div>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="the-linear-model.html#cb327-1" tabindex="-1"></a><span class="co">#proportion above zero</span></span>
<span id="cb327-2"><a href="the-linear-model.html#cb327-2" tabindex="-1"></a><span class="fu">sum</span>(df_post<span class="sc">$</span>l_contrast <span class="sc">&gt;</span> <span class="dv">0</span>)<span class="sc">/</span><span class="fu">nrow</span>(df_post)</span></code></pre></div>
<pre><code>## [1] 0.70675</code></pre>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="the-linear-model.html#cb329-1" tabindex="-1"></a><span class="co">#proportion below zero</span></span>
<span id="cb329-2"><a href="the-linear-model.html#cb329-2" tabindex="-1"></a><span class="fu">sum</span>(df_post<span class="sc">$</span>l_contrast <span class="sc">&lt;</span> <span class="dv">0</span>)<span class="sc">/</span><span class="fu">nrow</span>(df_post)</span></code></pre></div>
<pre><code>## [1] 0.29325</code></pre>
<p>This contrast indicate that if we randomly select one striped morph and one unstriped morph from their respective SVL distributions, we can expect the striped morph to have a longer SVL than the unstriped morph 71% of the time, whereas we expect the unstriped morph to have a greater SVL 29% of the time.</p>
<div id="how-a-frequentist-might-analyze-it" class="section level4 hasAnchor" number="9.3.1.1">
<h4><span class="header-section-number">9.3.1.1</span> How a frequentist might analyze it<a href="the-linear-model.html#how-a-frequentist-might-analyze-it" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now let’s take a look at how to fit a linear model with a binary categorical explanatory variable with frequentist inference. In frequentist inference with categorical explanatory variables, a common approach is to use an <em>indicator variable</em> for the categorical predicator. An indicator variable is simply a binary numeric indicator of whether or not each individual in the dataset is part of the particular category of interest. So for the question about color morph, we can use an indicator variable for “striped”, where a “1” indicates the individual is striped, and a “0” indicates the individual is not striped. Because our categorical variable of color morph in this case is binary, a “0” for striped means the individual is unstriped. Let’s go ahead and create the indicator variable:</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="the-linear-model.html#cb331-1" tabindex="-1"></a>tail<span class="sc">$</span>striped <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(tail<span class="sc">$</span>morph <span class="sc">==</span> <span class="st">&quot;striped&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<p>When we use an indicator variable such as <code>male</code> to model the effect of sex on weight, the statistical model looks a bit different than what it looked like when we used an index:</p>
<p><span class="math inline">\(\hat{l}_i = \alpha + \beta X_i\)</span></p>
<p>Here we are predicting the expected SVL of individuals <span class="math inline">\(\hat{l}_i\)</span> based on an intercept and a slope representing the effect of color morph on SVL. In this model, <span class="math inline">\(X_i\)</span> represents the indicator variable for “striped” and takes on values of 0 or 1, and <span class="math inline">\(\beta\)</span> represents the effect of being striped on SVL. Note than when <span class="math inline">\(X_i = 0\)</span>, <span class="math inline">\(\hat{l}_i = \alpha\)</span>. In other words, <span class="math inline">\(\alpha\)</span> is the expected mean SVL for the unstriped morph, and <span class="math inline">\(\beta\)</span> represents the difference in mean weight between striped and unstriped morphs. This is a little different than our Bayesian model which directly estimated the posterior distribution of average weights for striped and unstriped morphs directly.</p>
<p>Let’s go ahead and fit this model:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="the-linear-model.html#cb332-1" tabindex="-1"></a><span class="co">#fit the regression model</span></span>
<span id="cb332-2"><a href="the-linear-model.html#cb332-2" tabindex="-1"></a>m2.f <span class="ot">&lt;-</span> <span class="fu">lm</span>(length.cm <span class="sc">~</span> striped, <span class="at">data=</span>tail)</span>
<span id="cb332-3"><a href="the-linear-model.html#cb332-3" tabindex="-1"></a><span class="fu">summary</span>(m2.f)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = length.cm ~ striped, data = tail)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.6600 -0.2800 -0.0075  0.2450  0.7400 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.46000    0.08093  42.754   &lt;2e-16 ***
## striped      0.29500    0.11445   2.578    0.014 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3619 on 38 degrees of freedom
## Multiple R-squared:  0.1488, Adjusted R-squared:  0.1264 
## F-statistic: 6.644 on 1 and 38 DF,  p-value: 0.01395</code></pre>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="the-linear-model.html#cb334-1" tabindex="-1"></a><span class="co">#confidence interval</span></span>
<span id="cb334-2"><a href="the-linear-model.html#cb334-2" tabindex="-1"></a><span class="fu">confint</span>(m2.f, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) 3.29616982 3.6238302
## striped     0.06330913 0.5266909</code></pre>
<p>Let’s start by breaking down the model output. We can see the estimate for the intercept is 3.46. This represents the estimate of mean unstriped SVL. The <em>lm</em> function also conducts a hypothesis test of whether the intercept is significantly different from 0. We see the P-value is very low, so we would reject teh null hypothesis that the intercept is different from 0. But often this kind of hypothesis test doesnt’ make sense. Why do we care if the intercept, representing the mean weight of the unstriped morph, is different than 0?</p>
<p>Turning our attention to the slope for the effect of color morph, we see the estiamte is 0.295. What does this mean? It means that our best estimate of how different the mean striped morph is from the mean unstriped morph is 0.295 cm greater. In other words, the indicator parameterization of our model directly estimates the contrast between males and females, and whether that contrast is significantly different from 0. Here the P-value is 0.014, so using the typical significance value of 0.05, we would reject the null hypothesis that there is no difference in the mean SVL between morphs and conclude the average SVL for the striped morph is larger.</p>
<p>Let’s plot the regression line so we can visually see what the model is doing:</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="the-linear-model.html#cb336-1" tabindex="-1"></a><span class="co">#values of male</span></span>
<span id="cb336-2"><a href="the-linear-model.html#cb336-2" tabindex="-1"></a>x_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb336-3"><a href="the-linear-model.html#cb336-3" tabindex="-1"></a></span>
<span id="cb336-4"><a href="the-linear-model.html#cb336-4" tabindex="-1"></a><span class="co">#confidence interval for the mean weight for each sex</span></span>
<span id="cb336-5"><a href="the-linear-model.html#cb336-5" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(m2.f, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">striped=</span>x_vals), </span>
<span id="cb336-6"><a href="the-linear-model.html#cb336-6" tabindex="-1"></a>                 <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb336-7"><a href="the-linear-model.html#cb336-7" tabindex="-1"></a></span>
<span id="cb336-8"><a href="the-linear-model.html#cb336-8" tabindex="-1"></a><span class="co">#prediction interval</span></span>
<span id="cb336-9"><a href="the-linear-model.html#cb336-9" tabindex="-1"></a>preds_pi <span class="ot">&lt;-</span> <span class="fu">predict</span>(m2.f, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">striped=</span>x_vals), </span>
<span id="cb336-10"><a href="the-linear-model.html#cb336-10" tabindex="-1"></a>                    <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb336-11"><a href="the-linear-model.html#cb336-11" tabindex="-1"></a></span>
<span id="cb336-12"><a href="the-linear-model.html#cb336-12" tabindex="-1"></a><span class="co"># Combine into a data frame for plotting</span></span>
<span id="cb336-13"><a href="the-linear-model.html#cb336-13" tabindex="-1"></a>pred_df <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">striped=</span>x_vals,</span>
<span id="cb336-14"><a href="the-linear-model.html#cb336-14" tabindex="-1"></a>                 <span class="at">fit =</span> preds[, <span class="st">&quot;fit&quot;</span>],</span>
<span id="cb336-15"><a href="the-linear-model.html#cb336-15" tabindex="-1"></a>                 <span class="at">lwr_ci =</span> preds[, <span class="st">&quot;lwr&quot;</span>],</span>
<span id="cb336-16"><a href="the-linear-model.html#cb336-16" tabindex="-1"></a>                 <span class="at">upr_ci =</span> preds[, <span class="st">&quot;upr&quot;</span>],</span>
<span id="cb336-17"><a href="the-linear-model.html#cb336-17" tabindex="-1"></a>                 <span class="at">lwr_pi =</span> preds_pi[, <span class="st">&quot;lwr&quot;</span>],</span>
<span id="cb336-18"><a href="the-linear-model.html#cb336-18" tabindex="-1"></a>                 <span class="at">upr_pi =</span> preds_pi[, <span class="st">&quot;upr&quot;</span>])</span>
<span id="cb336-19"><a href="the-linear-model.html#cb336-19" tabindex="-1"></a></span>
<span id="cb336-20"><a href="the-linear-model.html#cb336-20" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb336-21"><a href="the-linear-model.html#cb336-21" tabindex="-1"></a><span class="fu">ggplot</span>(tail, <span class="fu">aes</span>(<span class="at">x =</span> striped, <span class="at">y =</span> length.cm)) <span class="sc">+</span></span>
<span id="cb336-22"><a href="the-linear-model.html#cb336-22" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> pred_df, </span>
<span id="cb336-23"><a href="the-linear-model.html#cb336-23" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> striped, <span class="at">y =</span> fit)) <span class="sc">+</span></span>
<span id="cb336-24"><a href="the-linear-model.html#cb336-24" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">shape =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">&quot;firebrick&quot;</span>) <span class="sc">+</span></span>
<span id="cb336-25"><a href="the-linear-model.html#cb336-25" tabindex="-1"></a>  <span class="fu">labs</span>(,</span>
<span id="cb336-26"><a href="the-linear-model.html#cb336-26" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Colr morph indicator&quot;</span>,</span>
<span id="cb336-27"><a href="the-linear-model.html#cb336-27" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;SVL (cm)&quot;</span></span>
<span id="cb336-28"><a href="the-linear-model.html#cb336-28" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb336-29"><a href="the-linear-model.html#cb336-29" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk37-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk37)TODO: caption.
</p>
</div>
<p>This scatterplot shows all the data for striped and unstriped color morphs. The regression line begins at the estimated mean for the unstriped morph (indicator = 0) and ends at the estimated mean for the striped morph (indicator = 1). The slope of that regression line represents the difference in means between striped and unstriped morphs.</p>
<p>Note that the <em>predict</em> function allowed us to directly compute the estimated means for <em>both</em> striped and unstriped morphs:</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="the-linear-model.html#cb337-1" tabindex="-1"></a><span class="fu">cbind.data.frame</span>(<span class="at">male=</span>x_vals, preds)</span></code></pre></div>
<pre><code>##   male   fit     lwr     upr
## 1    0 3.460 3.29617 3.62383
## 2    1 3.755 3.59117 3.91883</code></pre>
<p>What can we conclude from this model? The estimated mean weights were 3.46 for the unstriped morph (95% CI: 3.3-3.6) and 3.76 for the striped morph (95% CI: 3.59-3.92). The striped morph was significantly longer than the unstriped morph (beta = 0.295, 95% CI: 0.06-0.53, t = 2.58, df = 38, P = 0.014).</p>
<p>One handy way of plotting the data and estimates of mean weight from a model with categorical explanatory variables is to use a stripchart:</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="the-linear-model.html#cb339-1" tabindex="-1"></a><span class="co"># Add sex to prediction data</span></span>
<span id="cb339-2"><a href="the-linear-model.html#cb339-2" tabindex="-1"></a>pred.df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb339-3"><a href="the-linear-model.html#cb339-3" tabindex="-1"></a>  <span class="at">male =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb339-4"><a href="the-linear-model.html#cb339-4" tabindex="-1"></a>  <span class="at">morph =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;unstriped&quot;</span>, <span class="st">&quot;striped&quot;</span>)),</span>
<span id="cb339-5"><a href="the-linear-model.html#cb339-5" tabindex="-1"></a>  <span class="at">fit =</span> preds[,<span class="st">&quot;fit&quot;</span>],</span>
<span id="cb339-6"><a href="the-linear-model.html#cb339-6" tabindex="-1"></a>  <span class="at">lwr =</span> preds[,<span class="st">&quot;lwr&quot;</span>],</span>
<span id="cb339-7"><a href="the-linear-model.html#cb339-7" tabindex="-1"></a>  <span class="at">upr =</span> preds[,<span class="st">&quot;upr&quot;</span>]</span>
<span id="cb339-8"><a href="the-linear-model.html#cb339-8" tabindex="-1"></a>)</span>
<span id="cb339-9"><a href="the-linear-model.html#cb339-9" tabindex="-1"></a></span>
<span id="cb339-10"><a href="the-linear-model.html#cb339-10" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb339-11"><a href="the-linear-model.html#cb339-11" tabindex="-1"></a><span class="fu">ggplot</span>(tail, <span class="fu">aes</span>(<span class="at">x =</span> morph, <span class="at">y =</span> length.cm)) <span class="sc">+</span></span>
<span id="cb339-12"><a href="the-linear-model.html#cb339-12" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">width =</span> <span class="fl">0.1</span>, <span class="at">shape =</span> <span class="dv">1</span>, <span class="fu">aes</span>(<span class="at">color =</span> morph)) <span class="sc">+</span></span>
<span id="cb339-13"><a href="the-linear-model.html#cb339-13" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> pred.df, <span class="fu">aes</span>(<span class="at">x =</span> morph, <span class="at">y =</span> fit), <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb339-14"><a href="the-linear-model.html#cb339-14" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">data =</span> pred.df,</span>
<span id="cb339-15"><a href="the-linear-model.html#cb339-15" tabindex="-1"></a>               <span class="fu">aes</span>(<span class="at">x =</span> morph, <span class="at">xend =</span> morph, <span class="at">y =</span> lwr, <span class="at">yend =</span> upr), <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb339-16"><a href="the-linear-model.html#cb339-16" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;red&quot;</span>, <span class="st">&quot;unstriped&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>)) <span class="sc">+</span></span>
<span id="cb339-17"><a href="the-linear-model.html#cb339-17" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sex&quot;</span>, <span class="at">y =</span> <span class="st">&quot;SVL (cm)&quot;</span>, <span class="at">color =</span> <span class="st">&quot;Morph&quot;</span>) <span class="sc">+</span></span>
<span id="cb339-18"><a href="the-linear-model.html#cb339-18" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb339-19"><a href="the-linear-model.html#cb339-19" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="ch09_linearModels_files/figure-html/c09_chunk39-1.png" alt="TODO: caption." width="672" />
<p class="caption">
(#fig:c09_chunk39)TODO: caption.
</p>
</div>
<p>Here this shows all the data plust the means and their 95% confidence intervals for each color morph.</p>
<p>A final word on frequentist estimation with a categorical explanatory variable that is binary. The linear model that we just fit is equivalent to a <em>two-sample t-test</em> that assumes the variance of SVL is equivalent for striped and unstriped morphs. One can do the same analysis with the <em>t.test</em> function specifying that the comparison is not paired (more on that later) and that variances are equal (var.equal=TRUE):</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="the-linear-model.html#cb340-1" tabindex="-1"></a><span class="fu">t.test</span>(tail<span class="sc">$</span>length.cm <span class="sc">~</span> tail<span class="sc">$</span>morph, </span>
<span id="cb340-2"><a href="the-linear-model.html#cb340-2" tabindex="-1"></a>       <span class="at">mu =</span> <span class="dv">0</span>, <span class="at">conf.level =</span> <span class="fl">0.95</span>,</span>
<span id="cb340-3"><a href="the-linear-model.html#cb340-3" tabindex="-1"></a>       <span class="at">var.equal =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  tail$length.cm by tail$morph
## t = 2.5776, df = 38, p-value = 0.01395
## alternative hypothesis: true difference in means between group striped and group unstriped is not equal to 0
## 95 percent confidence interval:
##  0.06330913 0.52669087
## sample estimates:
##   mean in group striped mean in group unstriped 
##                   3.755                   3.460</code></pre>
</div>
</div>
<div id="categorical-predictors-with-more-than-two-categories" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Categorical predictors with more than two categories<a href="the-linear-model.html#categorical-predictors-with-more-than-two-categories" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Planned</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bayesian-workflow.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="graphical-causal-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true,
    "toc_depth": 2
  },
  "toolbar": {
    "position": "fixed"
  },
  "info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
